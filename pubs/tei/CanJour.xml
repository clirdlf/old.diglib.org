<?xml version="1.0"?>
<?xml-stylesheet href="dlfbasic-pub.xsl" type="text/xsl"?>

<!DOCTYPE TEI.2 SYSTEM 'http://etext.lib.virginia.edu/tei/teixlite.dtd'[
<!NOTATION jpg SYSTEM "JPEG">
<!NOTATION pdf SYSTEM "PDF">
<!NOTATION xml SYSTEM "XML">
<!NOTATION html SYSTEM "HTML">
<!ENTITY infoarchaimitjairspace SYSTEM "http://www.infoarch.ai.mit.edu/jair/jair-space.html" NDATA html>
<!ENTITY simbadustrasbgfrApJmap SYSTEM "http://simbad.u-strasbg.fr/ApJ/map.pl" NDATA html>
<!ENTITY jimeopen SYSTEM "http://www-jime.open.ac.uk" NDATA html>
<!ENTITY ProjectHarvestdistributionimage002 SYSTEM "./Project%20Harvest%20(distribution%20copy)_files/image002.jpg" NDATA jpg>
<!ENTITY ProjectHarvestdistributionimage003 SYSTEM "./ProjectHarvest(distributioncopy)_files/image003.gif" NDATA jpg>
<!ENTITY yaleimage001 SYSTEM "yaleimage001.jpg" NDATA jpg>
<!ENTITY NYPLimage001 SYSTEM "NYPLimage001.jpg" NDATA jpg>
<!ENTITY MITimage001 SYSTEM "MITimage001.jpg" NDATA jpg>
<!ENTITY architronicsaedkent SYSTEM "http://architronic.saed.kent.edu" NDATA html>
<!ENTITY consecolJournal SYSTEM "http://www.consecol.org/Journal" NDATA html>
<!ENTITY earthinteractions SYSTEM "http://earthinteractions.org" NDATA html>
<!ENTITY societymusictheorymtoissuesmto0281dodson SYSTEM "http://www.societymusictheory.org/mto/issues/mto.02.8.1/mto.02.8.1.dodson.html" NDATA html>
<!ENTITY imejwfu SYSTEM "http://imej.wfu.edu" NDATA html>
<!ENTITY opticsexpress SYSTEM "http://www.opticsexpress.org" NDATA html>
<!ENTITY albanyjmmh SYSTEM "http://www.albany.edu/jmmh" NDATA html>
<!ENTITY insectscience SYSTEM "http://www.insectscience.org" NDATA html>
<!ENTITY ijc SYSTEM "http://www.ijc.com" NDATA html>
<!ENTITY jucs SYSTEM "http://www.jucs.org" NDATA html>
<!ENTITY pressumichjep SYSTEM "http://www.press.umich.edu/jep" NDATA html>
<!ENTITY linguisticdiscoverydartmouthLinguistics SYSTEM "http://linguistic-discovery.dartmouth.edu/WebObjects/Linguistics.woa" NDATA html>
<!ENTITY cultivateint SYSTEM "http://www.cultivate-int.org" NDATA html>
<!ENTITY mathswarwickagt SYSTEM "http://www.maths.warwick.ac.uk/agt/" NDATA html>
<!ENTITY mathswarwickgt SYSTEM "http://www.maths.warwick.ac.uk/gt/" NDATA html>
<!ENTITY thescientificworld SYSTEM "http://www.thescientificworld.com" NDATA html>
<!ENTITY dspace SYSTEM "http://dspace.org" NDATA html>
<!ENTITY oclcresearchprojectspmwgdefault SYSTEM "http://www.oclc.org/research/projects/pmwg/default.htm" NDATA html>
<!ENTITY d3esourceforge SYSTEM "http://d3e.sourceforge.net" NDATA html>
<!ENTITY journalcocornucopia SYSTEM "http://www.journal.co-cornucopia.org/" NDATA html>
<!ENTITY dlese SYSTEM "http://www.dlese.org/" NDATA html>
<!ENTITY unidataucarcommunitycommitteesumada SYSTEM "http://www.unidata.ucar.edu/community/committees/umada/" NDATA html>
<!ENTITY d3esourceforged3eprints SYSTEM "http://d3e.sourceforge.net/d3eprints.html" NDATA html>
<!ENTITY cognetmit SYSTEM "http://cognet.mit.edu" NDATA html>
<!ENTITY dlibapril99bearman04bearman SYSTEM "http://www.dlib.org/dlib/april99/bearman/04bearman.html" NDATA html>
<!ENTITY rlgpreservdiginews56feature1 SYSTEM "http://www.rlg.org/preserv/diginews/diginews5-6.html#feature1" NDATA html>
<!ENTITY clirpubsreportsrothenbergcontents SYSTEM "http://www.clir.org/pubs/reports/rothenberg/contents.html" NDATA html>
<!ENTITY columbiaculibrariesdigitalprojectsepic SYSTEM "http://www.columbia.edu/cu/libraries/digital/projects/epic.html" NDATA html>
<!ENTITY infoarchaimitjairrationale SYSTEM "http://www.infoarch.ai.mit.edu/jair/jair-rationale.html" NDATA html>
<!ENTITY adsabsharvardabstractservice SYSTEM "http://adsabs.harvard.edu/abstract_service.html" NDATA html>
<!ENTITY firstmondayissues62buckinghamshum SYSTEM "http://firstmonday.org/issues/issue6_2/buckingham_shum" NDATA html>
<!ENTITY catchwordalpsp09531513v14n4contp11 SYSTEM "http://www.catchword.com/alpsp/09531513/v14n4/contp1-1.htm" NDATA html>
<!ENTITY imejwfuarticles1999201index SYSTEM "http://imej.wfu.edu/articles/1999/2/01/index.asp" NDATA html>
<!ENTITY musejhu SYSTEM "http://muse.jhu.edu" NDATA html>
<!ENTITY albanyjmmhvol3harvanindex SYSTEM "http://www.albany.edu/jmmh/vol3/harvan/index.html" NDATA html>
<!ENTITY insectscienceaboutchange SYSTEM "http://www.insectscience.org/about/change" NDATA html>
<!ENTITY macclade SYSTEM "http://macclade.org/" NDATA html>
<!ENTITY paupcsitfsu SYSTEM "http://paup.csit.fsu.edu/" NDATA html>
<!ENTITY slashdot SYSTEM "http://slashdot.org" NDATA html>
<!ENTITY pressumichjep0603McAdamspages SYSTEM "http://www.press.umich.edu/jep/06-03/McAdams/pages/" NDATA html>
<!ENTITY w3TRxlink SYSTEM "http://w3.org/TR/xlink" NDATA html>
<!ENTITY bioonerequestindex SYSTEM "http://www.bioone.org/bioone/?request=index-html" NDATA html>
<!ENTITY amsallenpressamsonlinerequestindex SYSTEM "http://ams.allenpress.com/amsonline/?request=index-html" NDATA html>
<!ENTITY dtdnlmnih SYSTEM "http://dtd.nlm.nih.gov/" NDATA html>
<!ENTITY harvardimage001 SYSTEM "harvardimage001.jpg" NDATA jpg>
<!ENTITY clirpubsreportspub89contents SYSTEM "http://www.clir.org/pubs/reports/pub89/contents.html" NDATA html>
<!ENTITY ncbinlmnihGenbankOverview SYSTEM "http://www.ncbi.nlm.nih.gov/Genbank/GenbankOverview.html" NDATA html>
<!ENTITY hulharvardldi SYSTEM "http://hul.harvard.edu/ldi/" NDATA html>
<!ENTITY ietfproceedings02nov126 SYSTEM "http://www.ietf.org/proceedings/02nov/126.htm" NDATA html>
<!ENTITY ietfrfc2169 SYSTEM "http://www.ietf.org/rfc/rfc2169.txt" NDATA html>
<!ENTITY locstandardsmets SYSTEM "http://www.loc.gov/standards/mets/" NDATA html>
<!ENTITY diglibpreserveharvardsip10 SYSTEM "http://www.diglib.org/preserve/harvardsip10.pdf" NDATA html>
<!ENTITY diglibpreservehadtdfs SYSTEM "http://www.diglib.org/preserve/hadtdfs.pdf" NDATA html>
<!ENTITY rlgpreservdiginews51feature2 SYSTEM "http://www.rlg.org/preserv/diginews/diginews5-1.html#feature2" NDATA html>
<!ENTITY doihandbook2000010222DOIHandbookV100 SYSTEM "http://www.doi.org/handbook_2000/010222DOI-Handbook-V100.pdf" NDATA html>
<!ENTITY sfxitopenurl SYSTEM "http://www.sfxit.com/openurl/openurl.html" NDATA html>
<!ENTITY projecteuclid SYSTEM "http://projecteuclid.org" NDATA html>
<!ENTITY emani SYSTEM "http://www.emani.org/" NDATA html>
<!ENTITY diglibpreservecriteria SYSTEM "http://www.diglib.org/preserve/criteria.htm" NDATA html>
<!ENTITY mellon SYSTEM "http://www.mellon.org/" NDATA html>
<!ENTITY rlglongtermrepositories SYSTEM "http://www.rlg.org/longterm/repositories.pdf" NDATA html>
<!ENTITY oclcresearchprojectspmwgpmframework SYSTEM "http://www.oclc.org/research/projects/pmwg/pm_framework.pdf" NDATA html>
<!ENTITY ftprlgpubarchtffinalreport SYSTEM "ftp://ftp.rlg.org/pub/archtf/final-report.pdf" NDATA html>
<!ENTITY wwwclassicccsdsdocumentsCCSDS6500B1 SYSTEM "http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf" NDATA html>
<!ENTITY ssdoogsfcnasanostisoasoverview SYSTEM "http://ssdoo.gsfc.nasa.gov/nost/isoas/overview.html" NDATA html>
<!ENTITY leedscedars SYSTEM "http://www.leeds.ac.uk/cedars/" NDATA html>
<!ENTITY kbcoopnedlib SYSTEM "http://www.kb.nl/coop/nedlib/" NDATA html>
<!ENTITY nlapadi SYSTEM "http://www.nla.gov.au/padi/" NDATA html>
<!ENTITY diglibpreservepresjour SYSTEM "http://www.diglib.org/preserve/presjour.htm" NDATA html>
<!ENTITY diglibpreservecriteria SYSTEM "http://www.diglib.org/preserve/criteria.htm" NDATA html>
<!ENTITY oclcresearchprojectsdigipresincentivesdp SYSTEM "http://www.oclc.org/research/projects/digipres/incentives-dp.pdf" NDATA html>
<!ENTITY jiscuploadeddocumentsejournalsfinal SYSTEM "http://www.jisc.ac.uk/uploaded_documents/ejournalsfinal.pdf" NDATA html>
<!ENTITY clirpubsreportspub107 SYSTEM "http://www.clir.org/pubs/reports/pub107/pub107.pdf" NDATA html>
<!ENTITY jstoraboutmovingwall SYSTEM "http://www.jstor.org/about/movingwall.html" NDATA html>
<!ENTITY firstmondayissue85kellerindex SYSTEM "http://firstmonday.org/issues/issue8_5/keller/index.html" NDATA html>
<!ENTITY jstoraboutearchive SYSTEM "http://www.jstor.org/about/earchive.html" NDATA html>
<!ENTITY kbcoopbibliopoliscongresamse SYSTEM "http://www.kb.nl/coop/bibliopoliscongres/amse.html" NDATA html>
<!ENTITY kbresourcesframesetkbpers2003kbkapen SYSTEM "http://www.kb.nl/kb/resources/frameset_kb.html?/kb/pr/pers/pers2003/kb-kap-en.html" NDATA html>
<!ENTITY ibmnldiaspreservation SYSTEM "http://www-5.ibm.com/nl/dias/preservation.html" NDATA html>
<!ENTITY iflaIVifla69papers128eAbramsSeaman SYSTEM "http://www.ifla.org/IV/ifla69/papers/128e-Abrams_Seaman.pdf" NDATA html>
<!ENTITY oclcresearchprojectspmwg SYSTEM "http://www.oclc.org/research/projects/pmwg/" NDATA html>
<!ENTITY digitalpreservation SYSTEM "http://www.digitalpreservation.gov/" NDATA html>
<!ENTITY nyplresearchlpaonline SYSTEM "http://www.nypl.org/research/lpa/online.html" NDATA html>
<!ENTITY westnetconsumable SYSTEM "http://www.westnet.com/consumable" NDATA html>
<!ENTITY apeculture SYSTEM "http://www.apeculture.com" NDATA html>
<!ENTITY musejhujournalsthedramareview SYSTEM "http://muse.jhu.edu/journals/the_drama_review" NDATA html>
<!ENTITY sscmjscmpressuiucjscmv1no1editorsnote SYSTEM "http://sscm-jscm.press.uiuc.edu/jscm/v1/no1/editors_note.html" NDATA html>
<!ENTITY backstage SYSTEM "http://www.backstage.com" NDATA html>
<!ENTITY downbeat SYSTEM "http://www.downbeat.com" NDATA html>
<!ENTITY nmzindex2 SYSTEM "http://www.nmz.de/index2.html" NDATA html>
<!ENTITY nmztaktlos SYSTEM "http://www.nmz.de/taktlos" NDATA html>
<!ENTITY dancingtimes SYSTEM "http://www.dancing-times.co.uk" NDATA html>
<!ENTITY leedsmusicinfocritmus SYSTEM "http://www.leeds.ac.uk/music/info/critmus/" NDATA html>
<!ENTITY cdnowmserverpagenameRPALLSTARmain SYSTEM "http://www.cdnow.com/cgi-bin/mserver/pagename=/RP/ALLSTAR/main.html" NDATA html>
<!ENTITY beatthief SYSTEM "http://www.beatthief.com" NDATA html>
<!ENTITY oobr SYSTEM "http://www.oobr.com" NDATA html>
<!ENTITY soundout SYSTEM "http://www.soundout.net" NDATA html>
<!ENTITY ntamaunimainzama SYSTEM "http://ntama.uni-mainz.de/~ama" NDATA html>
<!ENTITY informumdEdResNewslettersEthnoMusicology SYSTEM "http://www.inform.umd.edu/EdRes/ReadingRoom/Newsletters/EthnoMusicology" NDATA html>
<!ENTITY itpnyuGALLERYmusiclight SYSTEM "http://www.itp.nyu.edu/GALLERY/music_light.html" NDATA html>
<!ENTITY nmztaktlosindex SYSTEM "http://www.nmz.de/taktlos/index.shtml" NDATA html>
<!ENTITY danceheritage SYSTEM "http://www.danceheritage.org" NDATA html>
<!ENTITY friendsofphotography SYSTEM "http://www.friendsofphotography.org" NDATA html>
<!ENTITY actingbiz SYSTEM "http://www.actingbiz.com" NDATA html>
<!ENTITY artchive SYSTEM "http://www.artchive.com/artchive" NDATA html>
<!ENTITY aljadidabout SYSTEM "http://www.aljadid.com/about.html" NDATA html>
<!ENTITY nyfa SYSTEM "http://www.nyfa.org" NDATA html>
<!ENTITY liblatrobeAHR SYSTEM "http://www.lib.latrobe.edu.au/AHR/" NDATA html>
<!ENTITY ew SYSTEM "http://www.ew.com/ew/" NDATA html>
<!ENTITY nethungq SYSTEM "http://www.net.hu/hungq/" NDATA html>
<!ENTITY jendajournaljenda SYSTEM "http://www.jendajournal.com/jenda/" NDATA html>
<!ENTITY clasuflipsajournal SYSTEM "http://www.clas.ufl.edu/ipsa/journal/" NDATA html>
<!ENTITY shootthemessenger SYSTEM "http://www.shootthemessenger.com.au" NDATA html>
<!ENTITY westafricareviewvol12index12 SYSTEM "http://www.westafricareview.com/war/vol1.2/index1.2.htm" NDATA html>
<!ENTITY theballet SYSTEM "http://www.the-ballet.com" NDATA html>
<!ENTITY balletalert SYSTEM "http://www.balletalert.com" NDATA html>
<!ENTITY balletmagazine SYSTEM "http://www.ballet.co.uk/magazine/" NDATA html>
<!ENTITY ballettanz SYSTEM "http://www.ballet-tanz.de" NDATA html>
<!ENTITY bruneldeptspfabstjournal3no1journal31 SYSTEM "http://www.brunel.ac.uk/depts/pfa/bstjournal/3no1/journal3_1.htm" NDATA html>
<!ENTITY homesnafutarlo SYSTEM "http://home.snafu.de/tarlo/" NDATA html>
<!ENTITY criticaldance SYSTEM "http://criticaldance.com" NDATA html>
<!ENTITY dancemagazine SYSTEM "http://www.dancemagazine.com" NDATA html>
<!ENTITY danceinsider SYSTEM "http://www.danceinsider.com" NDATA html>
<!ENTITY danceonline SYSTEM "http://www.danceonline.com" NDATA html>
<!ENTITY dancespirit SYSTEM "http://dancespirit.com" NDATA html>
<!ENTITY danceteacher SYSTEM "http://www.dance-teacher.com" NDATA html>
<!ENTITY danceart SYSTEM "http://www.danceart.com" NDATA html>
<!ENTITY danceviewindex SYSTEM "http://www.danceview.org/index.html" NDATA html>
<!ENTITY msuuserokumurak SYSTEM "http://www.msu.edu/user/okumurak/" NDATA html>
<!ENTITY dancesport SYSTEM "http://www.dancesport.uk.com" NDATA html>
<!ENTITY noviajlwelectric SYSTEM "http://www.novia.net/~jlw/electric/electric.html" NDATA html>
<!ENTITY webspanhgpklm SYSTEM "http://www.webspan.net/~hgpklm/" NDATA html>
<!ENTITY istdnews SYSTEM "http://www.istd.org/news.html" NDATA html>
<!ENTITY pbmlindahllod SYSTEM "http://www.pbm.com/~lindahl/lod/" NDATA html>
<!ENTITY londondance SYSTEM "http://www.londondance.com" NDATA html>
<!ENTITY themorrisring SYSTEM "http://www.TheMorrisRing.org" NDATA html>
<!ENTITY folk SYSTEM "http://www.folk.org" NDATA html>
<!ENTITY pointemagazine SYSTEM "http://pointemagazine.com" NDATA html>
<!ENTITY websyrrsholmesmorrisrichindex SYSTEM "http://web.syr.edu/~rsholmes/morris/rich/index.html" NDATA html>
<!ENTITY salsaweb SYSTEM "http://www.salsaweb.com" NDATA html>
<!ENTITY thedonkey SYSTEM "http://www.thedonkey.org" NDATA html>
<!ENTITY sruti SYSTEM "http://www.sruti.com" NDATA html>
<!ENTITY sdballet SYSTEM "http://www.sdballet.com" NDATA html>
<!ENTITY tanznetz SYSTEM "http://www.tanznetz.de" NDATA html>
<!ENTITY voiceofdance SYSTEM "http://www.voiceofdance.org" NDATA html>
<!ENTITY africafilmtv SYSTEM "http://www.africafilmtv.com" NDATA html>
<!ENTITY libberkeleyMRCnewafricancinema SYSTEM "http://www.lib.berkeley.edu/MRC/newafricancinema.html" NDATA html>
<!ENTITY szsmakingfilminafrica SYSTEM "http://www.szs.net/making-film-in-africa/" NDATA html>
<!ENTITY filmkultura SYSTEM "http://www.filmkultura.hu" NDATA html>
<!ENTITY hnetmsuaflitweb SYSTEM "http://www2.h-net.msu.edu/~aflitweb/" NDATA html>
<!ENTITY artsuwaterlooFINEjuhdekinemahp SYSTEM "http://arts.uwaterloo.ca/FINE/juhde/kinemahp.htm" NDATA html>
<!ENTITY productionweekly SYSTEM "http://www.productionweekly.com" NDATA html>
<!ENTITY wpcmathfilmsindex SYSTEM "http://www.wpcmath.com/films/index.html" NDATA html>
<!ENTITY sensesofcinema SYSTEM "http://www.sensesofcinema.com" NDATA html>
<!ENTITY sithengi SYSTEM "http://www.sithengi.co.za" NDATA html>
<!ENTITY safilm SYSTEM "http://www.safilm.org.za" NDATA html>
<!ENTITY desiresstoryframe SYSTEM "http://desires.com/storyframe.html" NDATA html>
<!ENTITY fortunecitytinpanclapton843index2 SYSTEM "http://www.fortunecity.com/tinpan/clapton/843/index2.html" NDATA html>
<!ENTITY weltmusikiwalewaindex SYSTEM "http://weltmusik.de/iwalewa/index.htm" NDATA html>
<!ENTITY afromixindexen SYSTEM "http://www.afromix.org/index.en.html" NDATA html>
<!ENTITY albmuzika SYSTEM "http://www.albmuzika.com" NDATA html>
<!ENTITY allafricamusic SYSTEM "http://allafrica.com/music/" NDATA html>
<!ENTITY amadindafsnet SYSTEM "http://www.amadinda.fsnet.co.uk" NDATA html>
<!ENTITY amazingsingles SYSTEM "http://www.amazings.com/ingles.html" NDATA html>
<!ENTITY aorbasement SYSTEM "http://www.aorbasement.com" NDATA html>
<!ENTITY adem SYSTEM "http://www.adem.ch" NDATA html>
<!ENTITY aiem SYSTEM "http://www.aiem.org.au" NDATA html>
<!ENTITY geocitiesVienna3651 SYSTEM "http://www.geocities.com/Vienna/3651/" NDATA html>
<!ENTITY shefuniacademicIMmusstaffjsBJE SYSTEM "http://www.shef.ac.uk/uni/academic/I-M/mus/staff/js/BJE.html" NDATA html>
<!ENTITY budamusique SYSTEM "http://www.budamusique.com" NDATA html>
<!ENTITY chaoscontrol SYSTEM "http://www.chaoscontrol.com" NDATA html>
<!ENTITY sunsitekthfeastlibmrfyinyuetextsarticles SYSTEM "http://sunsite.kth.se/feastlib/mrf/yinyue/texts/articles.html" NDATA html>
<!ENTITY mitpress2ejournalsComputerMusicJournal SYSTEM "http://mitpress2.mit.edu/e-journals/Computer-Music-Journal/" NDATA html>
<!ENTITY coraconnection SYSTEM "http://www.coraconnection.com" NDATA html>
<!ENTITY cosmik SYSTEM "http://www.cosmik.com" NDATA html>
<!ENTITY hrdarkoetfet12 SYSTEM "http://www.hr/darko/etf/et12.html" NDATA html>
<!ENTITY crossrunews SYSTEM "http://cross.ru/news/" NDATA html>
<!ENTITY culturekiosque SYSTEM "http://www.culturekiosque.com" NDATA html>
<!ENTITY musiccolumbiacurmus SYSTEM "http://music.columbia.edu/~curmus/" NDATA html>
<!ENTITY descarga SYSTEM "http://www.descarga.com" NDATA html>
<!ENTITY dotmusic SYSTEM "http://www.dotmusic.com" NDATA html>
<!ENTITY scaahknltvmindex SYSTEM "http://sca.ahk.nl/tvm/index.html" NDATA html>
<!ENTITY humanasufprbrrem SYSTEM "http://www.humanas.ufpr.br/rem/" NDATA html>
<!ENTITY researchumbceduefhmeol SYSTEM "http://research.umbc.edu/efhm/eol.html" NDATA html>
<!ENTITY exclaim SYSTEM "http://www.exclaim.ca" NDATA html>
<!ENTITY unifrankfurtfb09muwiFZMw SYSTEM "http://www.uni-frankfurt.de/fb09/muwi/FZMw.html" NDATA html>
<!ENTITY instrumentsgearhead SYSTEM "http://www.1800instruments.com/gearhead.htm" NDATA html>
<!ENTITY gridface SYSTEM "http://www.gridface.com" NDATA html>
<!ENTITY aedvcstuberlinbrandeisindex SYSTEM "http://aedv.cs.tu-berlin.de/~brandeis/index.html" NDATA html>
<!ENTITY textfilesmagazinesHARDCORE SYSTEM "http://www.textfiles.com/magazines/HARDCORE/" NDATA html>
<!ENTITY hitmakers SYSTEM "http://www.hitmakers.com" NDATA html>
<!ENTITY dcommsarvariindex SYSTEM "http://www2.4dcomm.com/sarvari/index.html" NDATA html>
<!ENTITY archiveilamruhome SYSTEM "http://archive.ilam.ru.ac.za/home.asp" NDATA html>
<!ENTITY forumnetircamrubriquephp3idrubrique13 SYSTEM "http://forumnet.ircam.fr/rubrique.php3?id_rubrique=13" NDATA html>
<!ENTITY iuma SYSTEM "http://www.iuma.com" NDATA html>
<!ENTITY jazzguitar SYSTEM "http://www.jazzguitar.com" NDATA html>
<!ENTITY jazzusa SYSTEM "http://jazzusa.com" NDATA html>
<!ENTITY jellyroll SYSTEM "http://www.jellyroll.com" NDATA html>
<!ENTITY kulttuurivihkot8m SYSTEM "http://www.kulttuurivihkot.8m.com" NDATA html>
<!ENTITY laritmo SYSTEM "http://www.laritmo.com" NDATA html>
<!ENTITY mbira SYSTEM "http://www.mbira.org" NDATA html>
<!ENTITY zambukombirapagemintro SYSTEM "http://www.zambuko.com/mbirapage/m_intro.html" NDATA html>
<!ENTITY memimakers SYSTEM "http://www.memi.de/makers.php3" NDATA html>
<!ENTITY mi2n SYSTEM "http://www.mi2n.com" NDATA html>
<!ENTITY biuhumuimsMinad SYSTEM "http://www.biu.ac.il/hu/mu/ims/Min-ad/" NDATA html>
<!ENTITY musewelcomehtml SYSTEM "http://www.muse.ie/welcome.html" NDATA html>
<!ENTITY stokstadcyberspacecafemuseweek SYSTEM "http://www.stokstad.com/cyberspacecafe/museweek.html" NDATA html>
<!ENTITY researchumbceolMAindex SYSTEM "http://research.umbc.edu/eol/MA/index.htm" NDATA html>
<!ENTITY ghanawebGhanaHomePageghmusic SYSTEM "http://www.ghanaweb.com/GhanaHomePage/ghana/gh_music.html" NDATA html>
<!ENTITY themusicmagazine SYSTEM "http://www.themusicmagazine.com" NDATA html>
<!ENTITY scholarsnuslandowpostzimbabwemusiczmusicov SYSTEM "http://www.scholars.nus.edu.sg/landow/post/zimbabwe/music/zmusicov.html/" NDATA html>
<!ENTITY mustrad SYSTEM "http://www.mustrad.org.uk" NDATA html>
<!ENTITY multimaniamusicandindex SYSTEM "http://www.multimania.com/musicand/index.html" NDATA html>
<!ENTITY netmusik SYSTEM "http://www.netmusik.com" NDATA html>
<!ENTITY northernjourneycdnfolkjournalnjojcg SYSTEM "http://www.northernjourney.com/cdnfolk/journal/njojcg.html" NDATA html>
<!ENTITY notationmachine SYSTEM "http://www.notationmachine.com" NDATA html>
<!ENTITY ntamaunimainz SYSTEM "http://ntama.uni-mainz.de" NDATA html>
<!ENTITY ufsmalternet SYSTEM "http://www.ufsm.br/alternet/" NDATA html>
<!ENTITY choirandorganchoir SYSTEM "http://www.choirandorgan.com/choir.htm" NDATA html>
<!ENTITY stockholmmusicmuseumpan SYSTEM "http://stockholm.music.museum/pan/" NDATA html>
<!ENTITY popculturecorn SYSTEM "http://www.popculturecorn.com" NDATA html>
<!ENTITY progressionmagazine SYSTEM "http://progressionmagazine.com" NDATA html>
<!ENTITY indianaethmusicpublications SYSTEM "http://www.indiana.edu/~ethmusic/publications/publications.html" NDATA html>
<!ENTITY rembetikoclub SYSTEM "http://www.rembetiko.gr/club.htm" NDATA html>
<!ENTITY millersvresound SYSTEM "http://www.millersv.edu/~resound" NDATA html>
<!ENTITY rockbites SYSTEM "http://www.rockbites.com" NDATA html>
<!ENTITY rollingstone SYSTEM "http://www.rollingstone.com" NDATA html>
<!ENTITY iaspmrpm SYSTEM "http://www.iaspm.net/rpm/" NDATA html>
<!ENTITY gromcomusicrimarchive SYSTEM "http://gromco.com/music/rim_archive/" NDATA html>
<!ENTITY sibetrans SYSTEM "http://www.sibetrans.com" NDATA html>
<!ENTITY undsamus SYSTEM "http://www.und.ac.za/und/samus/" NDATA html>
<!ENTITY musikuussmstmonline SYSTEM "http://www.musik.uu.se/ssm/stmonline/" NDATA html>
<!ENTITY chandrakanthatablasite SYSTEM "http://chandrakantha.com/tablasite/" NDATA html>
<!ENTITY techno SYSTEM "http://www.techno.de" NDATA html>
<!ENTITY themusicimmindex SYSTEM "http://www.themusic.com.au/im_m/index.html" NDATA html>
<!ENTITY turkishmusic SYSTEM "http://www.turkishmusic.org" NDATA html>
<!ENTITY artsusyddepartsperformPUBLICATIONScontactdepartment SYSTEM "http://www.arts.usyd.edu.au/departs/perform/PUBLICATIONS/contact%20department.html" NDATA html>
<!ENTITY siciliateatro SYSTEM "http://www.siciliateatro.org" NDATA html>
<!ENTITY wmichcompdrindex SYSTEM "http://www.wmich.edu/compdr/index.html" NDATA html>
<!ENTITY curtainup SYSTEM "http://www.curtainup.com" NDATA html>
<!ENTITY dramamagazine SYSTEM "http://www.dramamagazine.co.uk" NDATA html>
<!ENTITY dramatistsguilddocdrama SYSTEM "http://www.dramatistsguild.com/doc/drama.htm" NDATA html>
<!ENTITY infozinemirrortheatre SYSTEM "http://www.infozine.com/mirror/theatre/" NDATA html>
<!ENTITY eoneilllibrarynewsletterindex SYSTEM "http://www.eoneill.com/library/newsletter/index.htm" NDATA html>
<!ENTITY galatealetvu SYSTEM "http://galatea.let.vu.nl" NDATA html>
<!ENTITY georgecoates SYSTEM "http://www.georgecoates.org" NDATA html>
<!ENTITY webgccunyMESTCjadt SYSTEM "http://web.gc.cuny.edu/MESTC/jadt.htm" NDATA html>
<!ENTITY ucdirthfrm SYSTEM "http://www.ucd.ie/~irthfrm/" NDATA html>
<!ENTITY researchhaifatheatrejtd SYSTEM "http://research.haifa.ac.il/~theatre/jtd.html" NDATA html>
<!ENTITY londontheatremembersbackissuesnewsletters SYSTEM "http://www.londontheatre.co.uk/members/backissuesnewsletters.htm" NDATA html>
<!ENTITY pressjhupressjournalspaj SYSTEM "http://www.press.jhu.edu/press/journals/paj/paj.html" NDATA html>
<!ENTITY hypergraphiapendulo0teat SYSTEM "http://www.hypergraphia.com/pendulo/0teat.html" NDATA html>
<!ENTITY performanceartpagesindex SYSTEM "http://www.performance-art.org/pages/index.cfm" NDATA html>
<!ENTITY plasamedialsi SYSTEM "http://http://www.plasa.org/media/lsi/" NDATA html>
<!ENTITY homeeolprops SYSTEM "http://home.eol.ca/~props/" NDATA html>
<!ENTITY plattevilletheatrepctpubd SYSTEM "http://www.plattevilletheatre.org/pctpubd.htm" NDATA html>
<!ENTITY wwwusersimaginetchauveausomm SYSTEM "http://wwwusers.imaginet.fr/~chauveau/somm.html" NDATA html>
<!ENTITY lbororesearchscenography SYSTEM "http://www.lboro.ac.uk/research/scenography/" NDATA html>
<!ENTITY stagedirections SYSTEM "http://www.stage-directions.com" NDATA html>
<!ENTITY thestage SYSTEM "http://www.thestage.co.uk" NDATA html>
<!ENTITY artsjournal SYSTEM "http://www.artsjournal.com" NDATA html>
<!ENTITY dancingtimesballroomdt SYSTEM "http://www.dancing-times.co.uk/ballroomdt.html" NDATA html>
<!ENTITY sideline SYSTEM "http://www.side-line.com" NDATA html>
<!ENTITY researchumbcefhmcambodiaindex SYSTEM "http://research.umbc.edu/efhm/cambodia/index.htm" NDATA html>
<!ENTITY danceadvanceindex2 SYSTEM "http://www.danceadvance.org/index2.html" NDATA html>
<!ENTITY danceeurope SYSTEM "http://www.danceeurope.net" NDATA html>
<!ENTITY danceexpressionmag SYSTEM "http://www.danceexpressionmag.co.uk" NDATA html>
<!ENTITY danceonlineindex SYSTEM "http://www.danceonline.com/index.html" NDATA html>
<!ENTITY danceview SYSTEM "http://www.danceview.org" NDATA html>
<!ENTITY danz SYSTEM "http://www.danz.org.nz" NDATA html>
<!ENTITY onetellancashirefolk SYSTEM "http://web.onetel.net.uk/~lancashirefolk/" NDATA html>
<!ENTITY biglobeneballetstar SYSTEM "http://www2a.biglobe.ne.jp/~ballet/star.html" NDATA html>
<!ENTITY tanzoriental SYSTEM "http://www.tanzoriental.com" NDATA html>
<!ENTITY villagevoicedance SYSTEM "http://www.villagevoice.com/dance/" NDATA html>
<!ENTITY womenandperformance SYSTEM "http://www.womenandperformance.org" NDATA html>
<!ENTITY tomlibraryupenn SYSTEM "http://tom.library.upenn.edu/" NDATA html>
<!ENTITY aiima SYSTEM "http://www.aiim.org/pdf_a/" NDATA html>
<!ENTITY jstorabout SYSTEM "http://www.jstor.org/about/" NDATA html>
<!ENTITY lockss SYSTEM "http://www.lockss.org/" NDATA html>
<!ENTITY jstoraboutissues SYSTEM "http://www.jstor.org/about/issues/" NDATA html>
<!ENTITY sorosopenaccessread SYSTEM "http://www.soros.org/openaccess/read.shtml" NDATA html>
<!ENTITY dlibjune01reich06reich SYSTEM "http://www.dlib.org/dlib/june01/reich/06reich.html" NDATA html>
<!ENTITY jakedbdocsjakeoverviewserrev SYSTEM "http://jake-db.org/docs/jake-overview-serrev.pdf" NDATA html>
<!ENTITY tomlibraryupennpubsindex SYSTEM "http://tom.library.upenn.edu/pubs/index.html" NDATA html>
<!ENTITY openarchives SYSTEM "http://www.openarchives.org/" NDATA html>
<!ENTITY naturedebateseaccessArticlesrichardson SYSTEM "http://www.nature.com/nature/debates/e-access/Articles/richardson.html" NDATA html>
<!ENTITY sourceforgeprojectslockss SYSTEM "http://sourceforge.net/projects/lockss/" NDATA html>
<!ENTITY lockssstanford SYSTEM "http://lockss.stanford.edu" NDATA html>
<!ENTITY vreichstanford SYSTEM "mailto:vreich@stanford.edu" NDATA html>
<!ENTITY limewiredevelopergnutellaprotocol04 SYSTEM "http://www9.limewire.com/developer/gnutella_protocol_0.4.pdf" NDATA html>
<!ENTITY loccopyrightlegislationdmca SYSTEM "http://www.loc.gov/copyright/legislation/dmca.pdf" NDATA html>
<!ENTITY clirpubsreportspub107waters SYSTEM "http://www.clir.org/pubs/reports/pub107/waters.html" NDATA html>
<!ENTITY iupap SYSTEM "http://iupap.org" NDATA html>
<!ENTITY publishapsIUPAP SYSTEM "http://publish.aps.org/IUPAP/" NDATA html>
<!ENTITY oclcdigitalpreservation SYSTEM "http://www.oclc.org/digitalpreservation/" NDATA html>
<!ENTITY clirpubsissues25plan SYSTEM "http://www.clir.org/pubs/issues/issues25.html#plan" NDATA html>
<!ENTITY ukolnserviceselibpaperssupportingrept011 SYSTEM "http://www.ukoln.ac.uk/services/elib/papers/supporting/pdf/rept011.pdf" NDATA html>
<!ENTITY dlibjuly00eppard07eppard SYSTEM "http://www.dlib.org/dlib/july00/eppard/07eppard.html" NDATA html>
<!ENTITY iflaVIIs13frbr SYSTEM "http://www.ifla.org/VII/s13/frbr/frbr.htm" NDATA html>
<!ENTITY sunsiteberkeleymoa2wpv2 SYSTEM "http://sunsite.berkeley.edu/moa2/wp-v2.pdf" NDATA html>
<!ENTITY oclcresearchprojectspmwgpresmetawp SYSTEM "http://www.oclc.org/research/projects/pmwg/presmeta_wp.pdf" NDATA html>
<!ENTITY supportsciencedirecttectextsgml SYSTEM "http://support.sciencedirect.com/tectext_sgml.shtml" NDATA html>
<!ENTITY dublincoredocuments20000711dcmitypevocabulary SYSTEM "http://dublincore.org/documents/2000/07/11/dcmi-type-vocabulary/" NDATA html>
<!ENTITY elsevierhomepageaboutresprojtrmenu SYSTEM "http://www.elsevier.nl/homepage/about/resproj/trmenu.htm" NDATA html>
<!ENTITY supportsciencedirecttecindex SYSTEM "http://support.sciencedirect.com/tecindex.htm" NDATA html>
<!ENTITY kbcoopnedlibhomeflash SYSTEM "http://www.kb.nl/coop/nedlib/homeflash.html" NDATA html>
<!ENTITY oaidlibvtExploreroai11testoai SYSTEM "http://oai.dlib.vt.edu/cgi-bin/Explorer/oai1.1/testoai" NDATA html>
<!ENTITY allianceforlifelonglearning SYSTEM "http://www.allianceforlifelonglearning.org/" NDATA html>
<!ENTITY cmiyale SYSTEM "http://cmi.yale.edu/" NDATA html>
<!ENTITY archreq SYSTEM "http://www.diglib.org/preserve/archreq.htm" NDATA html>
<!ENTITY presjour SYSTEM "http://www.diglib.org/preserve/presjour.htm" NDATA html>
<!ENTITY pracshare SYSTEM "http://www.diglib.org/preserve/pracshare.htm" NDATA html>
<!ENTITY criteria SYSTEM "http://www.diglib.org/preserve/criteria.htm" NDATA html>
<!ENTITY criteria SYSTEM "http://www.diglib.org/preserve/criteria.htm" NDATA html>
<!ENTITY diglibpreservehadtdfs SYSTEM "http://www.diglib.org/preserve/hadtdfs.pdf" NDATA html>
<!ENTITY harvardsip10 SYSTEM "http://www.diglib.org/preserve/harvardsip10.pdf" NDATA html>
<!ENTITY lockssStanford SYSTEM "http://lockss.Stanford.edu" NDATA html>
<!ENTITY diglibpreservejisc0206 SYSTEM "http://www.diglib.org/preserve/jisc0206.htm" NDATA html>
<!ENTITY diglibpreserveharvard0206 SYSTEM "http://www.diglib.org/preserve/harvard0206.htm" NDATA html>
<!ENTITY diglibpreservestanford0206 SYSTEM "http://www.diglib.org/preserve/stanford0206.htm" NDATA html>
<!ENTITY ciaonet SYSTEM "http://www.ciaonet.org/" NDATA html>
<!ENTITY stke SYSTEM "http://www.stke.org" NDATA html>
<!ENTITY webbmitdspace SYSTEM "http://web.mit.edu/dspace" NDATA html>
<!ENTITY diglibpreservenyplprop101300 SYSTEM "http://www.diglib.org/preserve/nyplprop10-13-00" NDATA html>


]>
<TEI.2 id="CanJour">
<teiHeader type="aacr2">
<fileDesc>
<titleStmt>
<title type="245">Archiving Electronic Journals: Research Funded by the Andrew W. Mellon Foundation</title>
<title type="gmd">[electronic resource]
</title>
<author>
</author>
<editor>Cantara, Linda Miller, 1952-
</editor>
<respStmt>
<resp>
</resp>
<name>
</name>
<resp>Creation of machine-readable version:
</resp>
<name>Digital Library Federation, Council on Library and Information Resources
</name>
<resp>Conversion to TEI.2-conformant markup:
</resp>
<name>John Ivor Carlson, Digital Library Federation, Council on Library and Information Resources
</name>
</respStmt>
</titleStmt>
<extent>ca. 918 kilobytes
</extent>
<publicationStmt>
<publisher>Digital Library Federation, Council on Library and Information Resources
</publisher>
<pubPlace>Washington, D.C.
</pubPlace>
<availability>
<p>Publicly accessible
</p>
<p>copyright 2005, by the Digital Library Federation, Council on Library and Information Resources
</p>
</availability>
<date>2005
</date>
<idno type="url"></idno>
<idno type="isbn" n="DLF10"></idno>
<idno type="isbn" n="DLF13"></idno>
</publicationStmt>
<seriesStmt>
<p></p>
</seriesStmt>
<notesStmt>
<note>
</note>
</notesStmt>
<sourceDesc>
<biblFull>
<titleStmt>
<title>Archiving Electronic Journals: Research Funded by the Andrew W. Mellon Foundation
</title>
<title type="parallel">
</title>
<title level="m">
</title>
<author>
</author>
<editor>Cantara, Linda Miller, 1952-
</editor>
<respStmt>
<resp>
</resp>
<name>
</name>
</respStmt>
</titleStmt>
<editionStmt>
<p></p>
</editionStmt>
<extent>
</extent>
<publicationStmt>
<publisher>Digital Library Federation, Council on Library and Information Resources
</publisher>
<pubPlace>Digital Library Federation, Council on Library and Information Resources, 1755 Massachusetts Ave., NW, Suite 500, Washington, DC 20036
</pubPlace>
<date>2003
</date>
<idno type="callNo" n="LOC"></idno>
<idno type="callNo" n="Dewey"></idno>
<idno type="isbn" n="DLF10"></idno>
<idno type="isbn" n="DLF13"></idno>
<idno type="isbn" n="CLIR10"></idno>
<idno type="isbn" n="CLIR13"></idno>
</publicationStmt>
<seriesStmt>
<p></p>
</seriesStmt>
<notesStmt>
<note>
</note>
</notesStmt>
</biblFull>
</sourceDesc>
</fileDesc>
<encodingDesc>
<projectDesc>
<p>Prepared for the Digital Library Federation
</p>
</projectDesc>
<editorialDecl>
<p></p>
</editorialDecl>
<refsDecl>
<p></p>
</refsDecl>
<classDecl>
<taxonomy id="LCSH">
<bibl>
<title>Library of Congress Subject Headings
</title>
</bibl>
</taxonomy>
</classDecl>
</encodingDesc>
<profileDesc>
<creation>
<date>2003
</date>
</creation>
<langUsage>
<language id="eng">English
</language>
</langUsage>
<textClass>
<keywords>
<term>nonfiction
</term>
<term>prose
</term>
<term>feminine
</term>
<term>
</term>
</keywords>
<keywords scheme="LCSH">
<term type="Field650"></term>
</keywords>
</textClass>
</profileDesc>
<revisionDesc>
<change>
<date>7/2005
</date>
<respStmt>
<resp>corrector
</resp>
<name>John Ivor Carlson
</name>
</respStmt>
<item>Converted XHTML to tei-compliant XML.
</item>
</change>
</revisionDesc>
</teiHeader>
<text id="CanJourn">

<front>

<titlePage>
<docTitle>
<titlePart type="main">Archiving Electronic Journals <lb/>Research Funded by the Andrew W. Mellon Foundation</titlePart>
</docTitle>
<byline>Edited, with an Introduction, by Linda Cantara, Indiana University.
</byline>
<docImprint>
The Digital Library Federation <lb/>
Council on Library and Information Resources <lb/>
<pubPlace>Washington, DC.</pubPlace>
<date>2003</date>
</docImprint>
</titlePage>

<div1 type="abstract">
<p>Increasingly, scholarly journals are published electronically. What does it take to keep them accessible electronically in perpetuity? Can the property rights of publishers, the access responsibilities of libraries, and the reliability assurances that scholars need be reconciled in agreements to create archives of electronic journals? These series of studies examine various aspects of the challenges of archiving electronic journal content.</p>
</div1>

<div1 type="preface"><head>Preface</head>
<p>In early 2000, the DLF, CLIR, and CNI began to address these questions with a view to facilitating some practical experimentation in digital archiving. In a series of three meetings -- one each for librarians, publishers, and licensing specialists, respectively -- the groups managed to reach consensus on the <xref doc="diglibpreservecriteria">minimum requirements</xref> for e-journal archival repositories.</p>
<p>Building on that consensus,  <xref doc="mellon">The Andrew W. Mellon Foundation</xref> solicited proposals from selected research libraries to plan the development of e-journal repositories meeting those requirements. Seven major libraries received grants from the Andrew W. Mellon Foundation, including the New York Public Library and the university libraries of Cornell, Harvard, MIT, Pennsylvania, Stanford, and Yale.</p>
<p>Yale, Harvard, and Pennsylvania worked with individual publishers on archiving the range of their electronic journals. Cornell and the New York Public Library worked on archiving journals in specific disciplines. MIT's project involved archiving "dynamic" e-journals that change frequently, and Stanford's involved the development of specific archiving software tools.</p>
</div1>

</front>
<body>

<div1 type="section" n="01">
<head>Introduction</head>
<p>Scholarly research and communication depend upon perpetual access to the published scholarship of the past. Before the advent of electronic journals, research libraries subscribed to printed journals, provided access to, and preserved these bibliographic resources in continual support of the research, teaching, and learning needs of their constituent communities. The introduction of electronic journals has transformed scholarly communication in extraordinary ways  --  making it possible to disseminate research results more quickly, to provide hyperlinked access to cited publications, and to amplify text with images, audio and video files, datasets and software  --  but it has also created a dilemma for libraries which now license access to rather than own the journals to which they subscribe. Clearly, a model of collaboration involving scholars, publishers, and librarians is required to ensure that the e-scholarship of today will be accessible to researchers of the future.</p>
<p>The seminal report on digital preservation, <hi rend="italics">Preserving Digital Information: Report of the Task Force on Archiving of Digital Information</hi>, commissioned by the Commission on Preservation and Access (now the Council on Library and Information Resources) and the Research Libraries Group (RLG) in 1994 and published in 1996, issued the following list of major findings that have served as the guidelines for more recent research:<note target="intro01">[1]</note></p>

<list>
<item>The first line of defense against loss of valuable digital information rests with the creators, providers, and owners of digital information.</item>
<item>Long-term preservation of digital information on a scale adequate for the demands of future research and scholarship will require a deep infrastructure capable of supporting a distributed system of digital archives.</item>
<item>A critical component of the digital archiving infrastructure is the existence of a sufficient number of trusted organizations capable of storing, migrating, and providing access to digital collections.</item>
<item>A process of certification for digital archives is needed to create an overall climate of trust about the prospects of preserving digital information.</item>
<item>Certified digital archives must have the right and duty to exercise an aggressive rescue function as a fail-safe mechanism for preserving valuable digital information that is in jeopardy of destruction, neglect, or abandonment by its current custodian.<note target="intro02">[2]</note></item>
</list>

<p>Equally influential in the development of digital archiving strategies has been the <hi rend="italics">Reference Model for an Open Archival Information System (OAIS)</hi>, an initiative of the Consultative Committee for Space Data Systems (CCSDS) which began in 1995.<note target="intro03">[3]</note> The OAIS Reference Model is the conceptual framework for virtually all international digital archiving efforts,<note target="intro04">[4]</note> including the seven e-journal archiving planning projects funded by the Andrew W. Mellon Foundation and reported in this publication.</p>
<p>In October 1999, the Council on Library and Information Resources (CLIR), the Digital Library Federation (DLF), and the Coalition for Networked Information (CNI) convened a group of publishers and librarians to discuss responsibility for archiving the content of electronic journals.<note target="intro05">[5]</note> A series of meetings led to the publication in May 2000 of the document, "Minimum Criteria for an Archival Repository of Digital Scholarly Journals" (Version 1.2).<note target="intro06">[6]</note> Soon after, the Andrew W. Mellon Foundation solicited proposals for one-year e-journal archiving planning projects which would incorporate the minimum criteria outlined in this document. Seven institutions were awarded grants for projects carried out from January 2001 through early 2002: the libraries of Cornell University, Harvard University, Massachusetts Institute of Technology (MIT), Stanford University, the University of Pennsylvania, and Yale University, and the New York Public Library (NYPL). Cornell and the NYPL took a subject-based approach, with Cornell addressing issues related to agricultural journals and the NYPL addressing those related to electronic resources in the performing arts. Harvard, Pennsylvania, and Yale took a publisher-based approach: Harvard worked with Blackwell Publishing, the University of Chicago Press, and John Wiley &amp; Sons; Pennsylvania worked with Oxford and Cambridge; and Yale worked with Elsevier Science. MIT investigated the issues presented by "dynamic" e-journals, that is, those in which the content changes frequently,<note target="intro07">[7]</note> while Stanford focused on the development of tools to facilitate local caching of e-journal content. While the approach of each library was unique, a number of key issues were addressed by all:</p>

<div2 type="subsection" n="01">
<head>Development of sustainable economic and business models</head>

<p>As Brian Levoie recently noted, "preservation objectives must be aligned with the incentives for relevant decision-makers to carry them out."<note target="intro08">[8]</note> In the case of e-journals, the "relevant decision-makers" include authors, publishers, and librarians. Although the grantees propose several economic models  --  from charging authors an archiving fee upon publication, to setting up endowments to ensure perpetual funding, to charging publishers for archiving services (charges which would undoubtedly be passed on to subscribers), to charging libraries for access to archived content  --  no one means of financing digital archiving of e-journals was identified, and in fact, a combination of funding models will most likely be required. Further, whereas smaller publishers have a strong incentive to have their electronic content archived, larger commercial publishers are reluctant to provide potential archives unrestricted access to their electronic content, fearing loss of control over presentation as well as loss of future revenues.<note target="intro09">[9]</note> On the other hand, libraries are reluctant to delegate e-journal archiving to publishers alone for fear that bankruptcies or mergers or simply a publisher's decision that it is no longer economically beneficial to support a particular journal could result in loss of access to the scholarly record. In addition, as Donald Waters has noted, "the concern about the viability of publisher-based archives is whether the material is in a preservable format and can endure outside the cocoon of the publisher's proprietary system."<note target="intro10">[10]</note> Nevertheless, although research libraries and their constituents would be the beneficiaries of e-journal archives (and thus, have a strong incentive to archive e-journals), the grantees almost unanimously acknowledge that the costs of long-term archiving  --  which are still unknown, given rapid changes in technology  --  cannot be assumed by individual libraries on behalf of the wider library community.</p>
</div2>

<div2 type="subsection" n="02"><head>Identification of what should be archived</head>
<p>The grantees had considerable differences of opinion concerning what should be archived, ranging from the "look and feel" of original e-journal issues to bit-stream-only preservation. Whereas Stanford's LOCKSS project focused on caching Web pages, other grantees outlined protocols for requesting that publishers deposit SGML/XML source files and the document type definitions (DTDs) required to validate them. Also addressed was specific content that should or could be archived as well as the range of file formats anticipated and supportable. In addition, nearly all the reports discuss the need for metadata, both publisher-provided and archive-created, for ingesting, documenting, maintaining, and accessing archived materials.</p>
</div2>

<div2 type="subsection" n="03"><head>Guidelines for accessing e-journal archives</head>
<p>One of the most controversial issues addressed by the grantees concerned when and how archived journals might be accessed. Debate over what constitutes a "trigger event," that is, a predefined occurrence that would permit an archive to disseminate content, remained unresolved. Nearly all suggested a JSTOR-like "moving wall"<note target="intro11">[11]</note> as a potential trigger event, but many publishers were reluctant to agree to permit access until after a resource had no more commercial viability. Equally uncertain was the question of whether an archive should be "dark," that is, one that allows no access for routine scholarly use, or "light," that is, fully accessible.</p>
</div2>

<div2 type="subsection" n="04"><head>Recent Developments</head>
<p>When available, each report in this publication is followed by a brief postscript on related activities in-progress since the submission of the final report. Meanwhile, the Mellon Foundation has provided development funding for two projects which take two very different approaches to e-journal archiving, Stanford's LOCKSS project and JSTOR's Electronic-Archiving Initiative.</p>
<p>As outlined in Stanford's report, LOCKSS (Lots of Copies Keep Stuff Safe) uses low-cost tools to crawl the Web to cache "redundant, distributed, decentralized" e-journal presentation files for which a library has a subscription or license. LOCKSS supports the traditional model whereby individual libraries build and maintain local collections of journals, and work is underway to develop a user interface for local collection management of e-journals cached using the LOCKSS system. A LOCKSS Alliance of participating libraries has been formed and the system is currently in beta test mode.<note target="intro12">[12]</note></p>
<p>Taking a different approach, the JSTOR Electronic-Archiving Initiative is focusing, among other things, on preservation of publishers' source files. As Eileen Fenton, Executive Director of the Initiative reports:</p>
<q><p>As the academic and publishing communities have moved into the twenty-first century with ever-increasing reliance on digital content, the infrastructure for preserving this content has not yet been created. Recognizing that establishing a production-level archiving system is a matter of increasing importance, JSTOR, with support from the Andrew W. Mellon Foundation, has launched the Electronic-Archiving Initiative. Known informally as "E-Archive," the mission of this Initiative is the long-term preservation of and access to electronic scholarly resources.  The goal is to develop all of the technical and organizational infrastructure elements necessary to ensure the longevity of important scholarly e-resources. At a practical level this includes developing a business model that can support the ongoing work of the archive; establishing relations with producers of electronic content, with librarians, and with scholars; and developing the technical and content management infrastructure necessary to support a trusted archive of electronic materials.</p>
<p>Currently E-Archive is engaged in collaborative discussions with publishers and libraries and is focused on developing a sustainable business model and a prototype archive.  E-Archive has also launched a study of the economic impact increasing reliance on e-journals is having on library periodical operations.  This study, which focuses on the non-subscription costs of print versus electronic periodicals, is nearing completion, and the findings are expected to be available for broad distribution in late 2003.<note target="intro13">[13]</note></p></q>
<p>The Mellon Foundation's support for two very different approaches to e-journal archiving is based on acknowledgment that "overlapping and redundant archiving solutions under the control of different organizations with different interests and motives in collecting offer the best hope for preserving digital materials...It would be unwise at the outset to expect that only one approach would be sufficient."<note target="intro14">[14]</note> Noteworthy e-journal archiving approaches and developments initiated since the submission of the final reports in this publication include the following:</p>

<list>
<item>In cooperation with IBM Global Services, the Koninklijke Bibliotheek (KB), the National Library of the Netherlands, has developed a large-scale Digital Information Archiving System (DIAS). In August 2002, the KB became the first official digital archive for Elsevier Science e-journals; in May 2003, the KB also signed a long-term digital archiving agreement with Kluwer Academic Publishers.<note target="intro15">[15]</note></item>
<item>In June 2003, the National Library of Medicine (NLM) announced the public domain availability of a Journal Archiving and Interchange Document Type Definition (JAIDTD) for publishing online articles. If widely adopted, the JAIDTD would considerably streamline the process of archiving e-journals.<note target="intro16">[16]</note></item>
</list>

<p>In related digital preservation activities, work is underway to develop a global digital format registry to provide finer granularity of format typing than the current MIME Media Types registry provides, and to standardize representation information about document formats.<note target="intro17">[17]</note> In addition, OCLC Research and RLG have formed a new working group which will build on their previous research to develop recommendations and best practices for implementing preservation metadata. The projected time frame for the PREMIS (PREservation Metadata: Implementation Strategies) working group's activities is twelve months (June 2003-June 2004).<note target="intro18">[18]</note> And, in December 2002, the United States Congress approved funding for the National Digital Information Infrastructure and Preservation Program (NDIIPP), a collaborative project under the leadership of the Library of Congress to develop an infrastructure for the collection and preservation of digital materials. The first of three calls for proposals was announced in August 2003, for projects to begin in early 2004.<note target="intro19">[19]</note></p>
<p>The seven Andrew W. Mellon Foundation e-journal archiving planning project reports in this publication represent a significant body of research upon which future endeavors to ensure long-term access to the electronic scholarly record will build. For their efforts to identify, develop, and test the archival practices and tools that will facilitate long-term preservation of and access to electronic journals, the scholarly community owes many thanks to the seven institutions that carried out the projects, to the Digital Library Federation (DLF) and the Coalition for Networked Information (CNI) for initiating discussion of the issues, and to the Andrew W. Mellon Foundation for providing the funds necessary to accomplish the required research.</p>
<p>Linda Cantara <lb/>Indiana University, Bloomington <lb/>October 2003</p>
</div2>

<div2 type="subsection" n="05"><head>Endnotes</head>
<note id="intro01">[1] For example, see RLG-OCLC Working Group on Digital Archive Attributes, <hi rend="italics">Trusted Digital Repositories: Attributes and Responsibilities</hi>, An RLG-OCLC Report (Mountain View, CA: Research Libraries Group, May 2002), online at <xref doc="rlglongtermrepositories">http://www.rlg.org/longterm/repositories.pdf</xref>; and OCLC-RLG Working Group on Preservation Metadata, <hi rend="italics">Preservation Metadata and the OAIS Information Model: A Metadata Framework to Support the Preservation of Digital Objects</hi> (Dublin, OH: OCLC Online Computer Library, June 2002), online at <xref doc="oclcresearchprojectspmwgpmframework">http://www.oclc.org/research/projects/pmwg/pm_framework.pdf</xref>.</note>
<note id="intro02">[2] John Garrett and Donald Waters, co-chairs, <hi rend="italics">Preserving Digital Information: Report of the Task Force on Archiving of Digital Information</hi>, The Commission on Preservation and Access and The Research Libraries Group, 1 May 1996, 40. Online at <xref doc="ftprlgpubarchtffinalreport">ftp://ftp.rlg.org/pub/archtf/final-report.pdf</xref>.</note>
<note id="intro03">[3] Consultative Committee for Space Data Systems, <hi rend="italics">Reference Model for an Open Archival Information System (OAIS)</hi>, Blue Book, Issue 1, CCSDS 650.0-B-1/ISO 14721:2002 (January 2002). Online at <xref doc="wwwclassicccsdsdocumentsCCSDS6500B1">http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf</xref>. For an overview of the development of the OAIS Reference Model, see <xref doc="ssdoogsfcnasanostisoasoverview">http://ssdoo.gsfc.nasa.gov/nost/isoas/overview.html</xref>.</note>
<note id="intro04">[4] For example, see CEDARS (Curl Exemplars in Digital ARchives) at <xref doc="leedscedars">http://www.leeds.ac.uk/cedars/</xref>, NEDLIB (Networked European Deposit Library) at <xref doc="kbcoopnedlib">http://www.kb.nl/coop/nedlib/</xref>, and PADI (Preserving Access to Digital Information) at <xref doc="nlapadi">http://www.nla.gov.au/padi/</xref>.</note>
<note id="intro05">[5] See <xref doc="diglibpreservepresjour">http://www.diglib.org/preserve/presjour.htm</xref>.</note>
<note id="intro06">[6] Dan Greenstein and Deanna Marcum, "Minimum Criteria for an Archival Repository of Digital Scholarly Journals," Version 1.2 (Washington, DC: Digital Library Federation, 15 May 2000). Online at <xref doc="diglibpreservecriteria">http://www.diglib.org/preserve/criteria.htm</xref> and included as Appendix I of this publication.</note>
<note id="intro07">[7] For a discussion of e-journals as "dynamic collections of dynamic entities," see Patsy Baudoin, "Uppity Bits: Coming to Terms with Archiving Dynamic Electronic Journals," <hi rend="italics">The Serials Librarian</hi> 43:4 (2003), 63-72.</note>
<note id="intro08">[8] Brian Lavoie, <hi rend="italics">The Incentives to Preserve Digital Materials: Roles, Scenarios, and Economic Decision-Making</hi>, white paper published electronically by OCLC Research (Dublin, OH: OCLC Online Computer Library, April 2003). Online at <xref doc="oclcresearchprojectsdigipresincentivesdp">http://www.oclc.org/research/projects/digipres/incentives-dp.pdf</xref>.</note>
<note id="intro09">[9] This is a significant issue since the majority of commercial scholarly publications are produced by a very small number of publishers. For example, Maggie Jones of the Joint Information Systems Committee (JISC) recently reported that in 2002, 80 percent of the 5,025 journal titles licensed by JISC/NESLI (National Electronic Site Licensing Initiative) were from six publishers: Elsevier, Blackwells, Springer, Kluwer, Taylor &amp; Francis, and Wiley. See Maggie Jones, <hi rend="italics">Archiving E-Journals Consultancy: Final Report</hi>, report commissioned by the Joint Information Systems Committee (JISC), October 2003, 12. Online at <xref doc="jiscuploadeddocumentsejournalsfinal">http://www.jisc.ac.uk/uploaded_documents/ejournalsfinal.pdf</xref>.</note>
<note id="intro10">[10] Donald Waters, "Good Archives Make Good Scholars: Reflections on Recent Steps Toward the Archiving of Digital Information," <hi rend="italics">The State of Digital Preservation: An International Perspective</hi>, Conference Proceedings, Documentation Abstracts, Institute for Information Science, Washington, DC, 24-25 April 2002, Publication 107 (Washington, DC: Council on Library and Information Resources, July 2002), 86. Online at <xref doc="clirpubsreportspub107">http://www.clir.org/pubs/reports/pub107/pub107.pdf</xref>.</note>
<note id="intro11">[11] The "moving wall" is "the time period between the last issue available in JSTOR and the most recently published issue of a journal." See "JSTOR: The Moving Wall" at <xref doc="jstoraboutmovingwall">http://www.jstor.org/about/movingwall.html</xref>; see also, Roger C. Schonfeld, <hi rend="italics">JSTOR: A History</hi> (Princeton and Oxford: Princeton UP, 2003), 134-138.</note>
<note id="intro12">[12] For a discussion of the philosophical underpinnings of the LOCKSS model, see Michael A. Keller, Victoria A. Reich, and Andrew C. Herkovic, "What is a Library Anymore, Anyway?," <hi rend="italics">First Monday</hi> 8:5 (May 2003). Online at <xref doc="firstmondayissue85kellerindex">http://firstmonday.org/issues/issue8_5/keller/index.html</xref>.</note>
<note id="intro13">[13] Email correspondence from Eileen Fenton to author, 20 October 2003. See also "JSTOR: The Challenge of Digital Preservation and JSTOR's Electronic-Archiving Initiative" at <xref doc="jstoraboutearchive">http://www.jstor.org/about/earchive.html</xref>.</note>
<note id="intro14">[14] Waters, 89.</note>
<note id="intro15">[15] For more information, see Anne Katrien Amse, "Safeguarding the Historic Resources of the Future: Digital Archiving at the Dutch National Library," Parallel Session 3: Historical Resources of the Future, Bibliopolis Conference: The Future History of the Book, 7-8 November 2002, The Hague (Netherlands), Koninklijke Bibliotheek, online at <xref doc="kbcoopbibliopoliscongresamse">http://www.kb.nl/coop/bibliopoliscongres/amse.html</xref>; Johan F. Steenbakkers, "Permanent Archiving of Electronic Publications," <hi rend="italics">Serials</hi> 16:1 (March 2003), 33-36; Koninklijke Bibliotheek, "National Library of the Netherlands and Kluwer Academic Publishers Agree on Long-Term Digital Archiving," (19 May 2003), online at <xref doc="kbresourcesframesetkbpers2003kbkapen">http://www.kb.nl/kb/resources/frameset_kb.html?/kb/pr/pers/pers2003/kb-kap-en.html</xref>; and the IBM/KB Long-term Preservation Study Reports Series at <xref doc="ibmnldiaspreservation">http://www-5.ibm.com/nl/dias/preservation.html</xref>.</note>
<note id="intro16">[16] For more information, see the Postscript to Harvard University's report in this publication.</note>
<note id="intro17">[17] See Stephen L. Abrams and David Seaman, "Towards a Global Digital Format Registry," Meeting 165, Information Technology and Preservation and Conservation Workshop, World Library and Information Congress: 69th IFLA General Conference and Council, 1-9 August 2003, Berlin, Germany. Online at <xref doc="iflaIVifla69papers128eAbramsSeaman">http://www.ifla.org/IV/ifla69/papers/128e-Abrams_Seaman.pdf</xref>.</note>
<note id="intro18">[18] See <xref doc="oclcresearchprojectspmwg">http://www.oclc.org/research/projects/pmwg/</xref>.</note>
<note id="intro19">[19] See <xref doc="digitalpreservation">http://www.digitalpreservation.gov/</xref>.</note>
</div2>
</div1>

<div1 type="section" n="02"><head>Project Harvest: <lb/>A Report of the Planning Grant For the Design of a Subject-Based Electronic Journal Repository</head>
<p rend="center">Presented to <lb/>The Andrew W. Mellon Foundation</p>
<p rend="center">Submitted by Sarah E. Thomas <lb/>Principal Investigator <lb/>Carl A. Kroch University Librarian <lb/>Cornell University</p>
<p rend="center">1 September 2002</p>
<div2 type="subsection" n="01"><head>Introduction</head>
<p>In December 2000, in response to a call from the Mellon Foundation, the Cornell University Library received a grant to develop a plan for a repository of electronic journals in the field of agriculture. The Mellon Foundation recognized that solutions to the problem of preserving electronic journals can only be solved if done in cooperation with the publishers. From January 2001 through March 2002, the Cornell Mellon teamed worked together and with the project teams from the other Mellon planning grant recipients to deepen our knowledge of the digital archiving problems.</p>
<p>Project Harvest, as the project came to be known, built on Cornell's historic excellence in preservation in general and the preservation of agricultural literature in particular. During the course of the year we initiated a dialogue with a number of agriculture publishers with whom we have successfully cooperated on other projects. We sought to explore the conditions under which a publisher might be willing to participate in a subject-based repository. In addition, we surveyed specialists in the field of agricultural preservation in order to determine the requirements of librarians for digital archives. Finally, we spent much of the year exploring potential business models for a successful digital repository.</p>
</div2>

<div2 type="subsection" n="02"><head>Cornell University Library's Interest in Digital Preservation</head>
<p>Cornell niversity Library has traditionally invested heavily in preservation of all kinds. The Preservation program is one of the best in the nation, with a staff of thirty involved in a range of functions from fine restoration (four professional conservators and ten conservation technicians) to digital preservation where a staff of five is devoted to research and applications. In addition, Cornell has a special mandate to preserve agricultural materials in relation with the National Agricultural Library and the United States Agricultural Information Network (USAIN). Cornell's interest in research resources covers a very broad spectrum. In addition, we are interested in serving both the immediate and long-term user, and have served as a <hi rend="italics">de facto</hi> archive for content providers of all types.</p>
<p>In short, the Cornell University Library is deeply concerned with identifying and applying effective and efficient means for managing research resources, in avoiding redundancy/duplicative efforts, and in stabilizing materials to make them usable. This is easier when resources come on stable, eye-legible media such as animal skin, paper, palm leaf, even jade. It's more difficult when the medium contains the seeds of its own destruction, such as brittle paper, color transparencies, nitrate negatives. More modern media, such as videotape and sound recordings, have very short life expectancies. The problem is compounded when the media is dependent on a playback device which in turn may be subject to obsolescence. And, in the digital world, software dependency adds an additional layer of difficulty. The rate of obsolescence can be very fast  --  as short as a three-year window. Technological obsolescence is not the only problem in the digital world: more and more of the resources research libraries depend on are licensed, not physically owned. A recent survey of Digital Library Federation (DLF) members indicated that 40 percent of their expense for building digital libraries goes to licenses.</p>
<p>Like other digital materials, e-journals are at risk from ongoing technical, organizational, and economic changes. For these digital assets to remain usable and valuable over time, there must an explicit, recognized commitment to maintaining the integrity of and ensuring the long-term preservation of e-journals. A digital archive has a key role to play in this digital life cycle by serving as a trusted third party for the preservation of digital materials; by establishing a secure repository that complies with accepted preservation policies, procedures and standards; by identifying or adapting improved and appropriate preservation practices; by supporting efficient, economical long-term access that balances the potential of developing technologies with available resources and required revenues, as appropriate; and by providing a reliable, monitored, maintainable infrastructure.</p>
<p>Preservation is also closely aligned with trust. The more control over a source document you have, the greater the ability to exert preservation measures. Research libraries have built in redundancies in their physical collections with a good portion of collection overlap. This would be difficult to duplicate in the digital realm because so much material is licensed and to replicate a digital archive at each site would be prohibitively expensive. Thus, the idea of trusted digital archives comes into play.</p>
<p>Skepticism remains strong among research libraries and their constituencies. Very few research libraries have withdrawn hardcopy versions of materials accessible in digital form. A recent survey by JSTOR of 4,220 faculty across the country revealed there is a growing dependency on electronic resources but continuing skepticism about their long-term viability. Nearly 78 percent of respondents indicated that hard copy versions should be retained even if an effective digital preservation strategy were in place, while 97 percent of respondents indicated it was important for libraries, publishes, and other partners to archive, catalog, and protect electronic journals.</p>
<p>Given this background, the challenge facing the Project Harvest team was to identify what was needed to foster digital preservation. Specifically, we sought to determine if the time was yet ripe for the following:</p>

<list>
<item>Technical solutions that retained flexibility and some measure of reversibility.</item>
<item>Cost-effective solutions based on sustainable business and organizational models.</item>
<item>The establishment of third-party archives that would be trusted by publishers, users, and libraries. The goal would be for Cornell to archive agriculture e-journals in a way that would obviate the need for other research libraries to do so. Furthermore, scholars and others would trust the arrangement.</item>
<item>The definition of an archiving solution that is verifiable and auditable.</item>
</list>

</div2>

<div2 type="subsection" n="03"><head>The Nature of the Digital Archives</head>
<div3 type="part" n="01"><head>Levels of Access</head>
<p>Much of the first part of the year was devoted to an internal discussion of the nature of the digital archive that Cornell would be willing to maintain. Two potential models on a broad spectrum of possibilities were identified:</p>

<list>
<item>"Dark" archive  --  A "dark" digital archive would be a closed repository that would strictly control individual and/or organizational access to the information stored under its control. Bits would be preserved in the event that the publisher no longer could provide access to the journal. The primary function of the archive would be as a fail-safe bit repository.</item>
<item>"Light" archive  --  Conversely, a "light" archive would be a repository that would allow individual and/or organizational access to the information stored within. Access to the content of any of these options may be subject to access restrictions agreed upon by the publisher and the archive. Nevertheless, access under some circumstances would be presumed, and an access system would have to be maintained.</item>
</list>

<p>As we worked through business models in parallel with our discussion on the level of appropriate access, we came to see that the response to these issues would drive the design and organization of the entire repository. Our initial analysis, for example, suggested that a dark archive would be less expensive to build and maintain, but it also removed any potential short-term sources of funding. The contents of the archive would only become of value if the material were no longer available from the publisher. A light archive might be able to sustain itself as a secondary means of access to the content. In addition, regular access to the content in the archive would ensure the material was still usable. (A dark archive, conversely, would need elaborate systems to ensure bit integrity was maintained.) The light archive, however, would have much higher development and maintenance costs since in addition to storing and migrating data as with the dark archive, an access, retrieval, and authentication system would have to be maintained.</p>
<p>In the end, we concluded that Cornell should consider maintaining a dark archive when an appropriate business case can be made  --  namely, when someone is willing to subsidize the costs associated with maintaining a bit archive. The bulk of the Cornell University Library's efforts, however, should be devoted to developing and sustaining a light archive for public access with operational parameters to be set through discussion with its publishing partners. The nature and degree of access will have to be specified in agreements with our publisher partners and users.</p>
</div3>

<div3 type="part" n="02"><head>Factors to Consider in the Development of an Accessible Archive</head>
<p>CUL believes the following parameters are significant:</p>

<list>
<item>The user must have clearly defined use of the intellectual content of an electronic journal.</item>
<item>Time constraints to access should be lifted with a "moving wall" similar to the JSTOR model.</item>
<item>All information must be searchable by common metadata terms: author, title, publication, keyword, etc.</item>
<item>Information retrieval should be defined at a common granular level. At the least, a user should be able to search and retrieve information at the article level. Also, the user must be able to browse different levels of aggregation including article, issue, volume, and title.</item>
<item>Access must be assured following changes in publishing organization ownership.</item>
</list>

</div3>

<div3 type="part" n="03"><head>The Subject-Based Digital Archives Approach</head>
<p>The course of this discussion led two team members to develop the distinctions further in a draft white paper on the Subject-Based Digital Archives (SBDA) Approach. A preliminary report on this analysis was presented at the Fall 2001 DLF Forum.</p>
<p>Most of the other Mellon project recipients did their planning around building archives for specific publishers. The Publisher-Based Digital Archives (PBDA) approach focuses on the distinctiveness of each publisher/journal. The SBDA approach, however, would stress the commonality of content across the full publishing spectrum (and beyond). Commonality supports and encourages access, increased access promotes buy-in from content controllers and creators, buy-in further increases access, and revenue from access can be fed back into preservation. One way it does this is by extending the "dark/light" dichotomy to metadata as well. It recognizes that one can have dark metadata with dark data; light metadata with light data; light metadata with dark data; and light metadata with no data. The actual scenario will depend upon the publisher. In certain cases, the ability to search the light metadata alone may generate enough revenue to support the maintenance of the archival system. The SBDA scenario may have important implications for preservation as well.</p>
<p>Developed as a straw man during the course of the project, the SBDA scenario held enough promise to warrant further work. The idea is being further developed in a report for the Council on Library Information Resources (CLIR).</p>
</div3>

<div3 type="part" n="04"><head>Business Model Development</head>
<p>Ongoing funding for any digital archive must be predictable and also flexible enough to address future changes within the partnership. Early on in the project we recognized that CUL and its partners would have to take an active role in establishing alternative funding sources which might include access fees, grant funding, and endowment support.</p>
<p>As the project evolved, it became clearer to us that the development and maintenance of a digital repository that would meet the requirements of developing archival standards  --  including the OAIS Reference Model<note target="harvest01">[1]</note> and the RLG-OCLC report, <hi rend="italics">Trusted Digital Repositories</hi><note target="harvest02">[2]</note>  --  would be expensive. The design and preparation of the system would be one of many costs. As we learned from our partners working on Project Euclid, a math journal publishing project, the ingest of complex digital objects requires a degree of manual oversight and processing. In the absence of an acceptable technical model for an archive, however, it became impossible to accurately determine cost models.</p>
<p>The development of technical solutions for the archive was an essential prerequisite for our business planning. The technical model itself, however, needed to be shaped by business needs: the best technical model in the world would not be acceptable if there was not a business plan that could support it. This chicken-and-egg conundrum was one the project never successfully solved.</p>
</div3>

<div3 type="part" n="05"><head>Metadata</head>
<p>Metadata is a broadly used term. "Descriptive" metadata records the content of a digital object, "structural" metadata records the structural information about a data object, and "administrative" metadata records the maintenance of the digital object. Users, archive managers, and archive auditors require metadata of all three kinds. CUL and the partners will need to share metadata for the archive via a common interpretation of an established standard. It became apparent to us during the course of the project that these metadata protocols will need to be implemented at Cornell in collaboration with other electronic journal projects such as Project Euclid. As necessary, the archive will modify metadata for local implementation, which may supersede proprietary metadata. In the long term, metadata costs for the archive must be minimized, and it would be expected that the publisher partners would efficiently accommodate metadata modifications adopted by the archival community. The project would adopt content creation policies to capture requisite metadata.</p>
</div3>

<div3 type="part" n="06"><head>Preservation formats</head>
<p>It is possible the archive could store two formats: a publisher's proprietary format for typesetting or publication and an archival format with the emphasis on intellectual content. CUL, in consultation with its partners and other archives, came to believe ultimately that an acceptable archival format is highly desirable. A common format should encourage uniform archiving protocols and reduce the administrative overhead of the archive. Ultimately, it is expected the partners will submit files to the repository already in a preservation format, reducing costs and errors associated with data conversion. The archive will provide a reasonable time for partners to achieve a coordination of formats with a goal of three years. One of the most successful parts of the planning year grant, therefore, was the dialogue that was started with Harvard and the National Library of Medicine on the design of an Archival Information Package (AIP).</p>
</div3>
</div2>

<div2 type="subsection" n="04"><head>Work with Publishers</head>
<p>With these general guidelines in mind, the project then turned to a group of publishers to determine their perspectives on third-party subject-based archives. A meeting with a group of publishers was held in Washington, D.C. in September 2001. Representatives from the American Dairy Science Association, Academic/Elsevier, the American Phytopathological Society, BioOne, CABI, NRC-Canada, Wiley, the National Agricultural Library, and USAIN met with members of the Project Harvest team to discuss the issues the team had investigated on its own.</p>
<p>At the meeting we identified a number of incentives that might encourage a publisher to arrange for the maintenance of its journals in a third-party repository. These included:</p>

<list>
<item>Protection of assets, especially if the material has continuing value as it ages</item>
<item>Low additional overhead for the publisher</item>
<item>Customer satisfaction</item>
<item>Potential advertisement for their materials</item>
</list>

<p>At the meeting we learned that all the publishers in attendance intend to establish their own archives. They saw themselves shifting from focusing on the currency of their content to developing databases of content of continuing value. Retrospective runs of journals which in the past they had been happy to leave in the hands of libraries become instead a potential source of new revenues. Much of the discussion centered on exactly what needed to be archived, and it became apparent that the publishers by and large were much less concerned about preserving the "artifactual" nature of the electronic document than about ensuring that meaningful content is carried forward.</p>
<p>It was clear during the course of the meeting that the publishers and the librarians in attendance had different perceptions concerning who should be responsible for digital preservation. Librarians, as the survey (Appendix E) revealed, want trusted third-party archiving. The publishers seemed unaware that some of their customers do not believe that the publishers alone safeguard materials.</p>
<p>Given their assumption that they would be archiving material in order to support their own revenue streams, publishers saw little need to pay to support a third-party archive. Likewise, given their interest in potential new revenue streams from retrospective holdings, the publishers were not enthusiastic about "light" archives. A few would consider the possibility if revenue generated was returned to the publisher.</p>
<p>The good news was that on a technical level there appeared to be a real convergence in formats, with all of the publishers moving to an SGML-based publishing system. Many were unwilling to share the Document Type Definition (DTD) that they use  --  in some cases because of anti-trust concerns  --  but all seemed willing to consider developing as an output from their system an AIP- or SIP-formatted document<note target="harvest03">[3]</note>  --  assuming we can come to some sort of agreement about what each would contain.</p>
<p>An important part of all discussions of dark archives is consideration of what trigger events might move content from a dark archive into the open. The publishers were unable to come to any common agreement over what might constitute a trigger event. Some acknowledged that the passage of time might be one such trigger event, but they were thinking in terms of centuries, not the relatively short periods that are normally discussed.</p>
</div2>

<div2 type="subsection" n="05"><head>Librarians' Perceptions</head>
<p>It became clear to the team early on in the project that if were to develop a repository that was to be trusted by other librarians and scholars, we would need to know more about what that community expected from such an archive. We therefore conducted a survey of preservation officers at USAIN and Land Grant institutions. The survey form is found in Appendix E.</p>
<p>The results of the survey were most revealing. Among the findings were:</p>

<list>
<item>45 percent of respondents indicated the need for both print and electronic copies of journals</item>
<item>55 percent of respondents indicated that e-journal already substitute for print</item>
<item>84 percent of respondents would cancel print if a trustworthy and reliable archive existed</item>
</list>

<p>When asked if they had detected a difference in content between print and electronic journals, 22 percent said they had noticed a difference, an equal percent said they had not noticed a difference, and 45 percent said they did not know. As for what a trusted repository should preserve, most of the respondents wanted the archive to maintain the "look and feel" of the journal as well as all the functionality that the publisher offered, while a smaller group would be happy with just maintaining the "look and feel." Most importantly, over 90 percent rejected any single archiving solution, preferring instead that multiple custodians or a third party do the work.</p>
</div2>

<div2 type="subsection" n="06"><head>Conclusions</head>
<p>At the end of the planning year, Cornell University staff have a much clearer sense of our own expectations of what will be required in a digital electronic journal repository. The important work accomplished during this first year in translating the OAIS Reference Model, RLG-OCLC's <hi rend="italics">Trusted Digital Repositories: Attributes and Responsibilities</hi>, and the various emerging preservation metadata standards into the Cornell environment continues in two important areas.</p>
<p>First, much of the Project Harvest work is being translated to Project Euclid (<xref doc="projecteuclid">http://projecteuclid.org</xref>) and its newest iteration, the Electronic Mathematical Archiving Network Initiative (EMANI at <xref doc="emani">http://www.emani.org/</xref>), an international collaboration for the preservation of the journal literature in mathematics. Several compelling arguments developed during the course of Project Harvest have led us to build the Euclid infrastructure. Though several options exist, we have decided that a subject-based archive can best be built around the <hi rend="italics">article</hi> rather than the journal issue. Project Euclid is built around the journal article and therefore lends itself to this sort of approach.<note target="harvest04">[4]</note> Further, Euclid's modular component infrastructure as well as its support for OAI will make it possible for us to include in the system items other than journal articles, including gray literature, technical reports, and other items that would be appropriate for a subject-based archive. However, since Project Euclid was developed as a publishing system and not an archiving system, we will need to add to its infrastructure those elements that will allow the system to manage and maintain archival information packages as part of the system. We will therefore employ input from preservation policy staff and programmers trained during the course of Project Harvest to add the component parts to the existing system to make Project Euclid an archival (as opposed to publishing) system compliant with OAIS.</p>
<p>While we are excited about the development of the EMANI project, the Project Harvest planning process also raised real issues in our minds about the viability of managing national, and even international, electronic journal repositories in individual institutions. We were fairly certain by the end of the project we could develop a viable technical infrastructure for the repository. It was far from clear, however, that we could develop a funding model that would sustain that repository. Publishing partners were reluctant to either fund directly or indirectly (e.g., through higher subscription costs) the maintenance of such an archive; early investigations of a subscription model among potential archive clients, while promising, still faced the challenge of "free riders;" and the responsibility for maintaining a repository for a discipline is something that no institution should have to take on alone. Further work on the SBDA model may lead to the conclusion that it could become a reliable source of revenue for the archive. At the last meeting of the Mellon participants, however, our attention shifted to the planning process for the development of a central archiving service. The recognition among the Mellon e-journal archive planning participants that the function is best performed centrally may be the most important conclusion of all.</p>
</div2>

<div2 type="subsection" n="07"><head>Endnotes</head>
<note id="harvest01">[1] Consultative Committee for Space Data Systems, <hi rend="italics">Reference Model for an Open Archival Information System (OAIS)</hi>, CCSDS 650.0-B-1 Blue Book (Washington, DC: National Aeronautics and Space Administration, January 2002). Online at <xref doc="wwwclassicccsdsdocumentsCCSDS6500B1">http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf</xref>.</note>
<note id="harvest02">[2] RLG-OCLC, <hi rend="italics">Trusted Digital Repositories: Attributes and Responsibilities</hi> (Mountain View, CA: Research Libraries Group, 2002). Online at <xref doc=" rlglongtermrepositories">http://www.rlg.org/longterm/repositories.pdf</xref>.</note>
<note id="harvest03">[3] The OAIS reference model describes the organization of digital content into "information packages," namely, Submission Information Packages (SIPs), Archive Information Packages (AIPs), and Dissemination Information Packages (DIPs).</note>
<note id="harvest04">[4] We will leave it to publisher-based archives to concentrate on the publisher's output as defined by the publisher, and to address issues related to the capture of the "look and feel" of the journal issue.</note>
</div2>

<div2 type="subsection" n="08"><head>Appendix: Project Harvest Team Members</head>
<div3 type="part" n="01"><head>Project Harvest Team</head>

<list>
<item><hi rend="bold">Sarah Thomas</hi> <lb/>University Librarian <lb/>Principal Investigator</item>
<item><hi rend="bold">Peter B. Hirtle</hi> <lb/>Director, Cornell Institute for Digital Collections <lb/>Project Coordinator</item>
<item><hi rend="bold">Marcy E. Rosenkrantz</hi> <lb/>Director, Library Systems <lb/>Digital Library and Information Technologies</item>
<item><hi rend="bold">Mary Ochs</hi> <lb/>Head, Collection Development and Preservation, Mann Library <lb/>Chair, Publisher Relations Group</item>
<item><hi rend="bold">Tim Lynch</hi> <lb/>Head, Information Technology Section, Mann Library <lb/>Chair, Technical Design Group</item>
<item><hi rend="bold">Nancy McGovern</hi> <lb/>Coordinator, Digital Imaging &amp; Preservation Research</item>
<item><hi rend="bold">Gregory Lawrence</hi> <lb/>Government Information Librarian, Mann Library</item>
<item><hi rend="bold">Bill Kehoe</hi> <lb/>Programmer-Analyst <lb/>Digital Library and Information Technologies (D-LIT)</item>
</list>

</div3>

<div3 type="part" n="02"><head>Advisory Committee</head>

<list>
<item><hi rend="bold">Anne R. Kenney</hi> <lb/>Assistant University Librarian <lb/>Instruction and Learning, Research, and Information Services <lb/>Director of Programs <lb/>Council on Library and Information Resources <lb/>Chair, Steering Committee</item>
<item><hi rend="bold">Janet McCue</hi> <lb/>Director, Mann Library</item>
<item><hi rend="bold">H. Thomas Hickerson</hi> <lb/>Associate University Librarian for Information Technologies and Special Collections</item>
<item><hi rend="bold">Mariana Wolfner</hi> <lb/>Professor of Molecular Biology and Genetics</item>
</list>

</div3>
</div2>

<div2 type="subsection" n="09"><head>Appendix: Project Harvest USAIN Survey Fall 2001</head>
<p>This is the Cornell University Library Project Harvest Web-based questionnaire described in our recent email. As we stated in the message, your confidential responses will be very important to our project. At any time, you can withdraw from the survey by closing this Web session. The data collected will be tabulated and shared with the survey participants in early September. Thank you for your cooperation.</p>
<p><hi rend="bold">1. Your present location is:</hi> Please select a 2-letter state abbreviation:</p>

<list>
<item>AK</item>
<item>AL</item>
<item>AR</item>
<item>AZ</item>
<item>CA</item>
</list>

<p><hi rend="bold">2. Your principle occupation is (choose one):</hi></p>

<list>
<item>Director/administrator</item>
<item>Librarian</item>
<item>Educator</item>
<item>Student</item>
<item>Extension specialist</item>
<item>Researcher</item>
<item>Information or communication specialist</item>
<item>Other (please specify):</item>
</list>

<p><hi rend="bold">3. Please estimate how many e-journals your organization provides access to:</hi></p>

<list>
<item>50 or less</item>
<item>51-100</item>
<item>101-250</item>
<item>251-500</item>
<item>More than 500</item>
</list>

<p><hi rend="bold">4. How valuable are e-journals to your library in serving its user community (choose one):</hi></p>

<list>
<item>Minimal value compared to print versions</item>
<item>Useful for dual access, cannot substitute for print versions</item>
<item>Useful for sole access, can substitute for print versions</item>
</list>

<p><hi rend="bold">5. Would you cancel print journal versions if a reliable archiving solution was available for e-journals:</hi></p>

<list>
<item>Yes</item>
<item>No</item>
<item>Other (please specify):</item>
</list>

<p><hi rend="bold">6. Would you have greater trust in the long-term integrity of e-journals if preservation responsibilities were held by:</hi></p>

<list>
<item>Publisher only</item>
<item>Library only</item>
<item>A third-party other than a library or publisher</item>
<item>Some combination of the above</item>
</list>

<p><hi rend="bold">7. E-journal content can be archived in a very simple form, at low cost, or in more complex forms, at progressively higher cost. Rank the options listed below (1 most worthwhile  --  4 least worthwhile):</hi></p>

<list>
<item>___ Preserving the basic content only (text and illustrations) in a form that will look different from the original</item>
<item>___ Preserving the original appearance of the journal (the basic content plus the "look and feel" of the publication)</item>
<item>___ Preserving the full functionality of the journal as it appeared initially (basic content plus the "look and feel" plus features like automated reference linking)</item>
<item>___ Preserving the basic content and making it available in a continually updated form consistent with the appearance and functionality of recent issues of the journal</item>
</list>

<p><hi rend="bold">8. Which electronic format would you consider best for archiving e-journals:</hi></p>

<list>
<item>PDF</item>
<item>HTML</item>
<item>XML</item>
<item>Other (please specify)</item>
</list>

<p><hi rend="bold">9. Have you observed significant information losses in e-journals or other digital resources:</hi></p>

<list>
<item>Yes</item>
<item>No</item>
<item>Not sure</item>
</list>

<p><hi rend="bold">10. PLEASE ENTER ANY COMMENTS YOU HAVE FOR US:</hi></p>
<p><hi rend="bold">We appreciate your time and interest in helping us to provide excellent service.</hi></p>
<p><hi rend="bold">Sincerely, <lb/>Gregory Lawrence <lb/>Albert R. Mann Library <lb/>Cornell University <lb/>Ithaca, NY 14853-4301</hi></p>
</div2>
</div1>

<div1 type="section" n="03"><head>Report on the Planning Year Grant <lb/>For the Design of an E-journal Archive</head>
<p rend="center">Presented by: <lb/>Harvard University Library Mellon Project Steering Committee <lb/>Harvard University Library Mellon Project Technical Team</p>
<p rend="center">To: <lb/>The Andrew W. Mellon Foundation <lb/>1 April 2002</p>
<div2 type="subsection" n="01"><head>1. Introduction</head>
<p>Early in 2000, the Digital Library Federation, the Council on Library and Information Resources, and the Coalition for Networked Information sponsored a series of meetings with librarians, publishers, and licensing specialists to identify minimum requirements for e-journal archival repositories.<note target="Grant01">[1]</note> Based on a request from the Andrew W. Mellon Foundation to build on these requirements, the Harvard University Library was one of several research libraries that submitted a proposal for the design and planning of an electronic journal archive and subsequently received a one-year planning grant in December 2000. Harvard proposed to explore the development of an archive based  on the collection of e-journals from specific publishers.  There are, in  fact, a number of different ways that an archival collection could be focused.  In opting to work with specific publishers, Harvard intended to test the assumption  that there would be some economies of scale in processing large numbers of titles from the same source.  Between January 2001 and March 2002, the Project Steering Committee and the Project Technical Team (see Appendix A) worked together and with other Mellon grant recipients and publishing partners to identify needs and solutions.</p>
</div2>

<div2 type="subsection"><head>2. Project Objectives</head>
<p>During 2001, Harvard University Library used its one-year planning grant for an electronic journal archive from the Mellon Foundation to explore and define both the business and technical issues of content, format and deposit mechanisms, access control and interface requirements, long-term preservation guidelines, costs of development, operation and maintenance of the working archive, and financial and governance models for a sustainable archive.  The remainder of this report represents our research findings and current thinking on the design of a publisher based e-journal archive.</p>
<div3 type="part" n="01"><head>2.1 Archive Mission</head>
<p>Archives serve a variety of different functions in the larger society and even within the smaller scholarly community.  Research libraries in particular serve to "support education, continuous learning and research"<note target="Grant02">[2]</note> for their designated constituents.  The focal points of this type of collection are intellectual artifacts generally in textual and graphic formats.  An increasingly significant amount of the intellectual content is published and distributed in electronic journals.  This Archive's specific mission is to:</p>

<q><hi rend="italics">Preserve the significant intellectual content of a defined set of electronic journals independent of the form in which that content was originally delivered in order to assure that this content will be accessible to the scholarly community for the indefinite future in a readable format.</hi></q>
</div3>

<div3 type="part" n="02"><head>2.2 Scope of this Project</head>
<p>Harvard has proposed to begin collaboration with selected publishers to build and archive each publishing partner's entire collection of e-journals that can be deposited according to agreed specifications. Moving forward, Harvard has envisioned working with multiple publishers to build an operational model archive and a large collection of archived e-journal content.</p>
<p>Functionally, the Archive is designed to render text and still images and other formats as practically possible with no significant loss in intellectual content.  The Archive reserves the right to freely manipulate the internal format of the manifestation over time as long as the plain meaning of the intellectual content is preserved. In general, archiving takes place at a semantic level, not a syntactic one.<note target="Grant03">[3]</note>  This allows the Archive to be constructed around the principle of data format migration, rather than access system emulation.</p>
</div3>

<div3 type="part" n="03"><head>2.3 Publishing Partners</head>
<p>Initially, Harvard proposed to select potential publishing partners who produce a significant volume of content in digital format to test the scalability of the ingest process and the Archive.  Based on the stated criteria for the grant, a key characteristic of any publishing partner would be a strong interest in archiving and a willingness to invest time and resources in the project.  Beyond that, it was assumed that any publishing partner would have to possess a high level of technical expertise in order to contribute to the technical planning process.  We recognize that this assumption is not appropriate when dealing with smaller or less technologically sophisticated publishers.  However, we are optimistic that much of the development work planned for this Archive will produce sharable tools and infrastructure that may be adaptable for other publishing environments and assume that archives will, when dealing with less willing or able partners, themselves assume more of the responsibility for technical integration.  How these different models for publisher-archive interaction will change the economics and operation of archives needs exploration.</p>
<p>For the purposes of moving forward in exploring business and technical aspects of the Archive, Harvard held preliminary discussions with Blackwell Science and the University of Chicago Press.  John Wiley was considered as a possible partner if Harvard could come to agreement on an electronic journal license; this was subsequently completed and Wiley was included in the group of potential partners.  The Massachusetts Medical Society, publisher of <hi rend="italics">The New England Journal of Medicine</hi> (NEJM), declined to participate in further discussions, citing concern about the time and labor involved in view of other commitments and the lack of perceived need for an archival partner.  Our discussions with Blackwell Science were expanded to include both Blackwell Science and Blackwell Publishers which later merged to form Blackwell Publishing.  The resulting group of three potential partners has given Harvard the opportunity to explore a variety of issues from the perspective of a large privately-held commercial organization, a large publicly-held commercial organization, and a small non-profit organization, each of whom works closely with scholarly societies.  Collectively, these publishers produce 1,137 journals in electronic format.  While the ultimate goal of our discussions with these partners was to come to an agreement on the business and technical aspects of the design for the e-journal Archive, the intermediate goal of understanding the issues from a variety of perspectives proved to be immensely valuable.</p>
</div3>

<div3 type="part" n="04"><head>2.4 Content</head>
<p>Harvard proposed to build a publisher-based archive that would hold the entire collection of e-journals offered by selected publishing partners.  The underlying assumption is that material published by any given publisher is based on a common production process and that this uniformity will make it easier for the publisher to supply standardized input to an archive, thus simplifying the Archive's ingestion process.  In addition, by working in depth with publisher partners, the Archive can create a more sophisticated archiving plan informed by an understanding of the publishers internal systems and specific content.</p>
<div4 type="subpart" n="01"><head>2.4.1 Issue-centric Focus</head>
<p>Currently, the general practice of our three publishing partners is to regard their electronic titles as parallel (and possibly supplemented) manifestations of their print editions.  Although all three have indicated a willingness to explore the modality of issue-less publishing at some point in the future, none is actively experimenting with the concept. Since the notion of issue-less journals represents a major shift in serials publishing practice and is unsupported by current library systems and scholarly practice of citation, we have decided to retain the concept of the issue as central to the design and implementation of the Archive.  However, we retain some flexibility in this matter by allowing a loose definition of issue as a publisher-specified aggregation of content items without necessary regard for fixed publication patterns.  As will be apparent in Section 4, this issue-centric focus is central to the design and implementation of the Archive.  From the perspective of ingestion, this issue-centric focus allows Harvard to control receipt of content and to determine by examining the sequence if something has not been received.  Ingest will be based on our publishing partners depositing new e-journal content in the Archive on a predefined schedule.  The suggested schedule, each issue to be deposited prior to release of the next issue, will allow for an even and manageable ingest flow.</p>
</div4>

<div4 type="subpart" n="02"><head>2.4.2 E-journal Components</head>
<p>Many think of e-journal archiving only in terms of preserving articles.  However, e-journals actually contain a complex range of components.  The target for preservation is defined in this project as the electronic version of the journal.  At this early experimental stage, it was deemed best to preserve as much as possible in the categories of components and functionality.  To determine what components and functionality of e-journals exist, twenty-one journals were examined (see Appendix B).  This sample included eleven titles from the publishing partners and ten titles from other sources.  They covered a wide range of disciplines and represented titles available in print and electronic formats as well as titles only available electronically.</p>
<p>For all journals with printed versions, information about both the printed and electronic versions is available in the electronic version.  All journal sites have basic descriptive information such as scope and purpose, subject coverage, and copyright statement.  Most sites also have ISSN, frequency statement, indexing and abstracting service coverage, current editorial board, submission information, subscription and reprint information, and contact information.  This category of information is equivalent to the front matter of the printed journal and provides an essential intellectual infrastructure for the journal.  In discussion with the publishing partners, it has become evident that much of this front matter is not preserved in the electronic environment: only the most current version is available.  While the editorial board information is associated with a particular issue in print versions of journals, this is not the case in the electronic version.  Linking the appropriate version of front matter to specific issues is now an important item for the publishing partners to explore.</p>
<p>Within the issue or discrete publication bundle, all journals have table of contents information.  Items listed in the table of contents include articles, case reports, comments, communications, correspondence, responses, dialogue, columns, editorials, letters to the editor, book reviews, conference notes, news, announcements, interviews, errata, volume indexes, subject indexes, membership lists, and reviewers.</p>
<p>Advertisements are found in two of the journals reviewed.  Advertisements present a particular challenge for archiving.  First, it is not uncommon for Web advertisements to be served from an organization other than the content publisher so that archiving agreements would not necessarily cover their deposit.  Second, advertisements are frequently "dynamic," changing from day to day.  The same page viewed on different days can have different advertisements.  The advertisement seen in one country may be different from that seen in the same context in another; drug advertisements, for instance, are regulated at the national level and therefore vary with the country of receipt.  What is the appropriate advertisement to archive with a given issue?  When would dynamic advertisements be archived?</p>
<p>Web advertisements will be an important source for documenting contemporary business, society, design, and technology.  However, they represent a minor type of content for scholarly e-journals.  Harvard has decided not to archive advertisements as part of this e-journal archiving project.  We hope, however, that someone somewhere is archiving Web advertisements more generally as part of the documentation of our time.</p>
<p>For journals examined in this survey, most articles include an abstract in HTML.  Generally, the articles are delivered in both HTML and PDF; however, other formats noted include Postscript, TeX, and DVI, delivered as individual files or as aggregations bundled together in ZIP packages.  The HTML versions of article content offer thumbnail images of tables, generally in GIF format and occasionally in JPEG format.  Tables are also included in the HTML versions.  Figures, equations, symbols, and other graphics are delivered in GIF and JPEG formats.</p>
<p>One of the great powers of digital journal articles is that they are not limited to linear text and static pictures.  Increasingly, articles include "supplementary materials," digital files of many types.  These files can include digital materials used in the research described (statistical or instrumentation datasets, for example) or materials that expand on or illustrate topics discussed in the article (simulations, or tables too large for inclusion in the base article, for instance). These supplementary files represent a significant resource but also a significant challenge to the Archive.</p>
<p>In general, there is little control over the technical formats for supplementary files, no guidance to authors about good practices in the creation of such files, and little editorial analysis of the file content. The technical heterogeneity of these materials could introduce a wide and ever-growing range of formats into the Archive, significantly increasing the complexity of the preservation task.  The lack of guidelines and quality control means that unlike the case of articles themselves, the Archive is faced with objects of unknown virtue and potentially troublesome content.</p>
<p>One of our publishing partners suggested that it would be very useful to publishers if archives could provide guidance on preferred technical formats and practices that are well suited for preservation and archiving.  In the current environment, there is nothing to suggest to authors how to create digital objects with a greater chance of long-term viability. Many authors and their editors are very concerned about the longevity of their publications and if given guidance, may well be willing to change practices in ways that will reduce the complexity of preserving supplementary article content.</p>
<p>Most articles offer internal linking among components within the HTML version of the full text.  External links are also common and link out to authors' email addresses, author-provided URLs, citations in external indexing resources, other articles by the same author, and related articles.  Linking is a fast-changing area in e-journals and represents one of the great value-added features of electronic over paper publishing.  However, links pose significant challenges in archiving.  The largest application of links today is for references, allowing a user to navigate automatically from one article to a related cited article.  Most publishers, however, do not simply insert static links in references. Most links today are in the form of Digital Object Identifiers (DOIs), a type of persistent link or "name" that remains valid even if the cited work moves between systems or publishers. Frequently publishers keep a database of references and only determine the DOI for a citation  --  a costly process  --  once.  This allows the DOI to be reused each time the same work is cited.  Further, the number of DOIs for retrospective articles is growing very rapidly so that even if no link were available for a reference when an article is originally published, one could be added later when the DOI becomes available.</p>
<p>While the majority of links found in e-journals today are for references, there is every reason to expect linking to become richer with time.  There is already significant growth in links to "knowledge bases" such as GenBank.<note target="Grant04">[4]</note>  As these new types of links occur they will be added by automated means to existing articles.</p>
<p>Because links are dynamic and are expected to grow with time for already archived articles, it is unclear whether an archive should attempt to capture those links available at the point an article is ingested.  Would it be better for archives to implement the types of dynamic linking systems that publishers use, allowing for ever more rich links for archived content?  Or, should archives arrange for publishers to periodically resend the links for articles submitted earlier?  In either case, there will be complexity involved in supporting links for archives, but links are a vital type of content and users will likely be dissatisfied if they are not included in archived content.  This is an area requiring more exploration.</p>
<p>All journal Web sites include browsing functionality and most include search capability.  All journals except one include help features.</p>
</div4>

<div4 type="subpart" n="03"><head>2.4.3 User Survey</head>
<p>As we considered which components of electronic journals should be archived and how much of the look and feel of an e-journal should be preserved, there were concerns that costs would prohibit comprehensive archiving.  It is clear that all articles, reports, columns, editorials, communications, abstracts, errata, and correspondence must be archived.  It is less clear which other components should be preserved and how nontraditional components  --  such as links, threaded discussions, data sets, and data simulations  --  should be handled.  To address these questions, we designed a survey that we completed by interviewing faculty in the sciences (see Appendix C).  The survey focused on journal functionality including browsing, searching, image size and content (including cover images), tables of contents, subject and author indexes, advertisements, editorial board membership, editorial policy, announcements, membership lists (for societies), reviewer lists, copyright, guidelines for authors, career/job information, and business information (advertising guidelines, subscription information, and contact information).  Faculty were primarily concerned with the reliable archiving of scientific content, specifically articles, reports, editorials, and other original content, plus functionality, including browsing, searching, and printing.  Hierarchical links among volumes, issues, tables of contents, and articles were identified as important.  Threaded discussions were of interest, but not considered critical by some faculty since they are not peer-reviewed. Access to original data sets provided by the authors was also considered useful, although providing reliable and accurate links to materials not maintained by publishers is problematic.</p>
</div4>

<div4 type="subpart" n="04"><head>2.4.4 Components in Scope</head>
<p>Based on analysis of the e-journal sample and the user survey, Harvard has defined a preliminary list of materials deemed to be in the scope of archival collection and those currently out of scope of the archival collection, and will work with selected publishers to identify which components are available.  Deposits will include not only journal articles, but also associated materials (e.g., references, external links, abstracts), author-created supplementary digital files (e.g., datasets, sound files, simulations), other editorial journal content (e.g., editorials, reviews, communications, letters, threaded discussions), and selected masthead information (e.g., editor, editorial board, copyright statement).  Materials currently defined as in scope should be deposited, while those defined as out of scope are not expected but may be deposited if available, with the exception of advertising which will not be accepted.</p>
<p>The following components should be deposited in the Archive:</p>

<list>
<item><hi rend="underline">Articles</hi>:  This includes the text and auxiliary files such as (but not limited to) graphics, figures, tables, and/or photographs that constitute the "article proper."</item>
<item><hi rend="underline">Supplementary material/enhanced contents</hi>: When the author has deposited to the publishers digital objects related to the article such as (but not limited to) datasets, sound or video files, and/or computer programs  --  as opposed to pointing to such resources at alternate sites  --  those materials will be included in the Archive deposit.</item>
<item><hi rend="underline">Author supplied references</hi></item>
<item><hi rend="underline">Links to external resources</hi></item>
<item><hi rend="underline">Abstracts</hi></item>
<item><hi rend="underline">Tables of contents</hi></item>
<item><hi rend="underline">Placeholder files for non-deposited objects<note target="Grant05">[5]</note></hi></item>
<item><hi rend="underline">Other editorial content</hi>: This includes (but is not limited to) research, reports, columns, editorials, communications, correspondence, reviews, letters to the editor, and commentaries.</item>
<item><hi rend="underline">Bibliographic descriptions</hi>: This includes formatted metadata describing articles and other editorial content.</item>
<item><hi rend="underline">Editorial boards</hi></item>
<item><hi rend="underline">Editors</hi></item>
<item><hi rend="underline">Threaded discussions</hi></item>
<item><hi rend="underline">Copyright statements and information</hi></item>
<item><hi rend="underline">Editorial policies</hi></item>
<item><hi rend="underline">Reviewer lists</hi></item>
<item><hi rend="underline">Journal descriptions</hi></item>
<item><hi rend="underline">Cover images from the corresponding print issues</hi></item>
</list>
</div4>

<div4 type="subpart" n="05"><head>2.4.5 Components Currently Out of Scope (Not Deposited)</head>
<p>The following types of components are not expected or required for deposit in the Archive:</p>

<list>
<item><hi rend="underline">Information for authors</hi>: This includes copyright transfer agreements and guidelines for manuscript preparation and submission.</item>
<item><hi rend="underline">Subscription information</hi></item>
<item><hi rend="underline">Advertisements</hi></item>
<item><hi rend="underline">Other business information</hi>: This includes reprint ordering information, information for posting advertisements, contact information, and customer service information.</item>
<item><hi rend="underline">Additional information</hi>: This includes career/job information, etc.</item>
</list>
</div4>
</div3>
</div2>

<div2 type="subsection" n="03"><head>3. Business Model</head>
<div3 type="part" n="01"><head>3.1 Access Issues</head>

<p>One of the criteria to be met by this archive design is to make preserved information available to libraries under conditions negotiated with the publisher.  Policies governing access to the Archive must address three questions: who can access the Archive, under what circumstances, and how will access be obtained.  From our earliest discussions about access, it was determined that publishers should deposit materials into an initially dark archive as these materials become available.  A dark archive is one that allows no access for routine scholarly use.  As a result of some event  --  a "trigger" event  --  material in the Archive would be made available to some set of scholarly users resulting in a light archive.</p>

<p>Once the Archive has accepted preservation responsibility for deposited material, that content is then subject to periodic auditing to insure the efficacy of the Archive's preservation regimen and of the working of the repository system.  Auditing is particularly important for the Archive since it represents the only use of archived content while that content is in its initial dark period prior to the occurrence of a trigger event.  The composition of the auditors could be drawn from domain experts, subject area librarians, faculty, and scholarly societies.  It remains an open question whether domain expertise is required or practical.  However, initial quality control and internal and external auditing are not sufficient to insure the viability of files over time.  During the grant year, Harvard had informal discussions with several organizations that gather content from various sources and store that content.  Although initial quality control procedures varied, each organization maintains that actual usage is one of the best mechanisms for insuring content viability.  The issue an archive must face is whether dark content not used regularly by expert users is an adequate and reliable preservation model.</p>
<div4 type="subpart" n="01"><head>3.1.1 Authorized Users</head>
<p>Harvard originally proposed that the Archive should initially be semi-dark, permitting access only to Harvard University Library's authorized users through an online process and to any user legitimately authorized by the publisher through a batch export process.  Such access would allow for maintenance, auditing, and minimal exercising of the data.  The publishing partners had some concerns about this position including:</p>

<list>
<item>the preference for having "real" users access their own embellished systems rather than Harvard's more basic Archive interface;</item>
<item>the need for monitoring to guard against unauthorized use;</item>
<item>the reluctance to allow Harvard users to access material that Harvard has archived but not subscribed to or licensed.</item>
</list>

<p>During the resulting discussions, Harvard agreed that throughout the dark period the Archive would be accessible only by its operators and by a designated outside auditing authority.  Under certain circumstances, archived material might be made available to authorized users who can present proof of their legitimate right to specific materials.</p>

<p>The Harvard University Library Access Management Service (AMS) allows fine granularity of access control, down to the level of permitting access to a particular object by a particular user through the use of a particular application.  This level of control is appropriate and practical to support auditing, but expensive to extend to large-scale external use.  An archive intending to restrict access to only those who have had a past subscription to the archived content would bear considerable expense to gather the required licensee information and to build and operate the appropriate access management system.  Rather than pursue this option, Harvard believed that the increasingly wide-spread adoption of the "moving wall" concept (in which content becomes publicly available after a specified time period) in the scholarly journal environment suggested a more practical approach.  After deposit, archived materials would enter an initial "dark" period chronologically bounded by the trigger events defined in the submission agreement. When any one of the trigger events has occurred, material would be accessible without restriction.</p>
</div4>

<div4 type="subpart" n="02"><head>3.1.2 Trigger Events</head>

<p>At various times over the planning period, the following possible trigger events (conditions which would cause archived content to become publicly available) were discussed:</p>

<list>
<item>When material is no longer accessible online from the publisher.  This trigger was intended to support the essential "failsafe" function of the Archive, insuring continued access to the scholarly record.  After much discussion the provision was modified in several ways.  "Material" was replaced with the more specific "volume or time-based unit of the title," recognizing that portions of the electronic run of a journal might have different availability over time.  The new wording allows for part of a run to become accessible from an archive when it is no longer available elsewhere. "Accessible online" was modified to "accessible online either from the publisher or from another source as a discrete title."  This allowed titles that were transferred from one publisher to another to remain "dark" if other triggers had not occurred.  It also protected access to the content through title and issue units, as opposed to having the content buried in an undifferentiated aggregate database.  The final form of this trigger was thus: "when a volume or time-based unit of the title is no longer available online either from the publisher or from another source as a discrete title."</item>
<item>When the publisher sells or otherwise transfers the rights to publish a given title to another body.  Publishers rightfully objected that this meant that titles could not be sold, as the "lightened" content in an archive would greatly reduce the value of the retrospective content.  This trigger was dropped in later discussions. </item>
<item>When the material has been in the Archive for "n" years ("n" being a time period to be agreed to by Harvard and the publisher on a title-by-title basis).  This trigger occasioned the greatest amount of discussion and was not fully resolved during the planning period.  It was refined in later discussions slightly to  "after a defined amount of time of the publisher's choosing has passed, to be determined by title and volume or time-based unit."</item>
<item>When the title ceases to be published.  Some publishers objected that a ceased title may still have residual economic value.  The provision was dropped from later discussions.</item>
<item>When the content enters the public domain.</item>
</list>

<p>Trigger events are one of the key provisions of an archiving plan.  They define when the preserved content, which someone has made a considerable investment to archive, is useable.  Because they touch on areas that affect the commercial value of the content and thus on the publisher's income, publishers are legitimately quite concerned that they be carefully constructed.  All parties to archiving  --  authors, publishers, archives, subscribing libraries  --  have an interest in the details of trigger definition. This is an area requiring further discussion among the concerned parties.</p>
</div4>
</div3>

<div3 type="part" n="02"><head>3.2 Economic Issues</head>
<p>Economic issues are paramount in planning for archiving.  In the paper environment, many of the costs of archiving are buried in library budgets.  Much of what is done to preserve print journals is the same activity needed to provide day to day access to the literature.  In the e-journal environment we are moving to an architecture which separates archiving from daily service, making archiving costs painfully apparent.  Further, it is unlikely we will have or need the same large-scale redundancy in e-journal archiving that we have had for paper journals.  It is more likely that the operating costs of archiving will be centered in only a few places, raising obvious issues of how to spread costs fairly. Understandably, economic issues were discussed extensively during the planning year: within Harvard, with our publisher partners, and with other institutions thinking about archiving.</p>
<p>We do not know what archiving will cost.  Beginning to understand real costs will be one of the key objectives of any implementation project.  It is clear, however, that keeping costs low is enormously important; the magnitude of costs will greatly influence the outcome of the question of who is willing to share in the cost of archiving.  Harvard identified some strategies for controlling costs.  First, by building an archiving program over a larger digital library environment, activities (preservation monitoring), organization (computer operations), and technical infrastructure (a digital repository) already in place can be used to support the archiving activity. Second, applying smart automation to the process of adding content to the Archive can be used to reduce labor, and thus the cost, of ongoing Archive operation.  Third, limiting the functionality of the Archive allows us to eliminate costly development components such as subscription management systems.</p>
<p>Even if an archive is successful in controlling costs, the ultimate question remains "who pays."  Some options for support of archiving are inappropriate for Harvard's Archive.  The institution will not simply bear the cost of archiving on its own as a national library might. Certainly Harvard would expect to contribute to the cost of archiving, but it will be difficult to convince university administrators that the institution should simply dedicate resources at this level for the common good.</p>
<p>Some have suggested an archive should support itself, at least in part, by providing services others would pay to use based on the archived content.  We have not pursued this option for several reasons. First, some of the publishers we have talked to were initially unwilling to allow the Archive to resell services using their content.  Second, making the Archive dependent on building marketable services adds a major new dimension to the already large task of archiving.  The information marketplace is full of smart and aggressive players.  Competing in this marketplace requires both capital and a sophisticated understanding of many complex markets  --  there is not likely to be a single product design that suits different topical domains.  It is far from clear that all domains will provide opportunities for the development of profitable services to support archiving.  Lastly, archiving must be a perpetual activity.  Funding for a sustainable archive cannot be dependent on a service that may or may not be viable in some future marketplace.</p>
<p>Harvard has proposed that funding for a sustainable archive accompany the deposit of content from the outset.  The model initially proposed to our partners was that there be an explicit "archiving surcharge" publishers would charge all institutional subscribers to archived titles that would be passed on to the Archive. The intent of the proposal was that the community that benefits from the Archive also assumes some share of the cost of archiving.  Our publisher partners did not want the Archive to dictate pricing policy to them, so this model was modified as follows.  The publishers would pay the Archive an annual fee for archiving.  They in turn could collect the required funds from any one of a number of sources including authors (through page charges), sponsoring scholarly societies, or subscribers as appropriate in individual cases. The archiving fee would be composed of two elements:</p>

<list>
<item>An "ingestion" fee to pay the operating costs of day to day receipt, quality control, and archival preparation of new content.</item>
<item>An amount to be added to the Archive endowment to cover the long-term cost of storage and preservation activity.  Endowment is a very appealing model to pay for a long-term commitment such as archiving.</item>
</list>

<p>In designing this Archive we understand the experimental nature of this project as a means of developing sustainable models and encouraging more work in the field.  As with all experiments, it is quite possible that new choices and better alternatives may arise out of this work. For this reason, it is important to establish an agreed upon exit strategy. Harvard has suggested that if it chooses to cease archiving any given set of materials, this specific content of the Archive would be transferred to another archive selected by agreement between Harvard and a stakeholder community.  In addition, an amount of the remaining archiving fund proportional to the amount deposited by each publisher for those e-journal titles would be transferred to the new archiving organization.  In the case where a publisher chooses to terminate its relationship with Harvard's Archive, materials that have previously been deposited will remain in the Archive, and deposit of all titles will continue until the current volumes are complete.</p>
</div3>
</div2>

<div2 type="subsection" n="04"><head>4. Technical Model</head>
<div3 type="part" n="01"><head>4.1 Technical Infrastructure</head>
<p>The software and hardware environment for the Archive will rely upon existing technical infrastructure developed by the Harvard University Library over the past three years under the aegis of its Library Digital Initiative.<note target="Grant06">[6]</note>  The core component of this infrastructure is the Digital Repository Service (DRS), an Oracle-based repository for digital objects.  Within the DRS, object content streams are stored along with their associated administrative and structural metadata.  The DRS, now in its second production release, currently maintains over 240,000 objects with a total size of 120 gigabytes.  The DRS is responsible only for the managed preservation of the objects deposited within it; resource discovery and delivery are handled through independent systems.</p>
<p>Digital objects are delivered out of the DRS through media type-specific delivery applications.  Delivery applications are available for <hi rend="italics">simple objects</hi>, those atomically composed of a single physical content stream, such as a raster image file; and <hi rend="italics">complex objects</hi>, logical aggregations of intellectually or structurally related content streams, such as an electronic monograph structurally delivered in a page turning navigational environment.  Additional applications are under development for streaming audio and video media types.</p>
<p>Dependent upon the access rules defined for a particular digital object, delivery applications may make use of the facilities of the Access Management System (AMS) including user authentication, profile, and authorization.</p>
<p>Digital objects stored in the DRS can be given persistent identifiers registered with and resolved by the Name Resolution Service (NRS). NRS identifiers and their resolution mechanism are compatible with IETF recommendations for URNs.<note target="Grant07">[7]</note>  The NRS is composed of two subsystems: an Oracle-based administrative system that maintains the mappings between URNs and URLs, and a THTTP-based resolution server.<note target="Grant08">[8]</note> Archived e-journal components will be named in the NRS at a level of granularity corresponding to that of discovery and delivery, that is, at the issue and item level.</p>
<p>Descriptive metadata useful for resource discovery is contained in catalog systems external to the DRS.  For the purposes of the Archive, title and issue-level descriptive metadata will be stored in HOLLIS, Harvard's Integrated Library System (ILS), searchable through a Web-accessible OPAC. Title-level descriptive information, such as ISSN, publisher, etc., will be captured in MARC bibliographic records, while individual issue-level information, such as chronology, enumeration, etc., will be stored in related holdings records.  Issue-level catalog metadata will also include an actionable link in the form of an NRS persistent identifier to a dynamically generated, issue-specific Web page, providing table-of-contents-like access to individual e-journal issue items.  Item-level metadata will be managed in a new item-level catalog, implemented either as a separate database in the ILS, or as a stand-alone XML database.  It will provide a mechanism for search and browsing and will include actionable links to dynamically generated Web pages displaying individual journal items.</p>
</div3>

<div3 type="part" n="02"><head>4.2 Archive Architecture</head>
<p>The design of the Archive was conceived in relation to the OAIS reference model, with its six main archival functions: ingest, data management, archival storage, preservation, access, and administration (see Appendix D).<note target="Grant09">[9]</note></p>
<p>Large portions of the operational aspects of the Archive are amenable to automation, including areas such as publisher registration and profiling, Submission Information Package (SIP) submission, ingest validation at a syntactic level, SIP-to-AIP (Archival Information Package) transformation, archival storage deposit, preservation migration, routine reporting, and handling and responding to access requests.  This degree of automation is achievable through a strict requirement of publisher compliance to formal standards for SIPs and the definition of a small set of normative data formats.  The resulting uniformity of the Archive input stream and the canonical nature of internal archive storage practices provides the opportunity to rely upon automated systems to perform routine ingest, archival storage, data management, and access functions.  Through the collaborative development of community standards, there is good potential for the sharing of common infrastructure components between archiving projects and institutions.</p>
<p>Dependent upon the implementation details of a new ILS currently undergoing installation, serial check-in and claiming operations may also be amenable to automation.  The primary remaining tasks that will require manual intervention include ingest validation at a semantic level (the degree to which this is feasible is subject to further investigation); preservation planning, primarily the monitoring of the technical obsolescence of data formats; and ongoing periodic auditing of archived materials.</p>
<div4 type="subpart" n="01"><head>4.2.1 Ingest</head>
<p>The Ingest function is responsible for accepting and acting upon submissions of material for deposit into the Archive.  The technical infrastructure necessary to support the following subtasks within this function are for the most part not currently extant, and their implementation would occupy the majority of the first year of an implementation project.</p>
<div5 type="division" n="01"><head>4.2.1.1 SIP</head>
<p>From the point of view of a content provider the Archive is opaque with a single defined input interface, the SIP.  The structural envelope of the SIP in the Archive is provided by METS (Metadata Encoding &amp; Transmission Standard), a comprehensive XML framework for encapsulating digital objects.<note target="Grant10">[10]</note>  The unit of submission to the Archive is the e-journal issue.  Physically, the SIP will take the form of a three-level file system hierarchy corresponding to the e-journal title, issue, and items.  The title-level directory is empty and is present only to provide a common structural parent.  The issue-level directory contains a METS file encapsulating all issue-level metadata and pointers to issue-level content files (e.g., masthead, editorial board, cover image) and to the item-level directories, each of which in turn has a METS file containing all item-level metadata and pointers to item-level content.  Content object technical metadata stored in the METS files provides the necessary representation information to facilitate archival preservation activities and content delivery.  A preliminary draft specification of the SIP is undergoing public review and comment.<note target="Grant11">[11]</note></p>
<p>One of the core concepts of the Archive is the use of a common archival item-level schema for articles and "article-like" content.  The implications of and many design principles for such a schema are defined in a preliminary feasibility study on the subject, commissioned by Harvard and authored by Inera.<note target="Grant12">[12]</note>  The design of this schema will begin with an investigation of existing common schemas, such as the ISO 12083 and the PubMedCentral Document Type Definitions (DTDs), for possible use as is or as the basis for additional development.  If a new schema should be necessary, in whole or in part, the design and documentation of it may be contracted out to an appropriate consultant and developed with coordinated input from the larger community.  As will be set out in the Archive submission agreement, when practical it will be the responsibility of content providers to transform their journal content from its internal native form into compliance with the Archive's schema when the publisher has content marked up in SGML or XML.  In order to transform content to this schema, participating publishers will need a significant level of internal technical expertise or access to external technical expertise and the resources to implement the transformation workflow.  It is clear that not all publishers of scholarly content will have these assets.  We will attempt to provide whatever technical assistance is feasible towards this effort including documentation, tools, or training for those publishers who are in a position to work with the Archive.  All three of our publishing partners have agreed in principal to the use of a common archival schema.  The potential for archive simplification due to this type of normalization emphasizes the importance of collaborative work within the archiving community to achieve consensus on common standards.</p>
<p>Since digital preservation activities are performed on a type-specific basis, minimizing the number of acceptable data formats can reduce the complexity and cost of archive operations.  To place this on a formal basis, the Archive will define a small set of preferred normative formats.  In general, a single normative format will be defined for each functional category of content: for example, XML for metadata, XML for full-text (using numeric character references for non-ASCII Unicode characters, named character entities for non-Unicode characters, and MathML for mathematics), TIFF for raster still images, XML/SVG for vector still images, etc.  Data submitted in non-normative formats will be transformed upon ingest into an analogous normative format whenever possible without significant loss of intellectual meaning.  For example, submitted JPEG files will be transformed into their analogous TIFF representations.  Content objects submitted to the Archive in non-normative formats that are not susceptible to transformation into a normative analogue will be accepted, but only under the proviso that they may be preserved only at the bit level  --  i.e., in the form of the initially deposited bit stream  --  and that their usefulness over time may become problematic.</p>
<p>It is our belief that long-term archival preservation requires the initial capture of intellectual content at the highest possible resolution, finest possible granularity, and most abstract representation.  Additional criteria for the selection of normative formats include open standards, mature and robust technology, long-term viability, prevalence of commercial grade tools, and the potential for instantiated data objects to be created as far upstream as possible in publishers' production processes.  The composition of the set of normative formats will undergo periodic review to insure they remain appropriate for archival purposes with regard to continual technological advances.</p>
<p>During our initial evaluation of the PDF format with regard to its inclusion in the set of archival normative formats, several undesirable characteristics of PDF were discovered. Foremost, perhaps, is the fact that PDF is a proprietary rather than an open standard. Although Adobe has published the specifications, this is a matter of company policy and subject to unpredictable change.  The built-in extensibility of PDF allows it to provide a structural envelope into which content can be placed in a variety of base formats.  For example, PDF files can be composed partially or entirely of raster page images rather than the actual text.  Internal PDF content streams can be formatted or compressed using completely private schemas, some or all of which may be resistant to archival preservation.  Also, PDF is most generally encoded in a binary rather than an ASCII form which tends to increase the complexity if not the difficulty of processing.  Many of the challenges to be faced in preserving PDF content are examined in detail by John Ockerbloom in a recent paper in <hi rend="italics">RLG DigiNews</hi>.<note target="Grant13">[13]</note></p>
<p>However, despite our reservations concerning the long-term preservability of PDF, the fact remains that it has found overwhelming utilization in electronic publishing. As the Archive grows over time to encompass publishers beyond our initial partners, we anticipate that in a non-trivial number of cases PDF will be the only content format that some publishers will be able to provide to the Archive. Thus, we will include PDF as a normative format.  However, we will attempt to constrain the specific internal format of PDF content through a published set of best practices (full-text, rather than page images; standard, rather than private compression; no encryption, etc.) to which publishers will be strongly encouraged to conform.  We will store these PDF versions that publishers will deposit and will also use them as part of the quality assurance effort.</p>
<p>All relevant information concerning the various data formats recognized by the Archive, both normative and non-normative, will be stored in a central format registry.  Depending upon the use for particular pieces of format information, it may be encoded in human or machine-readable formats.  These data will include items such as formal format name, version history, pointer to authoritative specification, name of maintenance organization, MIME type, technical metadata schemas, compliant tools, and validation and migration processes.  Since format-specific expertise is widely distributed in the archiving community, as is the need for the information captured, the format registry represents another instance of a common infrastructure piece that is deserving of community-wide development and maintenance.</p>
</div5>

<div5 type="division" n="02"><head>4.2.1.2 Submission Session</head>
<p>The Submission Session refers to the operational process of physically transferring a SIP from a content provider to the Archive.  Due to the potentially large number and size of e-journal issue components, we will investigate mechanisms for implementing the submission process with regard to the granularity of the transfer (i.e., a single aggregated unit versus individual file components); fixed (e.g., DVD) versus electronic medium of submission; and in the case of the later, limited throughput of commercial network connections and the reliability of standard protocols.</p>
</div5>

<div5 type="division" n="03"><head>4.2.1.3 Quality Assurance</head>
<p>Validation and auditing represent two independent phases of quality assurance for material deposited within the Archive.  Ingest validation is performed to insure that content submitted for deposit is syntactically correct with respect to the published standards of the Archive.  Additionally, validation will attempt to determine the correctness of submitted metadata (e.g., does the ISSN match the journal title and do data files actually conform to their specified formats) and the internal consistency of individual content objects (e.g., are all article bibliographic references correctly associated with the citations in the body of the text).  No SIP will be accepted into the Archive until it has successfully passed ingest validation.  The responsibility for correcting errors uncovered during ingest validation will rest with the submitting publisher as will be specified in the Archive submission agreement.  To lower operating costs and to facilitate the effective scaling of Archive operations, ingest validation will be automated to the fullest extent possible.</p>
<p>Since materials deposited within the Archive will generally be dark with respect to access for some initial period of time, it is important to allocate substantial effort to the validation of the quality of submitted material upon ingest.  The difficulty, and thus cost, of the identification and correction of errors in archived journal content will only increase over time.  We will develop tools to perform automated quality assurance (QA) testing at a syntactic level, and as far as practicable, on a semantic level.  In addition to the internal use of these tools by the Archive, they will also be made available to content providers for client-side validation prior to submission.  Thus, these systems will be implemented with regard to platform independence, and keeping in mind the wide range of technical resources available to potential content providers, ease of installation and use.</p>
<p>Due to the wide variety of publisher production workflows and content management systems, and the fact that item-level content is submitted to the Archive in a common schema, produced by transformation from its native form, it is important for ingest QA testing also to include semantic level validation.  All online content providers rely to a greater or lesser extent upon the high degree of domain expertise of their users in detecting semantic errors.  As material submitted to our Archive will remain dark for some initial period of time, relying solely upon this approach is not feasible.  It is also not feasible to assume that the Archive staff itself can ever possess the same width and breadth of domain knowledge as is present in the scholarly community.</p>
<p>Our approach to this problem is to move semantic validation to the level of copy-editing.  Within the SIP, content providers are asked to provide a rendered version of all item-level content in a standard page description format (e.g., PDF), derived from the provider's internal native form of the content which is presumed to be authoritative.  After SIP ingest, a rendered version of the item-level content is derived from the Archive's common schema version of that content.  Proofreading between these two versions will suffice to detect semantic errors.  The scope and selection of material that is validated in this manner will be adjusted over time with regard to the detected error rate, perhaps on a publisher and title basis.</p>
</div5>

<div5 type="division" n="04"><head>4.2.1.4 Descriptive Information</head>
<p>After SIP validity has been confirmed, issue and item-level descriptive metadata is extracted from the issue and item-level METS files of the SIP, and transmitted to the Data Management function for storage and later use in archive administration and resource discovery.</p>
</div5>

<div5 type="division" n="05"><head>4.2.1.5 Transformation of SIP to AIP</head>
<p>Following validation and descriptive cataloging, the individual components of the SIP are transformed into the AIP format for deposit into the DRS in its capacity as the Archival Storage entity.  For the most part, SIP components are deposited as is.  The METS files are rewritten to include additional internal archive-specific administrative metadata, and to change the references to content files from file references valid within the SIP file system hierarchy to DRS inter-object references.</p>
<p>Some of the technical metadata existing in the METS files may be duplicated in internal DRS storage structures in order to facilitate ongoing archive administration and preservation activities. Whenever feasible we will attempt to harvest technical metadata stored internal to submitted SIP components.</p>
</div5>
</div4>

<div4 type="subpart" n="02"><head>4.2.2 Data Management</head>
<p>The Data Management function is responsible for maintaining descriptive information about archival holdings and administrative data necessary to the internal management of the Archive.  Issue and item-level descriptive metadata is received from the Ingest function.  Issue-level metadata is stored in the existing HOLLIS ILS, which includes serial check-in and claiming mechanisms useful to detect and request submission of missing issues.  Item-level metadata is stored in a new catalog, implemented either in the HOLLIS ILS or as a stand-alone XML database application.</p>

<div5 type="division" n="01"><head>4.2.2.1 Bibliographic control</head>
<p>E-journal content is modeled within the Archive at both an issue level and an item level.  Issues are defined loosely as primarily publisher-specified aggregations of individual items, with some additional issue-level, and generally non-citable, content such as masthead, editorial board, cover image, etc.  Items are defined as indivisible pieces of citable content such as articles, editorials, reviews, letters, errata, etc.  For purposes of internal administration of the Archive as well as for end-user content discovery and delivery, bibliographic control of journal content is necessary at both issue and item levels.</p>
<p>This two level modeling scheme is explicitly issue-centric.  While our publishing partners are interested in exploring the modality of issue-less publishing in the future, none of them have indicated that this will occur during the scope of this project.  Thus, for the purposes of streamlining deployment we are maintaining our conceptual focus on issues while remaining cognizant of the fact that this is an area that will require additional work in the near future.</p>
<p>In keeping with the established policy of the Harvard University Library, no artificial distinction is drawn between analog and digital assets in library catalogs.  As issue level information (e.g., title, ISSN, publisher, holdings by chronology and enumeration, etc.) is already being captured in the library's existing OPAC for print and online editions of serials, we will provide similar bibliographic information in the union catalog for archived e-journals.  Discovery of archived content will use the standard search mechanisms provided by the Web-accessible OPAC. In addition, we will construct a new catalog for item-level bibliographic control specifically to capture and make searchable item-level information.</p>
</div5>

<div5 type="division" n="02"><head>4.2.2.2 Naming</head>
<p>Naming is the process of assigning unique, persistent identifiers to resources.  Uniqueness insures an unambiguous mapping between an identifier for a resource as described in a discovery service and the instantiation of that resource as delivered to the user.  Persistence is required when identifiers for archived content are publicly visible and thus, susceptible to being captured and used in external systems outside the control of the Archive. A "bookmarked" name should always resolve to the correct named content object regardless of the passage of time or changes to the underlying architecture or implementation of the Archive.  Within the Archive, naming needs to occur at the level of granularity of the discovery and delivery services, that is, at the issue and item levels.</p>
<p>The Digital Object Identifier (DOI) mechanism is the most widely used naming scheme for electronic journal articles.<note target="Grant14">[14]</note>  However, DOIs resolve to resource instantiations defined by the registering body for those DOIs, in this case, by the publishers.  Therefore, an article DOI will resolve to that article in the publisher's content delivery service.  There is no widely implemented mechanism to interrupt the DOI resolution process and substitute resolution to a local "appropriate copy" such as the Archive.  Thus, it is necessary for an Archive-specific identifier to be given to named issue and item-level content components.</p>
<p>The Harvard University Library operates its own Name Resolution Service (NRS), composed of an administrative registry of name-to-URL mappings and a resolution server compliant with established Internet Engineering Task Force (IETF) protocols for Uniform Resource Names (URNs).  Syntactically, URNs are always generated with an internal namespace designation to avoid collisions between names assigned by different naming systems.  The Harvard namespace, "urn-3," is registered with the Internet Assigned Numbers Authority (IANA).  Although NRS names will be used in the Archive discovery and delivery services, Archive metadata for e-journal content objects will also include other public and private identifiers associated with those objects, including DOIs and publisher-specific internal identifiers.</p>
</div5>
</div4>

<div4 type="subpart" n="03"><head>4.2.3 Archival Storage Strategy</head>
<p>Our three publishing partners currently offer 1,137 electronic journals, annually comprising over 210,000 articles with a total size of approximately 400 gigabytes per year (assuming SGML/XML full text and TIFF images for articles, each with an accompanying PDF file).  They project relatively modest growth in their electronic offerings over the next five years, with an anticipated increase in titles of three percent per year.</p>
<p>The current storage architecture underlying our operational Digital Repository Service (DRS) uses NFS-mounted, RAID-based devices as its primary online storage mechanism, with automatic replication over a dedicated T1 network to an off-site tape library which can be mounted as a file system for remote recovery access.  The operational policy for the tape library enforces automatic periodic tape refreshment on a five year schedule.  The total growth capacity of the current implementation of this system is 50 terabytes.  The recovery cost for storage under this system is $20/gigabyte/year.</p>
<p>The current practice of our publishing partners is to present journal content in the form of static text and visual images.  As advanced dynamic media types, such as streaming audio and video, become more prevalent in electronic publishing, the per-issue size requirements of the Archive will increase commensurately.</p>
<p>The Archival Storage function of the Archive is provided by the extant DRS. The DRS batch loading process requires that each physical data stream be available as a separate file, along with an additional XML-encoded control file specifying loading and storage options.  This proscribes the form of the AIP within the DRS as the complete set of SIP components with each issue and item-level METS metadata and content file deposited as individual digital objects.  The Ingest function is responsible for transforming the SIP into the AIP prior to DRS deposit.  After successful deposit of an AIP into the DRS, the Archive will generate and transmit an e-mail message of confirmation to the submitting content provider.  The issuance of this confirmation constitutes the formal notice of the archive's assumption of archival responsibility for the deposited material.</p>
<p>Issue and item-level METS metadata files contain internal pointers to their component content files.  In addition, the DRS has its own explicit mechanism to maintain typed relationships between individual digital objects stored within it.  Thus, issue and item-level METS files will be stored within the DRS with an inter-level parent/child structural relationship. Similarly, METS metadata files and their component content files will be stored with an intra-level parent/child relationship.</p>
<p>Given the substantial number and size of e-journal components that will be deposited over time, we will allocate resources to evaluate the DRS's scaling properties and, if necessary, to design and implement appropriate enhancements.</p>
</div4>

<div4 type="subpart" n="04"><head>4.2.4 Preservation Strategy</head>
<p>Because the purpose of this Archive is to preserve the significant intellectual content of journals  --  not the original form in which the content was authored or delivered  --  the Archive will most likely rely upon transformation to prevent obsolescence.<note target="Grant15">[15]</note>  As defined by OAIS, <hi rend="italics">transformation</hi> refers to "a [type of] digital migration where there is some change in the Content Information or PDI bits while attempting to preserve the full information content."<note target="Grant16">[16]</note></p>
<p>Files that are proprietary and therefore not amenable to transformation will also be accepted into the Archive, provided they are not essential to the meaning of the journal article.  The Archive will accept, store, locate, and deliver these files; the Designated Community would assume responsibility for transformation.</p>
<p>The Archive's preservation policies and management functions are format-specific, envisioned to meet the following objectives:</p>

<list>
<item>to provide a range of preservation services according to what is viable for a given format at a given time<note target="Grant17">[17]</note></item>
<item>to monitor and document levels of technology support for file formats in a file format registry<note target="Grant18">[18]</note> that would:
<list>
<item>minimize the amount of technical metadata collected for each object</item>
<item>promote collaboration among the Archive, industry, and standards bodies with domain expertise to define the "trigger" events to initiate transformation</item>
</list></item>
<item>to minimize costs with batch processing operations for file validation, monitoring, and transformation</item>
<item>to promote best practices for authors to create and submit journal articles to publishers</item>
</list>

<div5 type="division" n="01"><head>4.2.4.1 Preservation Planning</head>

<p>The central premise of the Archive's preservation policy is that viable preservation services vary according to the shifting, contemporaneous level of support that data formats enjoy with regard to standards and applications.  Recognizing that forward data migration of archived e-journal content will not always be lossless and in some cases not even possible, our policy is being modeled on the assumption that the Archive will offer multiple levels of preservation service.</p>
</div5>

<div5 type="division" n="02"><head>4.2.4.2 Levels of Preservation Service</head>
<p>Preservation planning is an area of active development.  Although much more analysis is needed, some key distinctions have emerged in considering the technical and operational implications of assuming responsibilities to monitor obsolescence and to migrate data.  Our expectation is that the Archive will offer multiple levels of service in which the highest level ("Level One") represents the Archive's commitment to monitor formats and associated technologies, to develop and execute migration strategies that attempt to preserve all of the format's native functions and semantic integrity, and to disseminate files (e-journal components) in formats that can be rendered by contemporary applications.</p>
<p>The Archive will provide the highest level of preservation service for a limited set of preferred normative formats as discussed previously. Objects submitted in non-normative formats are expected to fall into two categories: those that can be transformed upon ingest into an analogous normative format and those that cannot (e.g., files with encryption or proprietary compression).  Objects in this latter category will receive fewer services.  At a minimum, objects will receive "bitstore service" in which they are refreshed and can be disseminated from the Archive to members of the designated community or to "digital archaeologists" committed to investing the resources needed to re-render the objects with contemporary applications.</p>
<p>Challenges remain to define the terms and conditions in which objects will receive middle levels of preservation service  --  those that offer more than bitstore, but less than Level One  --  such as "lossy migration."  The Archive's preservation policy will include statements that address how objects are classified upon ingest to receive specified levels of preservation service and what circumstances could lead to the service level being promoted or demoted over time.</p>
</div5>

<div5 type="division" n="03"><head>4.2.4.3 Policy Implications</head>
<p>The implication of instituting a preservation policy with multiple service levels is that all objects associated with an e-journal item can be deposited to, and accepted by, the Archive, but those integral to the item's semantic meaning should when at all possible be deposited in normalized, repository-compliant formats for full preservation service.  Our publishing partners support this concept and are eager to use this archiving policy as an incentive to motivate authors to submit content in fewer, standardized formats.</p>
<p>Within the Archive, a preservation manager will be responsible for monitoring data format-specific technological trends, as well as the needs and capabilities of designated user communities.  To facilitate reliable monitoring and migration planning we will develop a comprehensive data format registry, an authoritative repository of format metadata  --  or in OAIS terms, representation information  --  including an authoritative specification, the organizational entity responsible for format maintenance, a list of key applications capable of reading and writing the format, and the technical attributes that represent the functional integrity of the format.  These latter properties are of particular importance in modeling format migrations as their values can be used to distinguish lossless from lossy transformation.  The assignment of high-level status to a particular format, for example, is due in part to the comprehensiveness of its representation information.  We have developed preservation metadata requirements for XML, raster still image, and audio formats in the planning phase of this project; requirements remain to be defined for vector still image, page description, and other formats expected to be submitted to the archive.</p>
<p>Reporting functions will be developed to enable the preservation manager to track periodically the numbers of formats and format types, as well as the relationships among objects stored in multiple versions in the Archive.  Procedures to identify potential technological obsolescence of selected formats and to present the costs and benefits of various migration options, when feasible, must also be developed to ensure that forward migration is always appropriately scheduled and performed in the most cost-effective manner.</p>
<p>We will also investigate the costs and benefits of preserving all versions of files (following each transformation) versus maintaining only the current version along with the technical metadata necessary to facilitate reverse engineering or, at the very least, a trail of useful provenance.</p>
</div5>
</div4>

<div4 type="subpart" n="05"><head>4.2.5 Access</head>
<p>The Access function encompasses both e-journal resource discovery and delivery.  Discovery takes place at the title and issue level through the existing Web-accessible HOLLIS OPAC.  Actionable issue-level links provide users with a table-of-contents-like view of all individual issue items.  Actionable item-level links from the table-of-contents-like issue display and from search result records in the item-level catalog provide users with access to individual issue items.  XML-encoded full-text content items are dynamically transformed into HTML using XSLT.  Other item content media types (e.g., streaming audio or video) are delivered via the appropriate DRS delivery applications.</p>
<p>Rather than browsing or searching these Archive catalogs for relevant content, a user may possess <hi rend="italics">a priori</hi> appropriate citation information for the desired content, such as author and title, chronology and enumeration, or a DOI uniquely identifying an item.  A valid access request to the Archive can be made by using this citation information in a properly formed OpenURL which encodes the citation data into an actionable URL.<note target="Grant19">[19]</note>  The Archive will implement an OpenURL service to accept such requests and respond with the appropriately displayed item.</p>
<p>Access authorization is a binary function.  During the initial dark period following submission, e-journal content is available only to Archive staff for internal administrative and maintenance purposes, and to auditors as described in the Administration function.  Once content is lit up in consequence of an appropriate trigger event, that content is available to the general public.  Authorization is enforced only at the point at which the delivery of actual issue or item-level content is requested; cataloging metadata for all content is always available to the public.</p>
<p>Delivery of raw e-journal issue data (i.e., issue content and metadata as preserved in the Archive) can be requested and returned as an OAIS Dissemination Information Package (DIP).  At least one form of the DIP should be equivalent to a Submission Information Package (SIP) so that a DIP delivered from a compliant archive can be ingested directly by another archive.  The Archive will consider support for additional standard DIP formats as they emerge in the future.  For the wholesale batch dissemination of archived content, that content will be transformed from its internal Archival Information Package (AIP) form to a DIP. The handling of and response to requests for a DIP will be an off-line, asynchronous operation.  It is highly desirable that the archiving community cooperates in the development of standard definitions of the DIP to facilitate the transformation of archival materials between participating institutions.</p>
</div4>

<div4 type="subpart" n="06"><head>4.2.6 Administration</head>
<p>The Administration function is responsible for the routine operation of the Archive.  A good deal of this work is manual, not automated, including the negotiation of submission agreements with content providers, supervision of the Archive staff, and the maintenance and enhancement of the Archive's technical environment and infrastructure.  Nonetheless, these manual procedures will be supported by systems providing administrative database services, online registration of content provider profile information, and hardware and software monitoring tools.</p>
<p>The major automated task of this function is the performance of required format migrations as instigated by the Preservation Planning function.  The Archive's adherence to the internal use of a limited set of normative Level One data formats constrains what would otherwise be a potentially intractable undertaking into a feasible task.  We will investigate the use of commercial tools to transform non-normative formats into normative data formats eligible to receive Level One preservation services.  Additional tools may be identified to perform other data management functions, such as validation and metadata extraction, that would assist preservation monitoring when transformation is not feasible.  In addition to the transformation and validation of the e-journal content objects, such migrations may also necessitate enhancements to delivery systems.  As the set of normative formats grows or is culled over time, ingest procedures will also require concomitant modifications.</p>
<p>Although extensive content quality assurance occurs upon Ingest, subsequent periodic auditing of archived material will also be carried out to validate the lossless nature of migration transformations as well as the general stability of the Archive's storage environment.  This auditing will occur under the purview of the Administration function by domain experts drawn from publishers, scholarly societies, and librarians.  Statistical sampling of the Archive's holdings categorized by publisher, subject area, and title will be employed in the selection of material to ensure appropriate representative coverage in the auditing process.</p>
</div4>
</div3>

<div3 type="part" n="03"><head>4.3 Schedule</head>
<p>A fair number of issues remain to be resolved.  In order to fully test the model for the Archive and to get a better understanding of the real costs involved in operating the Archive, Harvard believes it is necessary to build and run the Archive long enough to gather experience.  The work schedule, taking this into account, is composed of the following four main functional phases:</p>

<list>
<item> A one year development period primarily concerned with building additional needed pieces of infrastructure, designing the common archival item-level schema, finalizing the details of the SIP, and allowing sufficient time for our publishing partners to develop appropriate export mechanisms for Archive submission.</item>
<item>A six month ingest test period using a controlled submission of a limited number of titles from all three publishing partners to test and validate the stability and appropriateness of the Archive's technical systems and workflow processes.</item>
<item>A one year production ramp-up period during which the Archive will steadily increase submission volume to include the complete list of titles available from all three publishing partners. This phase will evaluate the scaling properties of the Archive's technical design and operational plan.</item>
<item>A one-and-a-half year full production period to confirm the operational stability of the Archive.</item>
</list>
</div3>
</div2>

<div2 type="subsection" n="05"><head>5 Roles and Responsibilities</head>
<div3 type="part" n="01"><head>5.1 Internal Roles and Responsibilities</head>
<div4 type="subpart" n="01"><head>5.1.1 Technical Development</head>
<p>The primary responsibilities of the Archive staff with regard to technical issues are the initial development, ongoing maintenance, and future enhancement of Archive systems.  Additionally, the expertise of the staff will be helpful in monitoring technical innovation and obsolescence with regard to normative data formats and potential preservation migration transformations.  This activity would be performed in cooperation with the Archive preservation manager and collection curators.  All technical work will be performed using accepted industry standards and processes for technical management, design, implementation and testing methodologies, configuration management, and documentation.</p>
<p>The Archive architecture relies heavily on efficiencies achieved by compliance to common standards, e.g., SIP structure and the archival schema.  Widespread compliance is best achieved by insuring that these standards are developed in an open collaborative process.  Archive staff will be responsible for the coordination of these processes and the resultant timely publication of appropriate specifications.</p>
<p>As Archive submission is opened to publishers beyond our initial partners, we anticipate working with institutions with widely varying technical resources and competencies.  Potential difficulties in this regard can be mitigated by the distribution of appropriate utilities and tool sets to facilitate publisher activities.  All Archive development will be evaluated in terms of the applicability of new system components for such distribution.  If found to be relevant, development will proceed with due consideration towards platform independence of the system implementation.  Archive staff will also be available for limited technical consultation regarding publisher development and operational procedures.</p>
</div4>

<div4 type="subpart" n="02"><head>5.1.2 Archive Content Development</head>
<p>Harvard's initial approach to archiving has been "publisher based," that is, oriented towards archiving all of the e-journal output of a publisher.  This approach was chosen for two reasons.  First, it simplifies the task of creating a large base of archival activity to test systems and operations, and to provide enough scale on which to base long-term cost projections.  Second, we believed that the marginal cost of archiving another title from a publisher with whom the issues of interoperation have already been worked out would be less than taking a new title from a new publisher.  The cost of archiving a title could thus be lowered.</p>
<p>Our plan is to work with our three publisher partners, pending final agreement, to build and test interoperation between the Archive and the publishers' systems, then begin to increase the number of titles archived from each.  One of the great uncertainties of archiving is the amount of labor required for ingesting new content.  The Archive will very likely be limited in staffing in the initial phase of its operation.  We plan to increase Archive coverage until we are ingesting all of the content from our original partners, or until the available staff cannot deal with additional input.  At the point where all available titles from the original publishing partners have been deposited successfully and it is determined that we have not yet reached our capacity to ingest content, it will be appropriate to evaluate the Archive's procedures and functions and determine growth options and extended partnerships.</p>
</div4>

<div4 type="subpart" n="03"><head>5.1.3 Curatorial Responsibilities</head>
<p>In traditional preservation, curators are responsible for ensuring that collections remain usable.  While they may store collections in centralized, environmentally-controlled storage facilities, or partner with conservators and preservation technologists to repair or copy materials, curators are ultimately fully responsible to account for the extent, condition, and usability of their collections.</p>
<p>The inherent fragility and complexity of digital collections require a shift in preservation responsibilities.  To ensure that items do not become obsolete, curators and other owners need to delegate preservation responsibilities to technical staff with the expertise and the tools.  In this new model, preservation technologists assume perpetual rather than temporary custody of the physical objects in their care.  They must monitor the items as well as the environment.  Because obsolescence is inevitable for all digital formats, they must be able to develop and present migration strategies to the curators and owners, then implement the strategy the owner prefers.  In traditional preservation, curators have ongoing custodial responsibility (whether passive or active) and preservation technologists intervene infrequently.  In the preservation model for digital archiving, repository managers assume the ongoing custodial responsibility and curators are consulted as necessary to make decisions about migration and other issues.</p>
</div4>
</div3>

<div3 type="part" n="02"><head>5.2 External</head>
<p>As we conceive this Archive, it cannot and does not stand in isolation.  The Archive itself has a variety of partners and stakeholders. Additionally, the Archive must have a relation with the broader community.</p>
<div4 type="subpart" n="01"><head>5.2.1 Stakeholders</head>
<p>Discussion among Harvard and its publishing partners has centered on who "owns" the Archive and who governs it. While the Archive is intended to be maintained and administered by Harvard and built on Harvard's existing digital library infrastructure, the publishing partners have suggested that a broader group with a vested interest should be involved.  Who are the stakeholders and what is their role in helping the Archive do its job? This community could comprise authors, scholarly societies, publishers, and institutional subscribers as representatives of researchers.  These delegated stakeholder groups should have a role in reviewing the policies and practices of the Archive as a mechanism for vetting the Archive and establishing a level of trust; however, some publishing partners have suggested that actual governance of the Archive is tied to the brightness of the Archive and the additional services that might be offered by the Archive.  The brighter the Archive, the more governance a publisher should have; the more services offered, the more governance a publisher should have.  Harvard, however, maintains that final governing authority is intrinsically tied to the ability to use its existing infrastructure as a starting point for the Archive, while a variety of policies and procedures related to the development, administration, ongoing maintenance, and financing of the Archive should be developed in consultation with and open for review and comment by representatives of this stakeholder community.</p>
</div4>

<div4 type="subpart" n="02"><head>5.2.2 The Archival Community</head>
<p>In addition to the stakeholder community with its representative input, we have elsewhere in this paper discussed the necessity for an external auditing service.  Such a service might be part of a broader confederation of archival organizations and stakeholders.  Such a confederacy might be charged with establishing registries for content and format types; certifying policies, practices and procedures; and supporting the ongoing development of digital archiving.</p>
</div4>

<div4 type="subpart" n="03"><head>5.2.3 Sharable Infrastructure</head>
<p>During the development of the Archive several pieces of sharable infrastructure will be produced:</p>

<list>
<item>Format registry to provide a centralized store for relevant information about data formats supported by the Archive.</item>
<item>SIP/DIP specifications. Community-wide agreement on these specifications will allow the free interchange of archived materials between archiving institutions and projects.</item>
<item>Issue-level content schema to capture issue-level information such as masthead, editorial board, etc.</item>
<item>Canonical item-level schema designed to accommodate the Archive's need for homogeneous content and allow a clean transformation path from publishers' native content formats.</item>
<item>METS Java toolkit for API-level support for the procedural construction, validation, and serialization/deserialization of syntactically valid METS files.</item>
<item>SIP Quality Control tool.</item>
<item>XLST stylesheets for issue and item-level display, based on the specifications for the issue and item-level XML schema.</item>
</list>
</div4>
</div3>
</div2>

<div2 type="subsection" n="06"><head>6. Postscript: 2003</head>
<p>Since the conclusion of our Mellon-funded planning project, additional work on e-journal archiving has continued.  Through our investigation of potential e-journal XML schemas we learned that the National Library of Medicine (NLM) was in the process of revising the document type definition (DTD) used for PubMedCentral (PMC).  Since PMC receives content from various publishers, their DTD has to support heterogeneity of document structure, although all the content is within the biomedical discipline.  NLM was receptive to our suggestion that the DTD be expanded to support content across academic disciplines.  Working with two leading XML consulting firms, Inera Inc. and Mulberry Technologies, Inc., with additional design input from Harvard, NLM has recently released an archive and interchange DTD suite (<xref doc="dtdnlmnih">http://dtd.nlm.nih.gov/</xref>) to provide a common format in which publishers and archives can exchange e-journal content.</p>
<p>The main benefits of the DTD suite are:</p>

<list>
<item>It was not created by, not reflects the bias of, any specific publisher, society, typesetter, or aggregator</item>
<item>The document analysis covered a wide range of academic disciplines to insure that the DTD is not biased towards any specific intellectual domain</item>
<item>It is based on public standards, such as the CALS and XHTML table models, MathML, and Unicode</item>
<item>It is modular and can be modified easily to meet specific needs without undermining either the code structure of the DTD or the interchange of files created according to the DTD</item>
<item>It was designed so that publishers can easily transform existing content to be compliant with the DTD</item>
</list>

<p>Although just recently released, the DTD suite is undergoing serious evaluation and prototypical use by  many content providers and suppliers.  If the DTD suite fulfills its promise, it will provide for the foreseeable future a common scholarly publishing DTD for purposes of article interchange and archiving.  Within archival repositories, significant economies of scale can be achieved only through large-scale automation, which in turn requires maximum homogeneity of content.  The NLM DTD suite fostered by the work of the Harvard University Library should help facilitate the creation and operation of sustainable archives for e-journals and thus help to promote their use within scholarly pedagogy and discourse.</p>
</div2>

<div2 type="subsection" n="07"><head>7. Endnotes</head>
<note id="Grant01">[1] Dan Greenstein and Deanna Marcum, "Minimum Criteria for an Archival Repository of Digital Scholarly Journals," Version 1.2 (Washington, DC: Digital Library Federation, 15 May 2000). Online at <xref doc="diglibpreservecriteria">http://www.diglib.org/preserve/criteria.htm</xref>. Also available in this publication.</note>
<note id="Grant02">[2] Anne J. Gilliland-Swetland, <hi rend="italics">Enduring Paradigm, New Opportunities: The Value of the Archival Perspective in the Digital Environment</hi>, Publication 89 (Washington, DC: Council on Library and Information Resources, February 2000). Online at <xref doc="clirpubsreportspub89contents">http://www.clir.org/pubs/reports/pub89/contents.html</xref>.</note>
<note id="Grant03">[3] It is possible for typographical manifestation to impart significant semantic value, as in the case of poetry and other forms of creative expression.  In such cases where the manifestation forms an intrinsic part of the intellectual content, we will explore mechanisms to identify, capture, and preserve this in the Archive.</note>
<note id="Grant04">[4] For information about GenBank, see <xref doc="ncbinlmnihGenbankOverview">http://www.ncbi.nlm.nih.gov/Genbank/GenbankOverview.html</xref>.</note>
<note id="Grant05">[5] In rare cases, an article included in the print version of a journal issue is not available in electronic format. The fact that such as article is not available should be noted.</note>
<note id="Grant06">[6] Harvard University Library, <hi rend="italics">Library Digital Initiative Home Page</hi> (Last modified January 2003). Online at <xref doc="hulharvardldi">http://hul.harvard.edu/ldi/</xref>.</note>
<note id="Grant07">[7] Internet Engineering Task Force (IETF), <hi rend="italics">Uniform Resource Names (urn) Charter</hi>, 55th IETF Working Group Meeting, Atlanta, Georgia (Last modified 31 July 2001). Online at <xref doc="ietfproceedings02nov126">http://www.ietf.org/proceedings/02nov/126.htm</xref>.</note>
<note id="Grant08">[8] R. Daniel, <hi rend="italics">A Trivial Convention for using HTTP in URN Resolution</hi>, RFC 2169 (June 1997). Online at <xref doc="ietfrfc2169">http://www.ietf.org/rfc/rfc2169.txt</xref>.</note>
<note id="Grant09">[9] Consultative Committee for Space Data Systems,  <hi rend="italics">Reference Model for an Open Archival Information System (OAIS)</hi>, CCSDS 650.0-B-1 Blue Book (Washington DC: National Aeronautics and Space Administration, January 2002). Online at <xref doc="wwwclassicccsdsdocumentsCCSDS6500B1">http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf</xref>.</note>
<note id="Grant10">[10] Network Development and MARC Standards Office, Library of Congress, <hi rend="italics">Metadata Encoding &amp; Transmission Standard (METS)</hi>. Online at <xref doc="locstandardsmets">http://www.loc.gov/standards/mets/</xref>.</note>
<note id="Grant11">[11] Harvard University Library, <hi rend="italics">Submission Information Package (SIP) Specification</hi>,  Version 1.0 DRAFT (19 December 2001).  Online at <xref doc="diglibpreserveharvardsip10">http://www.diglib.org/preserve/harvardsip10.pdf</xref>.</note>
<note id="Grant12">[12] Inera, Inc., <hi rend="italics">E-Journal Archive DTD Feasibility Study</hi> (5 December 2001). Online at <xref doc="diglibpreservehadtdfs">http://www.diglib.org/preserve/hadtdfs.pdf</xref>.</note>
<note id="Grant13">[13] John Mark Ockerbloom, "Archiving and Preserving PDF Files,"  <hi rend="italics">RLG DigiNews</hi> 15.1 (15 February 2001). Online at <xref doc="rlgpreservdiginews51feature2">http://www.rlg.org/preserv/diginews/diginews5-1.html#feature2</xref>.</note>
<note id="Grant14">[14] International DOI Foundation,  <hi rend="italics">The DOI Handbook</hi>, Version 1.0.0 (February 2001). Online at <xref doc="doihandbook2000010222DOIHandbookV100">http://www.doi.org/handbook_2000/010222DOI-Handbook-V100.pdf</xref>.</note>
<note id="Grant15">[15] Such transformations can be either anticipatory, with the repository maintaining the transformed version of the object, or "just-in-time," with transformation happening when a user requests an object.</note>
<note id="Grant16">[16] <hi rend="italics">Reference Model for an Open Archival Information System</hi> (OAIS): 5-5. URL at note 9 above.</note>
<note id="Grant17">[17] Preservation levels may be negotiated according to changes in the level of support for a given format by standards, industry applications, or applications within the Archive.</note>
<note id="Grant18">[18] Harvard and MIT have begun discussing a registry framework that will potentially be shared by both electronic journal archives.</note>
<note id="Grant19">[19] Herbert Van de Sompel, Patrick Hochstenbach, Oren Beit-Arie, "OpenURL Syntax Description," version OpenURL/0.1f (16 May 2000). Online at <xref doc="sfxitopenurl">http://www.sfxit.com/openurl/openurl.html</xref>.</note>
</div2>

<div2 type="subsection"><head>8. Appendix A: Project Staff</head>
<div3 type="part" n="01"><head>8.1 Project Steering Committee</head>
<p>This group was composed of senior curators, preservation experts, and library systems staff to address functional and organizational issues. Members of the Committee are:</p>

<list>
<item>Ivy Anderson, Coordinator for Digital Acquisitions</item>
<item>Marianne Burke, Assistant Director for Resource Management, Countway Library of Medicine (January 2001-September 2001)</item>
<item>Dale Flecker, Associate Director for Planning and Systems, Harvard University Library</item>
<item>Diane Garner, Librarian for the Social Sciences, Harvard College Library</item>
<item>Marilyn Geller, Project Manager (July 2001-March 2002)</item>
<item>Jeffrey Horrell, Associate Librarian of Harvard College for Collections</item>
<item>John Howard, Associate Director for Technology Development &amp; Services, Countway Library of Medicine (September 2001-March 2002)</item>
<item>Y. Kathy Kwan, Project Manager (January 2001-June 2001)</item>
<item>Jan Merrill-Oldham, Malloy-Rabinowitz Preservation Librarian</item>
<item>Constance Rinaldo, Librarian, Ernst Mayr Library of the Museum of Comparative Zoology</item>
<item>Lynne Schmelz, Librarian for the Sciences, Harvard College Library</item>
<item>MacKenzie Smith, Digital Library Projects Manager (January 2001-December 2001)</item>
</list>
</div3>

<div3 type="part" n="02"><head>8.2 Project Technical Team</head>
<p>An internal team composed of staff with significant experience in digital library development investigated technical issues and systems requirements. Members of the Team include:</p>

<list>
<item>Stephen Abrams, Digital Library Software Engineer</item>
<item>Stephen Chapman, Preservation Librarian for Digital Projects</item>
<item>Dale Flecker, Associate Director for Planning and Systems, Harvard University Library</item>
<item>Marilyn Geller, Project Manager (July 2001-March 2002)</item>
<item>Y. Kathy Kwan, Project Manager (January 2001-June 2001)</item>
<item>MacKenzie Smith, Digital Library Projects Manager (January 2001-December 2001)</item>
<item>Robin Wendler, Metadata Analyst</item>
</list>
</div3>
</div2>

<div2 type="subsection" n="09"><head>9. Appendix B: Titles Included in E-journal Component Survey</head>

<p><table>
<row><cell role="label">Title</cell><cell role="label">Publisher</cell><cell role="label">Print</cell><cell role="label">Electronic</cell></row>
<row><cell>American Journal of Human Genetics</cell><cell>University of Chicago Press</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Acta Zoologica</cell><cell>Blackwell</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>American Journal of Physical Anthropology</cell><cell>Wiley</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Astrophysical Journal</cell><cell>University of Chicago Press</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Current Issues in Education</cell><cell>Arizona State University and the College of Education</cell><cell>No</cell><cell>Yes</cell></row>
<row><cell>Electronic Journal of Combinatorics</cell><cell>Neil J. Calkin and Herbert S. Wilf (in association with American Mathematical Society)</cell><cell>No</cell><cell>Yes</cell></row>
<row><cell>ENDS Environment Daily</cell><cell>Environmental Data Services Ltd</cell><cell>No</cell><cell>Yes</cell></row>
<row><cell>European Journal of Organic Chemistry</cell><cell>Wiley</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>First Break</cell><cell>Blackwell</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Fish &amp; Shellfish Immunology</cell><cell>Academic Press</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Journal of Internal Medicine</cell><cell>Blackwell</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Journal of Political Economy</cell><cell>University of Chicago Press</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Journal of Seventeenth Century Music</cell><cell>Society of Seventeenth Century Music</cell><cell>No</cell><cell>Yes</cell></row>
<row><cell>Journal of the History of Behavioral Sciences</cell><cell>Wiley</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Medieval Review</cell><cell>The Medieval Institute, College of Arts and Sciences, Western Michigan University</cell><cell>No</cell><cell>Yes</cell></row>
<row><cell>Nature</cell><cell>Nature Publishing Group</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Nursing</cell><cell>Blackwell</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Philosophy</cell><cell>Blackwell</cell><cell>Yes</cell><cell>Yes</cell></row>
<row><cell>Politics Research Group Working Papers</cell><cell>JFK School of Government, Politics Research Group</cell><cell>No</cell><cell>Yes</cell></row>
<row><cell>Representation Theory</cell><cell>American Mathematical Society</cell><cell>No</cell><cell>Yes</cell></row>
<row><cell>Science</cell><cell>AAAS</cell><cell>Yes</cell><cell>Yes</cell></row>
</table></p>
</div2>

<div2 type="subsection" n="10"><head>10. Appendix C: Electronic Journal Archives Survey</head>
<p>Thank you for agreeing to participate in this survey for the Electronic Journal Archiving Project at Harvard University.</p>
<p>The Harvard University Library and three major publishers of scholarly journals  --  Blackwell Publishing, John Wiley &amp; Sons, Inc., and the University of Chicago Press  --  have agreed to work together on a plan to develop an experimental archive for electronic journals. The preservation and archiving of electronic journals  --  which are increasingly digital only and for which, in many cases, no paper copies exist  --  present unique, long-term challenges to librarians, publishers, and ultimately, to the scholars and researchers who will seek access to them over time.</p>
<p>The new joint venture is sponsored by the Andrew W. Mellon Foundation which recently awarded a grant to the Harvard University Library specifically for the planning of an electronic journal archive. The year-long planning effort will explore the issues related to electronic journal archiving and develop a plan for a repository at Harvard for electronic journal publications. The expected outcome is a proposal for an archive for these journals.</p>
<p>We are currently exploring which components of e-journals can and/or should be archived. It is clear that all articles will be archived as well as reports, columns, editorials, communications, abstracts, errata, and correspondence.  It is less clear which other components should be preserved and how non-traditional contents, such as links, data sets, and data simulations, should be handled.  How much of the look and feel of an electronic journal should be preserved?  Assume that not everything can be preserved because the costs will be prohibitive.</p>
<p>Another significant issue to be determined is at what point items in the archive may be accessed. For example, should the archive be "dark" and accessible only under emergency conditions (such as a publisher going out of business) or should the archive be "light" and effectively serve as an alternative to a publisher site for everyday access to journals?  Most likely, the scenario will be something in-between.</p>
<p>For this survey, please consider that the need for a particular journal component will be no sooner than ten years in the future. Also assume that not all journal features can be preserved.</p>

<div3 type="part" n="01"><head><hi rend="underline">SURVEY QUESTIONS</hi></head>
<p>Please rate the importance of the following components of an electronic journal.  (The concept <hi rend="italics">future</hi> is defined as ten or more years into the future.) Circle 1, 2 or 3 with the meanings:</p>

<list>
<item>*1* <hi rend="bold">no future use is likely</hi></item>
<item>*2* <hi rend="bold">limited future use is likely</hi></item>
<item>*3* <hi rend="bold">important to maintain future access to this component</hi></item>
</list>

<div4 type="subpart" n="01"><head>Journal Content</head>

<p><table>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Cover image for issue</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Table of contents</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Volume/issue number linked to content</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>References to outside information (e.g. portals, author-developed data that is stored outside the journal site, bibliographies developed by the journal, etc.)</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Threaded discussion</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Index to volume</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Subject</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Author</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Advertisements</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Announcements (e.g., events)</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Editorial board</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Editorial policy</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Membership list  (e.g., for societies)</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Reviewer list</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Copyright</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Licensing information</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Guidelines for authors  (e.g., manuscript preparation and submission)</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Business information</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Advertising guidelines</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Subscription information</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Customer Service</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Contact information</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Career/job information</cell></row>
</table></p>
</div4>

<div4 type="part" n="02"><head>Journal Functionality</head>

<p><table><head><hi rend="bold">Browsing</hi></head>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Chronologically</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>By subject</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Links within the journal, volume, issue (e.g., article to article links and links to supplementary information within the journal)</cell></row>
</table></p>

<p><table><head><hi rend="bold">Searching</hi></head>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Author</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Title</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Keyword</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Limit by date</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>Help</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>View thumbnail of image</cell></row>
<row><cell>1</cell><cell>2</cell><cell>3</cell><cell>View full-size image</cell></row>
</table></p>
</div4>
</div3>
</div2>

<div2 type="subsection" n="11"><head>11. Appendix D: Archive Workflow</head>

<p rend="center"><figure entity="harvardimage001"><head></head><figDesc>archive workflow</figDesc></figure></p>
</div2>
</div1>

<div1 type="section" n="04"><head>DEJA: A Year in Review</head>

<p rend="center">Report on the Planning Year Grant <lb/>For the Design of a Dynamic E-journal Archive</p>
<p>Presented by: <lb/>Patsy Baudoin, DEJA Project Manager, MIT Libraries <lb/>MacKenzie Smith, Associate Director for Technology, MIT Libraries</p>
<p>To: <lb/>The Andrew W. Mellon Foundation <lb/>30 May 2002</p>

<div2 type="subsection" n="01"><head>EXECUTIVE SUMMARY</head>

<div3 type="part" n="01"><head>INTRODUCTION</head>
<p>The MIT Libraries proposed to the Mellon Foundation to plan a preservation archive for dynamic electronic journals  --  DEJA (Dynamic E-Journal Archive)  --  that would be reliable, secure, enduring, and sustainable over the long term.  The Foundation's own request for proposals had previously laid out that it was interested in preserving the wealth of research electronic journals currently available to the scholarly community before it was too late.</p>
</div3>

<div3 type="part" n="02"><head>STATEMENT OF THE PROBLEM</head>
<p>The Mellon Foundation and librarians know that e-publications are at risk. Many electronic journals won't survive the vagaries of business bankruptcies and mergers nor technology's obsolescence and failures. Knowing this, the Mellon Foundation has challenged its library-grantees to protect the peer-reviewed research that is published on the Web in electronic journals, but effective archiving of electronic materials raises all sorts of challenges.  Besides the technological hurdles, there are many organizational, policy, and managerial problems.  Legal questions as well as educational and cultural issues emerge as some of the most difficult areas to change to enable a smooth transition to archiving electronic journals and an uninterrupted continuation of service to a library's patrons.</p>
</div3>

<div3 type="part" n="03"><head>METHODOLOGY</head>
<p>Our strategy was first to investigate the MIT Press's own scholarly publication site in cognitive science, CogNet.<note target="Deja01">[1]</note>  From there we scoured the world of electronic journals to understand more precisely what aspects of electronic journals made them dynamic and what sorts of provisions  --  repositories, tools, standards, and practices  --  could be used, built, and established to archive their content for the long term.</p>
</div3>

<div3 type="part" n="04"><head>CONCLUSIONS</head>
<p>We arrived at two major conclusions. </p>

<list>
<item>By January 2002, it had become evident that there were not enough scholarly dynamic e-journals to satisfy the Mellon Foundation's stated wish to archive quantities of content. We could not justifiably propose to build a dynamic e-journal archive with only a dozen or so e-journals, however valuable these might be.  We turned our attention to the more immediately pressing issues of archiving the e-journals of small publishers whose specific problems were not being addressed by other Mellon Foundation grantees and which would include the dynamic e-journals we had been interested in archiving in the first place.</item>
<item>Web technologies enable new kinds of publishing and influence how the results of scholarly research are communicated.  In articles we begin to see the inclusion of primary research material and the use of multimedia or other non-textual techniques to convey results.  In journals we see the displacement of traditional concepts, such as "issues" being replaced by rapidly changing Web sites of subject-based content.  As scholars and publishers become more familiar with and confident in the opportunities presented by the Web, use of these technologies <hi rend="italics">will</hi> increase.  However, research in methods of capturing and preserving this type of material is not keeping pace, thus threatening our ability to archive such publications for the future. Research in digital preservation of this type of material is becoming a critical need.</item>
</list>
</div3>
</div2>

<div2 type="subsection" n="02"><head>PRESERVING DYNAMIC ELECTRONIC JOURNALS</head>

<div3 type="part" n="01"><head>1. What is a dynamic electronic journal?</head>
<p>Dynamic electronic journals are often defined as e-journals in which the content changes frequently.  In reality, this is not yet happening much.  E-journals may publish articles as they are ready, without waiting for a whole issue's worth of articles, but this change is sequential addition.  Having arrived at this conclusion early in our investigation, we looked at a definition of dynamic e-journals, namely those that contain moving elements or make elements move.</p>

<list>
<item>Moving elements include, for example, audio and video clips as well as animations. Because moving elements are not printable, libraries can no longer rely on printing the e-journals as a primary preservation strategy.<note target="Deja02">[2]</note> Microfilm and microform are likewise static and cannot accommodate moving elements either. We will refer  to these as "dynamic elements."</item>
<item>E-journals that can make elements move typically include embedded software that enables movement, or scripts and programs that render content on the fly. We will refer to this sort of dynamism as functionality.</item>
</list>

<p>Because one cannot print dynamic e-journals to preserve them, the task at hand is to define new ways of preserving content that makes no sense without these constituent, dynamic aspects.  While we know how to catalog, index, and retrieve moving files, we must refine this cataloging since the elements are embedded in more readily cataloged articles.  Cataloging, indexing, and retrieving the kind of content that cannot be rendered without interactive functionality are particularly vexing hurdles, especially if the content changes with every user's instantiation of that content.  Interactive functionality manifests in many ways, some of which will be illustrated below when we discuss specific electronic journals.</p>
<p>Many questions complicate the preservation of dynamic and interactively functional content:</p>

<list>
<item>In what format are these bits best preserved?</item>
<item>What sorts of metadata do we need to insure their easy recovery?</item>
<item>What measures can be taken against data corruption (bit rot) or loss of data interpretability?</item>
<item>Does software need to be preserved to insure that the saved bits can be rendered? If so, which software and how can we preserve it?</item>
<item>In an article with audio and film clips, how do we preserve the order and placement of each individual file within the broader text file?</item>
</list>

<p>Dynamic electronic journals are a natural outgrowth of Internet and Web technologies. The electronic journals we will be discussing are Web-native: they were born in Web environments and are meant to be rendered and displayed in current Web environments. However we preserve them, for the time being they must also be Web accessible. In the future, it is likely that electronic material will be rendered in other digital (and perhaps even non-digital) environments.</p>
</div3>

<div3 type="part" n="02"><head>2. What content should be preserved?</head>
<p>Of course, besides dynamic elements and functionalities, dynamic e-journals contain text and other intellectually significant elements. The following list delineates several categories of "preservables" about which decisions of inclusion or exclusion must be made at the outset of the archiving process in order to know what to ask publishers to submit to the archive:</p>

<list>
<item>Content  --  intellectual content, including research and so-called supplementary materials</item>
<item>Structure  --  the relationship among items and all of their embeddings</item>
<item>Processes  --  basic Web functionalities (e.g., CGI scripts)</item>
<item>Visual Aspects  --  look and feel, layout, etc., in contrast to dynamic files like audio, video, and animated content</item>
<item>Linkages  --  internal and external hyperlinks which raise important structural questions as well as copyright issues</item>
<item>Interactivity  --  dynamic functionality</item>
</list>

<p>What we archive must be accompanied by the requisite types of metadata that will make it possible for future generations of scholars and researchers to obtain access to the archived materials: descriptive, representational, technical, and administrative metadata at the very least.</p>

<p>We have assumed the long-term preservation of e-journals will require a large repository, replete with ingest functions, search engine, and display mechanisms.  In order for a digital store of this magnitude and complexity to be accessed many years from now, we further assumed, it would have to be exercised, that is, put to use to verify the data's integrity, to insure the functioning of all mechanisms and the usefulness of the metadata, etc.  As directed by the Mellon Foundation's request for proposals, we undertook a thorough analysis of the Open Archival Information System (OAIS) reference model and we ascertained that our e-journal archive could reliably live in the MIT-DSpace infrastructure.<note target="Deja03">[3]</note></p>
</div3>

<div3 type="part" n="03"><head>3. What preservation strategies exist?</head>
<p>The literature about preservation currently reflects several preservation strategies.</p>
<p>Archives may preserve bits "blindly" and rely on digital archaeologists of the future to piece documents and software back together.  To address some of the risks data run  --  such as fragility and decay  --  data refreshing from time to time seems essential. Unfortunately, the unpredictable timing of software and hardware obsolescence, among many other unforeseeable risks and events, spells doom for most material early on in its history. This solution is hardly proactive and begs for alternatives.</p>
<p>Avoiding this archaeological approach leads to thinking more in depth about emulation and migration as more viable preservation strategies.<note target="Deja04">[4]</note> Emulation entails imitating or recreating a software environment so that programs and preserved data appear to run natively.  This preservation strategy would appear to lend itself to capturing the dynamic nature of the electronic journals under our consideration, but at this time the long-term feasibility of emulation  --  what it would take to make it work reliably as a preservation method  --  is hotly contested.<note target="Deja05">[5]</note> Still, given the dynamic specificities of the content at issue in dynamic e-journals, it may be necessary to investigate further the precise ways in which emulation can and cannot be used to preserve dynamic functionality, if not dynamic elements.</p>
<p>Migration currently seems to be the preservation strategy of choice, principally because it is the only and last-resort method in actual use. This approach is recommended for all digital objects one wants to prevent from falling into disuse.  Ideally, a migration policy lays out when and how to transfer data, but knowing when and how to migrate data is only the first in a series of challenges in managing data migration over the long term.  The most important downside of migration as a preservation strategy is inevitable data loss.  In addition, each digital archiving system will have to document its history and processes, create metadata, and otherwise track the many and constantly growing numbers of versions of any give file or dataset.  The urgency of solving the nexus of versioning problems will emerge with the first series of migrations.</p>
<p>All the same, since the interruption of vendor support is a common trigger for migrating data, as are software and hardware obsolescence, migration seems suitable to trying to ensure bit streams survive. It is questionable, however, if migration will be enough to maintain usable environments upon which dynamic functionalities rely to render content usable.</p>
<p>Regardless of the preservation method chosen, at-risk data themselves are best preserved in software-independent formats like SGML or XML for text and metadata.  Other common archivable formats are emerging for still image and graphics files (TIFF, JPEG) or video (MPEG, SMIL).  It remains to be seen what formats can best be used to enhance the likelihood of preserving such dynamic functionality as programs.</p>
</div3>
</div2>

<div2 type="subsection" n="03"><head>THE CHANGING LANDSCAPE</head>
<p>Authors want more and more to take advantage of what the Web can offer in the way of functionality.  Scientists, for example, devise software to carry out and report on their experiments, so it is not surprising to find them asking publishers with increasing frequency to publish software that is incorporated into their articles, software that must be used to understand the research at hand.  If not preserved the science it helps report will also be partially lost.</p>
<p>E-publishers engaged in providing Web instantiations of their print journals report being reluctant to incorporate dynamic functionalities which are expensive propositions in large measure because of their discipline-based varieties.  Publishers also appear reluctant to go down this path until print versions become a thing of the past. They indicate they would do away with print except that librarians insist they not dismiss it until we know better how to preserve electronic publications.</p>
</div2>

<div2 type="subsection" n="04"><head>DYNAMIC ELECTRONIC JOURNALS</head>
<div3 type="part" n="01"><head>The Misleading Case of CogNet</head>
<p>We introduce CogNet into this discussion here because it was a telling starting point to our year of planning.  As will become clear, CogNet is not an e-journal but our careful analysis of it yielded a number of clarifying issues, not the least of which involves the importance of copyright.</p>
<p>CogNet is an MIT Press scholarly communication site for the brain and cognitive science community.  As expected, working with an "in-house" publisher-partner helped sort out many technical, business, and legal issues.  The Press articulated concerns, explained procedures, and generally offered instructive and insightful perspectives on publishing scholarly materials on the Web.  In our proposal to the Mellon Foundation we claimed that CogNet represents a new breed of electronic publication: a site for publishing journals as well as for building community around these journals.  In addition to CogNet, our proposal named other such e-communities, namely Columbia International Affairs Online (CIAO) and Columbia Earthscape of the Electronic Publishing Initiative at Columbia (EPIC).<note target="Deja06">[6]</note>  Each of these maintains its respective discipline's highest standards by publishing peer-reviewed research. Because of the similarities, we looked into both CIAO and Earthscape and traveled to New York City to discuss Columbia's set-up and processes. In the end, however, we decided not to include the two EPIC publications in DEJA.</p>
<p>CogNet is a forward-looking site, but it is not an electronic journal. CogNet, in addition to offering many ancillary services to its community of scholars, brings together monographic and serial publications, all with their own editorial boards.  These publications include several MIT Press books, four MIT Press peer-reviewed journals, and a host of international, peer-reviewed journals published by other publishers.  DEJA's CogNet archiving rights are limited to those owned by the MIT Press.  To clear the rights to archive all of the journals in CogNet, it was soon clear, would be a Herculean task that would introduce another set of hurdles to the already complex rights management needs DEJA would be facing.  Working with CogNet-like portals, as they might properly be called, provides the illusion of working with a single publisher.  In reality, once the rights were cleared, data ingesting processes and procedures would still have to be worked out with each and every publisher individually.</p>
<p>A portal like CogNet feels dynamic as an effect of the hyperlinks. This is what makes for one aspect of the dynamic feeling of all Web experiences. However, as a complex directory it is but a secondary publisher of scholarship, even of the materials copyrighted by the MIT Press that exist in print.</p>
</div3>

<div3 type="part" n="02"><head>The Dynamic E-Journal as Experiment</head>
<p>We next turned to dynamic electronic journals as defined above.  Some of the e-journals we encountered were prime candidates for inclusion in our projected archive because of all we assumed about the value of their peer-reviewed intellectual content.  Most of these journals are already at risk and worth preserving simply because it appears they may not be around very much longer.  Some may consider currently at risk e-journals soon-to-be-failed experiments, with runs not long enough to invest in, but in many cases these are e-journals that took trailblazing risks by implementing innovative dynamic technologies and by putting in place technologically-driven processes which open both the academic and publishing worlds to new futures.  Not archiving these electronic journals means not only losing valuable content, however little of it there may turn out to be on an e-journal by e-journal basis, but more importantly, losing them as significant experiments that future historians of scientific writing, Web publishing, and Web technologies, among others, will sorely miss.</p>
</div3>

<div3 type="part" n="03"><head>Dynamic Content-Mapping</head>
<p>We looked at journals that use hyperlinked maps as their navigation platform on the assumption that the maps not only were the key to accessing intellectual content, but also themselves represented intellectual content.</p>
<p><hi rend="italics">Journal of Artificial Intelligence Research</hi>. JAIR (online at <xref doc="infoarchaimitjairspace">http://www.infoarch.ai.mit.edu/jair/jair-space.html</xref>) offers the JAIR Information Space to guide its users through part of its journal.<note target="Deja07">[7]</note>  Mark A. Foltz conceived and implemented the JAIR Information Space as part of an MA thesis in one of MIT's artificial intelligence labs.  The content mapping technique it uses lays out material in a way that conveys its own meaning, so that "easy judgments can be made about the relative distribution of articles among topics."<note target="Deja08">[8]</note>  The JAIR Information Space also offers a dynamic "details-on-demand" feature that "displays an article's full bibliographic entry and excerpt of the abstract when the pointer is moved over the corresponding article-icon."<note target="Deja09">[9]</note>  The JAIR Information Space is a rare and successful effort to map content and provide visual meaning according to discipline-specific standards and nomenclature.</p>
<p>The project, which opens onto a specific set of the journal's issues, ended when Foltz's doctoral studies took him in another direction.  His contributions to content visualization in electronic journals  --  both the Information Space at JAIR and his documentation  --  may well be worth preserving for future researchers.</p>
<p><hi rend="italics">The Astrophysical Journal</hi>. Users gain open and free access to the <hi rend="italics">Astrophysical Journal</hi> via the University of Strasbourg (at <xref doc="simbadustrasbgfrApJmap">http://simbad.u-strasbg.fr/ApJ/map.pl</xref>) by clicking deeper and deeper into maps. Clicking on a map dynamically generates the next-level map, and so on, until the system displays the requested article.  The maps are dynamically generated and visually represent topical relationships.  It seemed at first there was no other way into the journal's content, which is indeed the case at this URL. We learned later, however, that most astronomers and astrophysicists around the world still access the <hi rend="italics">Astrophysical Journal</hi>'s contents (also at no fee) via the Astrophysics Data System (ADS) site at Harvard,<note target="Deja10">[10]</note> where users must slog through a rather unfriendly, but more conventional, pre-Web-looking approach to content. The user-friendly University of Strasbourg interface may be a harbinger of things to come.</p>
</div3>

<div3 type="part" n="04"><head>Dynamic Editorial Process</head>
<p>Most e-journals, precisely because they are born of an all-print environment, remain tied to print preparation processes.  They rely on well-established procedures to take an article through its life cycle, from its authoring to its publication.  By now many publishers have introduced email as the primary means of communicating and transferring data, but few use the Web as an administrative-editorial platform. Those who do tend to be electronic-only publishers and they are instituting new and exciting new practices.</p>
<p>JIME, the <hi rend="italics">Journal of Interactive Media Education</hi> (<xref doc="jimeopen">http://www-jime.open.ac.uk</xref>), has been a pioneer in several regards.<note target="Deja11">[11]</note>  JIME's primary audience comprises education technologists and it uses their disciplinary expertise to develop the e-journal site.  For the JIME editors, "knowledge construction" is an iterative and collaborative process.  Inasmuch, the scholarly debate does not start with publication but early in the peer review process.  To this end, JIME developed and implemented the Digital Document Discourse Environment (D3E), software enabling a document-discussion-anchored publication to emerge.  The decision to use this software as a backbone has broad ramifications that reach beyond the process-oriented exigencies it satisfies technologically.</p>
<p>This platform fosters scholarly debate at all stages in the life cycle of an article.  As is made clear in the diagram below, during and after the Public Open Peer Review phase, readers, authors, and reviewers may all take part in a discussion that builds on the earlier, private open peer-review.<note target="Deja12">[12]</note></p>
<p>Working at any stage on the e-journal site, authors, editors and reviewers invoke the Web's capacity to streamline the editorial and review processes by relying on its dynamic, functional interactivity.  We found no other electronic journals that have taken on this collaborative aspect of e-publishing as radically as JIME.</p>
<p>It is worth noting that while e-journals and other scholarly e-community sites have generally failed in their attempts to establish threaded discussions, JIME appears to have a critical mass of such activity, owing in part to its enabling interactive software.  This e-journal is available at no cost.</p>

<p><figure entity="MITimage001"><head><hi rend="italics">The JIME review life cycle, showing the private and public open <lb/>peer review phases, and the active stakeholders at different points.</hi><note target="Deja13">[13]</note></head><figDesc>JIME review life cycle</figDesc></figure></p>
</div3>

<div3 type="part" n="05"><head>Dynamic Elements: Audio, Video, and Multimedia</head>
<p>The use of thumbnails (small image files) as clickable links to still images is common in many disciplines.  The thumbnail serves several functions. Perhaps most importantly, a thumbnail graphic can be transmitted to a browser far more efficiently than its larger counterpart.  Secondly, a thumbnail provides both a tease and a glimpse of what the authors have to display with their texts.</p>
<p>The prevalence of thumbnails and the myriad ways they are used can be gleaned from glancing at any number of e-journals.  <hi rend="italics">Architronic: The Electronic Journal of Architecture</hi> (<xref doc="architronicsaedkent">http://architronic.saed.kent.edu</xref>), <hi rend="italics">Conservation Ecology</hi> (<xref doc="consecolJournal">http://www.consecol.org/Journal</xref>), and <hi rend="italics">Earth Interactions</hi> (<xref doc="earthinteractions">http://earthinteractions.org</xref>) illustrate the varieties of visuals that appear as thumbnails: pictures, graphs, pie charts, data tables, drawings, etc. Alan Dodson's "Performance and Hypermetric Transformation: An Extension of the Lerdahl-Jackendoff Theory" appears in <hi rend="italics">Music Theory Online</hi> (<xref doc="societymusictheorymtoissuesmto0281dodson">http://www.societymusictheory.org/mto/issues/mto.02.8.1/mto.02.8.1.dodson.html</xref>). Viewable with or without frames, access to images and audio clips are easy and numerous.</p>
<p>The <hi rend="italics">Interactive Multimedia Electronic Journal of Computer-Enhanced Learning</hi> (IMEj of CEL) (<xref doc="imejwfu">http://imej.wfu.edu</xref>) is, not surprisingly given its purpose, replete with examples of static and dynamic visuals of all sorts.  To know at a glance what each article might include in the way of non-text media, scroll through any article: iconic indicators with short captions appear in the right-hand margin.  For example, an article entitled "The Biology Labs On-Line Project: Producing Educational Simulations That Promote Active Learning," by Jeffrey Bell of California State University<note target="Deja14">[14]</note> includes just under a dozen QuickTime video clips and at least as many thumbnails, still shots, graphics, and/or screenshots.  In one instance, the caption reads "A QuickTime movie (533 KB) showing how the DemographyLab works." In another article, entitled "Learning Greek with an Adaptive and Intelligent Hypermedia System," a caption-less icon indicates where the reader may view an online demonstration that runs in Shockwave, an easy to download plug-in.  There are movies of screenshots that demonstrate how software works to help students flag grammatical or word order errors in their work.</p>
<p>In some electronic journals, dynamic non-text elements often end up as "supplementary material." Since one cannot print film and audio clips or multimedia of any sort, supplementary materials typically grace e-journals with print editions.  The decision to include multimedia as a separate file provides the publisher an opportunity to highlight multimedia content and thereby promote and market the e-journal as desired.  A simple example of this occurs at <hi rend="italics">Optics Express</hi>.  The e-journal's home page (<xref doc="opticsexpress">http://www.opticsexpress.org</xref>) teases the reader with an animated image and a caption that includes a link to information about a current related article. By following the link, the reader can then access both a PDF version of the text of the article and the separately presented multimedia element.</p>
<p>Since 1998, a subscription to the <hi rend="italics">Computer Music Journal,</hi> published by the MIT Press, includes an annually produced CD-ROM of music and sound related to the articles the e-journal has published in the course of the year.  One can also purchase the CD-ROM separately. The e-journal itself seems devoid of music and sound files.</p>
<p>In the humanities and the arts especially, readers may come across multimedia applications that offer artistic depth or breadth in support of the content at hand, sometimes nearly stealing the show! Such is the case in one <hi rend="italics">Postmodern Culture</hi> article on filmmaker Dziga Vertov's Kino-Eye.<note target="Deja15">[15]</note> A pulsing eye-camera lens greets the reader with visual echoes of the topic at hand.  The image's caption reads, "Animated image constructed by author [Joseph Christopher Schaub] using <hi rend="italics">Man With a Movie Camera</hi> production stills."</p>
<p>The <hi rend="italics">Journal for MultiMedia History</hi> (<xref doc="albanyjmmh">http://www.albany.edu/jmmh</xref>), published by the Department of History at the University of Albany, is a most interesting example of multimedia-enhanced research because its practice demonstrates how paradigms can shift rather easily and to useful ends.  JMMH did not adopt the publish-as-needed model that Web technologies make possible and that most electronic-only journals embrace. Instead, it publishes a single issue per year; it also breaks with the traditional article or text-centered approach to journal publishing.  For example, the feature article of the 2000 issue introduces the documentary photographer George Harvan.<note target="Deja16">[16]</note> This entry comprises a database of the photographer's images, a set of interviews to read or listen to via audio files, and a handful of historical essays with their attendant reference links.  The three-part entry does not bear the shape of a classic article  --  although JMMH has chosen to call these multi-part entries such  --  nor is it conceived as a book. Presumably, additions to any part of it may be added at any time.  The power of the JMMH site stems from its soundness as scholarship, wielding as it does ample, well-managed resources in miniature repository-like entries that individually and collectively command intellectual presence and value.<note target="Deja17">[17]</note> The site privileges neither text over image, nor text over database; instead, each piece articulates depth and stands up to the tests of rigor.</p>
</div3>

<div3 type="part" n="06"><head>Dynamic Functionality</head>
<p>Among those concerned with how we will preserve our peer-reviewed heritage, there is little doubt that preserving dynamic functionality is the highest obstacle to overcome. Dynamic elements and their textual kin are files that will be similarly wrapped with appropriate metadata and migrated following whatever policies might be put in place.  Unlike dynamic elements, however, dynamic functionalities defy simple preservation. Fortunately, as we have learned this year, there isn't too much of it.  Authors, publishers, and librarians can imagine doing far more with the current available technologies than is actually being done.</p>
</div3>

<div3 type="part" n="07"><head>Required Plug-ins</head>
<p>All journals presenting materials in the Portable Document Format (PDF) require users to download Adobe's Acrobat Reader, a common and easily accessible plug-in.  E-journals often require downloading other plug-ins.  Many e-journals in chemistry and chemistry-related disciplines, for example, make use of Chime, an increasingly common plug-in that enables readers to view and manipulate representations of chemical compounds.</p>
<p><hi rend="italics">The Journal of Insect Science</hi> (JIS) is a faculty-library collaboration at the University of Arizona, available only online, free of charge (<xref doc="insectscience">http://www.insectscience.org</xref>). In "A Call for Change in Academic Publishing," editor Harry Hagedorn presents his concern for the untenable rates imposed on libraries who want to subscribe to the journal he had previously edited.<note target="Deja18">[18]</note>  Like rivulets plowing new beds, e-journals, thanks to Web technologies, are sprouting new business frameworks, sometimes with concomitant new business models.  To make its way among the journals in this field and to offer solace to those whose professional future depends upon being cited, the journal seeks visibility through inclusion in Chemical Abstracts, Agricola, CAB and BIOSIS.</p>
<p>JIS files are SGML- and XML-formatted, enabling not only structured access to documents but extractions across documents as well.  Contents are displayed in PDF if the content is static.  Since JIS encourages its authors to submit multimedia elements (e.g., color images, graphs, and diagrams; video and sound files; internal and external links; and datasets), some plug-ins may be required to make sense of the content. For example, to illustrate the principles of phylogenic reconstruction, MacClade or PAUP software might need to be used within an article.<note target="Deja19">[19]</note></p>
</div3>

<div3 type="part" n="08"><head>Personalization Tools </head>
<p>Some customization tools can serve several purposes. Tools such as alerting services that send emails with news about newly published articles and other content-related events promote the use of the e-journal's site, but do not directly influence content delivery or usability. Other tools affect the content more directly and beg for ways to be preserved.</p>
<p><hi rend="italics">The Internet Journal of Chemistry</hi>. IJC (<xref doc="ijc">http://www.ijc.com</xref>) explores the potential Web technologies offer.  The journal's files are not stored as PDF or HTML files, but instead are served up dynamically or on-the-fly. It offers the most straightforward and unencumbered testing ground for researching on-the-fly generation of scholarly content.  In addition, approximately seventy-five percent of the articles contain interactive elements.<note target="Deja20">[20]</note>  IJC editor Steven Bachrach, who engages the help of students to manage conversions and production, likes authors to be able to submit materials in their preferred formats,<note target="Deja21">[21]</note> thereby increasing the likelihood that readers will have to download appropriate plug-ins to ensure that all content can run as intended.</p>
<p>In addition to lifting constraints on authors who may want to take full advantage of new technologies, IJC offers readers an extensive range of customization preferences that complicate the task of preserving content.  IJC includes tools for readers to control layout, fonts, and color schemes. Readers can decide where to display footnotes (low on the page or in a floating window); they can create annotations and then decide whether to view these annotations within the document's frame or in a floating window. Readers can also personalize formats to view chemical structures a number of different ways: as standard GIF/JPEG images, using links to a data file, as embedded objects, or other options.</p>
<p>The IJC is not alone in offering annotation tools and preferences, but IJC annotations are private.  In contrast, the <hi rend="italics">Journal of Universal Computer Science</hi> (J.UCS) (<xref doc="jucs">http://www.jucs.org</xref>) offers readers not only public annotation and comment features but also labeling options (e.g., question, answer, problem, solution, advice, etc.).</p>
</div3>

<div3 type="part" n="09"><head>Discussion Forums and Threaded Discussions</head>
<p>As pointed out above, the <hi rend="italics">Journal of MultiMedia History</hi> removed a threaded discussion feature from its site when it was decided it was unsuccessful.  Many e-journal sites include areas where experts discuss published content, but there is little activity and often ill-targeted interventions.  Speculation abounds as to why.  In contradistinction, JIME's success in this regard may be attributed to its editors' philosophy of initiating open discussion in the early stages of the peer-review process.  The <hi rend="italics">British Medical Journal</hi>'s "Rapid Response" section also appears active and on-topic.<note target="Deja22">[22]</note></p>
</div3>

<div3 type="part" n="10"><head>Other Dynamic Functionalities</head>
<p>Some e-journals, besides their worthy content, offer particularly compelling dynamic features and instances of interactivity that simply cannot be found elsewhere in peer-reviewed e-journals.  <hi rend="italics">The Journal of Electronic Publishing</hi> (JEP) (at <xref doc="pressumichjep">http://www.press.umich.edu/jep</xref>) is an electronic-only publication that published a single hypertextual article. Its fragmented nature is presumably key to its meaning or at least to the freedom the author wanted readers to experience.<note target="Deja23">[23]</note>  <hi rend="italics">Linguistic Discovery</hi> (<xref doc="linguisticdiscoverydartmouthLinguistics">http://linguistic-discovery.dartmouth.edu/WebObjects/Linguistics.woa</xref>) specializes in foreign languages that are becoming extinct, which is all the more reason to preserve this brand new electronic-only journal. The fruit of collaboration between Dartmouth faculty members and their library, <hi rend="italics">Linguistic Discovery</hi> promises to pose some challenging archival questions depending on how they manage their character sets and alphabets.</p>
<p>Deciding what dynamic functionalities need to be archived will orient future research in this area.  <hi rend="italics">Cultivate Interactive</hi> (<xref doc="cultivateint">http://www.cultivate-int.org</xref>), considered a "Web magazine" because it is not peer-reviewed, displays extensive use of dynamic interactivity.  One example worth singling out is a service which provides software for translating articles into major European languages.  The University of Chicago Press offers readers far more than keyword searching: they provide a facility to input reference queries to find out how many times and where published articles are cited.  HighWire offers cross-publisher searching.  How ought we to think about preserving such translation and search algorithms?</p>
</div3>

<div3 type="part" n="11"><head>The Question of Metadata</head>
<p>Our planning took place knowing that MIT's DSpace initiative would provide the physical infrastructure for "housing" the DEJA archive. Because DSpace implements the Open Archival Information System (OAIS) reference model<note target="Deja24">[24]</note> to handle submission, storage management, preservation planning, and access, our planning also included determining formatting for the OAIS Information Packages: SIPs, AIPs, and DIPs.<note target="Deja25">[25]</note></p>
<p>As stated earlier, the DSpace system implements the OAIS reference model and so includes an archival storage subsystem.  In DSpace, AIPs for digital items are encoded using the Metadata Encoding and Transmission Standard (METS), an emerging standard of the digital library community.<note target="Deja26">[26]</note>  METS has also been identified as a reasonable way to encode the SIPs received from publishers, and as a mechanism to support the exchange of DIPs with other archives in the event of an archive closing.  METS provides for packaging together the descriptive metadata about the journal (at the issue, article, or other level of granularity), the technical metadata about the component files of the journal (e.g., PDF articles, TIFF image files, MPEG audio/visual files, or even SGML-encoded full text files).  It can also model the structure of the journal issue, article, etc.  Recently the METS standard has been expanded to support the encoding of complex Web sites using the XLink standard of the World Wide Web Consortium.<note target="Deja27">[27]</note> In METS we have a standardized way to package all the necessary content and metadata together for both exchange and archiving.  What we still lack is a sense of what metadata to capture, particularly technical metadata (or OAIS Representation Information) about the dynamic functionality of e-journal content.</p>
</div3>
</div2>

<div2 type="subsection" n="05"><head>Conclusions</head>
<p>The questions raised in the process of preserving dynamic functionality will be similar to those for archiving static content.  In both cases, we will have to rely on migrating data and/or emulating systems, but to preserve dynamic functionality we will need to track additional factors and create and maintain more complex and varied metadata.</p>
<p>When we understood that we could not meet the Mellon Foundation's mandate for quantity of significant scholarly content by focusing strictly on dynamic functionality, we decided to expand the scope of our project to include small electronic journals which were, in one way or another, ushering in new processes, techniques, business models, and so on.  The dynamic electronic journals at stake in this discussion have in common that they are all relatively small.  They have not grown sufficiently yet to outlast the behemoths with whom they compete, but their hope of doing so rests on their ability to innovative with the same or less technology than their bigger rivals.</p>
<p>Our working definition of small has been <hi rend="italics">infrastructurally</hi> small.  A publisher's various infrastructures make the preparation of materials for archiving more or less burdensome.  The small publishers we looked at had little personnel, few financial means, and/or an unsophisticated but serviceable technological infrastructure.  To preserve the publications of these small enterprises, special attention needs to be paid to those areas that hamper the publisher's ability to ready resources for submission to the archive.</p>

<div3 type="part" n="01"><head>Small, Somewhat Dynamic E-Journals</head>
<p>As a Scholarly Publishing &amp; Academic Resources Coalition (SPARC) e-journal group that publishes electronic versions of some nearly fifty small- and mid-sized print journals, BioOne offers quantity in addition to quality.<note target="Deja28">[28]</note> In addition, while publishing relatively small publications to make them more accessible, BioOne's publishing systems are quite sophisticated.  It serves up mostly static SGML files and metadata from a content management database.  BioOne's conversion and production work is outsourced to the Allen Press, whose responsibility it also is to maintain their servers, guarantee back-ups, and so on.</p>
<p>Among the eleven publications of the American Meteorological Society (AMS), <hi rend="italics">Earth Interactions</hi> (<xref doc="earthinteractions">http://earthinteractions.org</xref>) is uniquely electronic-only, although all of the Society's journals are available on the Web.<note target="Deja29">[29]</note>  The Society outsources online production to the Allen Press but maintains control of the editorial process. Our decision to work with small publishers made it easy to decide to partner with Keith Seitter and the AMS to archive all of its electronic publications.  As a lot, they represent all of the static and dynamic technological problems we would have to address in a first instantiation of the archive, including mathematics symbols, resolution questions for highly differentiated images, some interactivity, and so forth.</p>
<p>Two other SPARC-partnered electronic journals, <hi rend="italics">Algebraic and Geometric Topology</hi> (<xref doc="mathswarwickagt">http://www.maths.warwick.ac.uk/agt/</xref>) and <hi rend="italics">Geometry and Topology</hi> (<xref doc="mathswarwickgt">http://www.maths.warwick.ac.uk/gt/</xref>), are among the very smallest e-journals around, but neither of these is dynamic. Both are published by the Mathematics Department of the University of Warwick at Coventry in the United Kingdom.  They Web-publish as required and print as needed, owing to their ability to avail themselves of their University's infrastructure.  Their most Web-like feature is the availability of multiple formats, not including HTML which cannot display mathematical equations.  Both journals are being archived with Paul Ginsparg's ArXiv at Cornell University, for at least ten years.</p>
<p>Finally, the largest and one of the newest (established Summer 2001) electronic-only publishing ventures warrants mentioning precisely because it is the exception.<note target="Deja30">[30]</note> <hi rend="italics">TheScientificWorldJournal</hi> (<xref doc="thescientificworld">http://www.thescientificworld.com</xref>) is the intellectual heart of an extremely rich "scholarly knowledge network" for scientists of many different stripes.<note target="Deja31">[31]</note> Its content, which includes peer-reviewed articles, also makes available research papers, reviews, and other primary research documents which may contain multimedia and dataset-like enhancements to the science being reported.  What is striking about <hi rend="italics">TheScientificWorldJournal</hi> is indeed the amount of intellectual enhancement the journal takes on as an entire Web site.</p>
</div3>

<div3 type="part" n="02"><head>Licensing for E-Journal Archives</head>
<p>In a one-day workshop convened on February 25, 2002, with representatives of several small publishers and the DEJA and DSpace teams, we explored the business issues related to archiving the publications of this set of publishers.  Since these publishers are either non-commercial or not high-profit-motivated (e.g., SPARC journal publishers), they were, as a group, quite willing to accept licensing agreements that would allow the e-journal archive to make their content available to the public for free in relatively short time frames (e.g., three to five years).  They were also willing to consider subsidizing the archives of their publications, like the large commercial publishers working with other Mellon grantees, but do not have the resources to do so without passing the costs back to their subscribers or members (in the case of scholarly societies).  Again like the large publishers, they wish to decide how to present such charges to their subscribers rather than having it determined in the license with the archive.  The publishers we worked with were uniformly concerned about finding ways to archive their material by third parties. They were less confident of being able to archive their own material for the long-term (unlike the large commercial publishers) and were cognizant of the importance of finding archiving solutions to ensure the long-term viability of their titles.</p>
</div3>

<div3 type="part" n="03"><head>Final Recommendations</head>
<p>This project has identified that much more research is needed to understand how to preserve dynamic e-journals, including exploring what migration or emulation strategies will be required to preserve the types of dynamic functionality we have defined, what kinds of metadata will be needed to support preservation, how to track migration versions, and so on.  It is our hope that such research can, and will, be undertaken soon so this important cultural material is not lost permanently.  Doing such research, however, was far outside the scope of the current project. All we can do is identify the areas of most pressing research need: finding mechanisms to preserve dynamic e-journal content (e.g., functional programs, plug-ins, moving content, and so forth); identifying the technical metadata needed to support that preservation; and building cost models for doing such preservation.</p>
</div3>
</div2>

<div2 type="subsection" n="06"><head>Postscript: 2003</head>
<p>The MIT Libraries are not currently pursuing third party e-journal archiving as an active area of research. Our primary efforts have shifted to archiving and preservation of born-digital research material produced by the MIT faculty, flexible metadata support built on Semantic Web technologies, and interoperability across various digital library/archive and course management systems. The MIT Libraries are leading the DSpace Federation, a consortium of research institutions, libraries, and other cultural heritage institutions that are using MITs open source digital repository system (see <xref doc="dspace">http://dspace.org</xref>). We are also actively involved in the Global Digital Format Registry (GDFR) project, as well as the Metadata Encoding &amp; Transmission Standard (METS at <xref doc="locstandardsmets">http://www.loc.gov/standards/mets</xref>) and the PREMIS Project (PREservation Metadata: Implementation Strategies at <xref doc="oclcresearchprojectspmwgdefault">http://www.oclc.org/research/projects/pmwg/default.htm</xref>).</p>
<p>Update on JIME: The underlying publishing engine has been released as D3E (Digital Document Discourse Environment), a generic tool for others to publish their own e-journals modelled on JIME's infrastructure (see <xref doc="d3esourceforge">http://d3e.sourceforge.net</xref>). D3E underpins the Journal of Co-Counselling (<xref doc="journalcocornucopia">http://www.journal.co-cornucopia.org/</xref>), is used for peer review in the NSF-funded Digital Library for Earth System Education (DLESE at <xref doc="dlese">http://www.dlese.org/</xref>), and by the University Corporation for Atmospheric Research (UCAR) to connect their software developers with their academic user community (<xref doc="unidataucarcommunitycommitteesumada">http://www.unidata.ucar.edu/community/committees/umada/</xref>). A version has also been released with the Open Archives Eprints software from Southampton University, called D3Eprints (<xref doc="d3esourceforged3eprints">http://d3e.sourceforge.net/d3eprints.html</xref>).</p>
</div2>

<div2 type="subsection" n="07"><head>Endnotes</head>
<note id="Deja01">[1] See MIT's CogNet at <xref doc="cognetmit">http://cognet.mit.edu</xref>.</note>
<note id="Deja02">[2] Librarians continually struggle with managing shelf and storage space for print resources.</note>
<note id="Deja03">[3] For detailed information on the DSpace digital repository system see <xref doc="dspace">http://www.dspace.org</xref>.</note>
<note id="Deja04">[4] For discussions and perspectives on this topic, see David Bearman, "Reality and Chimeras in the Preservation of Electronic Records," <hi rend="italics">D-Lib Magazine</hi> 5.4 (April 1999), online at <xref doc="dlibapril99bearman04bearman">http://www.dlib.org/dlib/april99/bearman/04bearman.html</xref>; Margaret Hedstrom and Clifford Lampe, "Emulation vs. Migration: Do Users Care?" <hi rend="italics">RLG DigiNews</hi> 5.6 (15 December 2001), online at <xref doc="rlgpreservdiginews56feature1">http://www.rlg.org/preserv/diginews/diginews5-6.html#feature1</xref>; and Jeff Rothenberg, <hi rend="italics">Avoiding Technological Quicksand: Finding a Viable Technical Foundation for Digital Preservation</hi>, Publication 77 (Washington, DC: Council on Library and Information Resources, January 1999), online at <xref doc="clirpubsreportsrothenbergcontents">http://www.clir.org/pubs/reports/rothenberg/contents.html</xref>.</note>
<note id="Deja05">[5] Hedstrom and Lampe.</note>
<note id="Deja06">[6] See <xref doc="columbiaculibrariesdigitalprojectsepic">http://www.columbia.edu/cu/libraries/digital/projects/epic.html</xref>.</note>
<note id="Deja07">[7] From its inception in 1993, JAIR was an electronic journal. The JAIR Information Space was introduced in June 1998.</note>
<note id="Deja08">[8] Mark A. Foltz, "An Information Space Design Rationale" (Last modified 20 June 2002). Online at <xref doc="infoarchaimitjairrationale">http://www.infoarch.ai.mit.edu/jair/jair-rationale.html</xref>. This description of the project covers both conceptual and technical aspects of its implementation.</note>
<note id="Deja09">[9] <hi rend="italics">Ibid</hi>.</note>
<note id="Deja10">[10] The ADS site is <xref doc="adsabsharvardabstractservice">http://adsabs.harvard.edu/abstract_service.html</xref>.</note>
<note id="Deja11">[11] Simon Buckingham Shum and Tamara Sumner, "JIME: An Interactive Journal for Interactive Media," <hi rend="italics">First Monday</hi> 6.2 (February 2001). Online at <xref doc="firstmondayissues62buckinghamshum">http://firstmonday.org/issues/issue6_2/buckingham_shum</xref>; reprinted in <hi rend="italics">Learned Publishing: Journal of Association of Learned and Professional Society Publishers</hi> 14.4 (October 2001): 273-285. Online at <xref doc="catchwordalpsp09531513v14n4contp11">http://www.catchword.com/alpsp/09531513/v14n4/contp1-1.htm</xref>.</note>
<note id="Deja12">[12] The entire process of this private and public pre-print peer review system is described in detail at <xref doc="jimeopen">http://www-jime.open.ac.uk</xref> under "About JIME." The editors have written at length about the peer-review process and changes in scholarly publishing. See Tamara Sumner, Simon Buckingham Shum, <hi rend="italics">et al</hi>, "Redesigning the Peer Review Process: A Developmental Theory-in-Action," <hi rend="italics">Proc. COOP'2000: Fourth International Conference on the Design of Cooperative Systems</hi> (Sofia Antipolis, France: 23-26 May 2000); and Tamara Sumner and Simon Buckingham Shum, "From Documents to Discourse: Shifting Conceptions of Scholarly Publishing," Technical Reports KMI-TR50 (UK: Knowledge Media Institute, Open University, 1998).</note>
<note id="Deja13">[13] We thank the editors of JIME for permission to use this diagram here.</note>
<note id="Deja14">[14] Online at <xref doc="imejwfuarticles1999201index">http://imej.wfu.edu/articles/1999/2/01/index.asp</xref>.</note>
<note id="Deja15">[15] Joseph Christopher Schaub, "Presenting the Cyborg's Futurist Past: An Analysis of Dziga Vertov's Kino-Eye," <hi rend="italics">Postmodern Culture</hi> 8.2 (January 1998). Available online to subscribers through Project Muse (<xref doc="musejhu">http://muse.jhu.edu</xref>).</note>
<note id="Deja16">[16] Thomas Dublin and Melissa Doak, "Miner's Son, Miners' Photographer: The Life and Work of George Harvan," JMMH 3 (2000). Online at <xref doc="albanyjmmhvol3harvanindex">http://www.albany.edu/jmmh/vol3/harvan/index.html</xref></note>
<note id="Deja17">[17] It is worth noting that the discussion environments that had once appeared as a feature of the JMMH were removed for lack of activity.</note>
<note id="Deja18">[18]  At <xref doc="insectscienceaboutchange">http://www.insectscience.org/about/change</xref>.</note>
<note id="Deja19">[19] MacClade software is described at <xref doc="macclade">http://macclade.org/</xref>. PAUP, which stands for Phylogenetic Analysis Using Parsimony, is described at <xref doc="paupcsitfsu">http://paup.csit.fsu.edu/</xref>.</note>
<note id="Deja20">[20] In conversation with IJC editor, Steven Bachrach.</note>
<note id="Deja21">[21] For a detailed account of other interactive functionality in IJC, see Gerry McKiernan, "The Internet Journal of Chemistry: A Premier Eclectic Journal," <hi rend="italics">Library Hi Tech News</hi> 18.8 (September 2001): 27-35.</note>
<note id="Deja22">[22] It is important to note that the technologies that make discussions, chats, thread, and so on available in general have spawned entire new genres of professional, though not peer-reviewed, genres.  Slashdot (<xref doc="slashdot">http://slashdot.org</xref>), for example, accommodates discussions among engineering professionals alongside interventions by commentators and journalists, average users, and others with advice and opinions.  The democratic peer rating system that rates published interventions is arguably a new model for peer-review in an environment where traditional peer-review is under scrutiny.</note>
<note id="Deja23">[23] Mindy McAdams and Stephanie Berger, "Hypertext," JEP 6.3 (March 2001). Online at <xref doc="pressumichjep0603McAdamspages">http://www.press.umich.edu/jep/06-03/McAdams/pages/</xref>.</note>
<note id="Deja24">[24] The OAIS reference model documentation is available online at <xref doc="wwwclassicccsdsdocumentsCCSDS6500B1">http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf</xref>.</note>
<note id="Deja25">[25] The OAIS model requires a "producer" to submit a "Submission Information Package" or SIP to an archive, where it is managed as an "Archival Information Package" or AIP and delivered to consumers as a "Dissemination Information Package" or DIP.</note>
<note id="Deja26">[26] METS documentation is available online at <xref doc="locstandardsmets">http://www.loc.gov/standards/mets</xref>.</note>
<note id="Deja27">[27] Xlink documentation is available online at <xref doc="w3TRxlink">http://w3.org/TR/xlink</xref>.</note>
<note id="Deja28">[28] BioOne is available by subscription at <xref doc="bioonerequestindex">http://www.bioone.org/bioone/?request=index-html</xref>.</note>
<note id="Deja29">[29] The American Meteorological Society's ten other publications are currently available both in print and on the Web at <xref doc="amsallenpressamsonlinerequestindex">http://ams.allenpress.com/amsonline/?request=index-html</xref>.</note>
<note id="Deja30">[30] Among the features that distinguish the <hi rend="italics">ScentificWorldJournal</hi> from other e-journals is that it rests at the center of an e-community, The ScientificWorld, which offers many e-commerce services.</note>
<note id="Deja31">[31] Gerry McKiernan, "The ScientificWorld: An Integrated Scholarly Knowledge Network," <hi rend="italics">Library Hi Tech News</hi> 19.2 (March 2002): 21-29.</note>
</div2>
</div1>


<div1 type="section" n="05"><head>The New York Public Libraryc <lb/>Archiving Performing Arts Electronic Resources: <lb/>A Planning Project</head>

<p rend="center"><figure entity="NYPLimage001"><head></head><figDesc>nypl-logo</figDesc></figure></p>

<p rend="center"><hi rend="italics">Report to The Andrew W. Mellon Foundation <lb/>Mellon Electronic Journal Archiving Program</hi></p>

<p rend="center">31 July 2002</p>


<div2 type="subsection" n="01"><head>Summary</head>
<p>Through the New York Public Library's participation in the Mellon Electronic Journal Archiving Program, the Library was able to conduct a detailed investigation into the issues related to establishing a secure repository for archived electronic resources in the performing arts.</p>
<p>The project gave the Library the opportunity to gain a thorough knowledge of the landscape of electronic publishing in music, theater, dance, and film, and it also allowed the Library to investigate the special issues that must be addressed when planning for the long-term preservation of information in electronic format.  Electronic content that has been the focus of archival studies and archival projects  --  including work by other libraries participating in the Mellon Electronic Journal Archiving Program  --  has mainly consisted of lengthy, highly structured, and professionally produced journal runs that are the product of major publishers, most typically in scientific, technical, and medical (STM) fields.  Among electronic resources in the performing arts, however, few examples can be found that fit this profile.  Instead, these resources are most typically produced by publishers  --  individuals or small groups of like-minded people  --  with few financial resources who produce only a single title as a labor of love. Consequently, the Library took a broad view of the term "electronic journal" for its project, although it concentrated on resources that were "journal-like," that is, resources that are produced in a serial fashion, containing content of interest to sophisticated research by professionals and scholars.</p>
<p>Among the project's substantial contributions were the identification of a large number of such resources currently available which will be of special interest to the field of the performing arts, and the responses of e-publishers to a survey regarding electronic preservation issues. Another major contribution will be of interest both in and outside the field: the results of the Library's investigations into methods for gathering electronic content in a systematic fashion with the purpose of building and maintaining the archive.  The issues raised here will be of interest to librarians, publishers, and others concerned with preserving electronic information that is "off the beaten path." Created without the backing of major publishers or academic institutions, this is information produced outside of traditional major channels of publication and distribution, the new "gray literature."</p>
<p>Ultimately, the Library decided not to submit a second-stage implementation proposal to the Mellon Foundation, although the Library will continue to explore some more limited preservation efforts within the framework of a collaborative project led by Stanford University.  The following report gives details on the project's analysis of the landscape of performing arts electronic resources, work on content development and implementation planning, and the strategic thinking that went into the decision not to proceed at this time with an implementation effort that builds directly on the results of the planning project reported on here.</p>
</div2>

<div2 type="subsection" n="02"><head>Introduction</head>
<p>Research libraries are concerned to a great degree with preservation.  Today, this concern extends not only to the preservation of the manuscripts, books, periodicals, films, recordings, and other materials that line their shelves, but also to preservation of their intellectual content.  An archival manuscript, for example, comprises the text and the physical artifact, and both are valuable research resources.  Historically, library preservation has extended to the physical conservation of archival collections, the preservation of topical information such as newspapers and journals in the form of microfilm and microfiche, and the protection of degradable materials through appropriate environmental controls. However, the increasing production of information in electronic form has opened up new avenues of exploration in the area of archival preservation.  Major research institutions such as the New York Public Library as well as electronic publishers themselves now face the added challenge of ensuring that electronic scholarly journals and publications collected by libraries will be accessible to future generations of readers and scholars.</p>
<p>To this end, the New York Public Library, in response to the Andrew W. Mellon Foundation's invitation for participation in the Mellon Electronic Journal Archiving Program, undertook a planning project that focused on archiving electronic journals in the performing arts to address the long-term preservation of these materials.</p>
<p>The New York Public Library has, from its very beginnings, placed a high priority on safeguarding all its collections for the future, establishing one of the first preservation programs in a research library.  Today, the Library hosts one of the nation's largest such programs and works actively together with other leading institutions on addressing important issues related to the preservation of library materials.</p>
<p>The Library has also shown strong leadership in the application of digital technology through a highly sophisticated digital library program now in development that will make hundreds of thousands of materials from its research collections available on the Internet.  As part of this program, the Library has given special attention to the establishment of systems, policies, and procedures for archiving information in electronic form.</p>
<p>The choice to focus on the domain of performing arts was made for two very sound reasons:</p>
<p>First, the Foundation's invitation to participate in the Electronic Journal Archiving Program caused the Library to think in new ways about future readership of scholarly electronic materials in subject collections that are special strengths for the Library, such as the dance, music, and recorded sound collections at the New York Public Library for the Performing Arts.  This facility serves a broad constituency of hundreds of thousands of annual users  --  dancers, musicians, actors, playwrights, conductors, choreographers, stage directors, critics, historians, teachers, students, and people from all walks of life  --  and has become an unparalleled resource for information in the performing arts. While many research libraries have overlapping electronic collections, especially in the realm of science, technology, and medicine, and a reader is able to access information from a variety of services, the Library for the Performing Arts is focused on providing subject-specific materials that are not widely collected or widely available through a single resource.</p>
<p>Second, the Mellon Electronic Journal Archiving Program emphasized not only "the issues relating to electronic scholarly journals" but also "the likely loss to future generations of scholars of material published uniquely in the electronic medium."  For the librarians, archivists, and curators who grapple daily with the challenge of format diversity in written, printed, and recorded materials, the Foundation's focus on the electronic medium resonated with concerns about the preservation of non-print materials  --  which make up a major portion of the collections in the performing arts  --  as well as issues regarding electronically-rendered versions of print materials.  More importantly, the Foundation's project spoke to the developing concern, especially in performing arts studies, about the preservation of publications found only in electronic format, which are at significant risk.</p>
<p>Performing arts studies actually offer a relatively small range of scholarly journals within the confines of the printed form, if one means by "scholarly" refereed journals issued by learned societies or through established publishers.  What is starting to become more prevalent, however, is an interesting universe of material made available that takes advantage of the multimedia opportunities afforded by the World Wide Web, opportunities that have been very attractive both because they appeal to the sense of creativity of those involved in the performing arts and because of the relative ease with which publishing enterprises on the Web can be launched. </p>
<p>What can now be found on the Web in the performing arts ranges from very well-produced, highly structured, and highly specialized magazines, to informal tabloid fan-zines full of unedited commentaries, original compositions, and performance reviews. Some are produced under the auspices of traditional publishers and others are produced independently.  Rigor aside, all of this is of tremendous importance to scholars and researchers of the performing arts in assessing the impact of artists and the creative enterprise on the wider society.  Not surprisingly, the Library for the Performing Arts has collected, and continues to collect, this sort of material very extensively, both in electronic form and in print.</p>
<p>Within the Mellon Electronic Journal Archiving Program, the New York Public Library's focus on the performing arts provided a contrast to the projects of the other participants which focused primarily on electronic journals in the fields of science, technology, and medicine.  In its investigations, the Library determined that there were significant differences on many levels between e-journals in these fields and electronic resources in the performing arts.</p>
</div2>

<div2 type="subsection" n="03"><head>Major issues under investigation</head>
<p>The major issues investigated by the project can be divided into two realms: content development and implementation planning for a new electronic archive.</p>
<p>The Library's first objective was to identify the publishers of electronic journals and related resources in the performing arts and prioritize them in terms of their research value.  Building on earlier, preliminary work in preparation for the project and ongoing work to identify such resources by the staff of the Library for the Performing Arts, the Library was able to identify a significant number of performing arts titles.  The Library also began investigating intellectual property issues and the development of formal agreements with electronic publishers to cover the respective rights and responsibilities of both parties in developing a digital archive.  An investigation of the potential growth of the content of the archive was also undertaken.</p>
<p>Concurrently, the Library was able to investigate the wide range of technical issues involving system design, source and method of content delivery, and hardware and software requirements in its implementation planning for the archive.  Additionally, the Library considered potential organizational models and staffing requirements, access policies, and long-term funding options.  The long-term viability of the archive was also considered by examining methodologies to validate the archival processes from a technical perspective, and by exploring the means to assure user communities that electronic resources would be accessible and readable into the future.</p>
</div2>

<div2 type="subsection" n="04"><head>Project staffing, methodology, and scope of activities</head>
<p>The Library appointed as the Project Officer and Principal Investigator Jennifer Krueger, who formerly served as Assistant Director for Electronic Resources at the Science, Industry, and Business Library of the New York Public Library.  Ms. Krueger carried out her responsibilities beginning April 2001 and continuing through January 2002, and was assisted by Barbara Taranto. As the Director of the New York Public Library's Digital Library Program, Ms. Taranto provided general oversight of the project and carried out the project's completion through June 2002, in addition to taking a leading role in investigating implementation planning for the archive.  Ms. Taranto was appointed the Digital Library Program Director in February 2001 after previously serving as Systems Coordinator for The Research Libraries of the New York Public Library.  Prior to this, she worked as a systems specialist at Mount Sinai/NYU Health Center which gave her extensive experience with medical informatics and the long-term preservation of diagnostic imaging.  Subject expertise in dance, film, music, and theater was provided by the curatorial staff of the New York Public Library for the Performing Arts.  Additional input was provided by members of the Library's information technology staff and also by Dr. Clifford A. Lynch, Executive Director of the Coalition for Networked Information (CNI), who served as a consultant on this project.</p>
<p>Ms. Krueger, with the assistance of the others mentioned above, conducted extensive work in the area of content development.  This included an analysis of the performing arts literature in electronic form, the identification of individual resources for consideration, recommendations for criteria for inclusion, investigation into intellectual property issues, and communication with publishers and legal counsel.  Ms. Krueger also investigated work completed by other organizations regarding the establishment of digital archives in terms of content and implementing technology.  This included, for example, the minimum criteria established for digital archives by the Council on Library and Information Resources (CLIR) and the Digital Library Federation (DLF),<note target="NYPL01">[1]</note> and electronic archival implementation done by the European Union-funded Networked European Deposit Library (NEDLIB) (<xref doc="kbcoopnedlib">http://www.kb.nl/coop/nedlib/</xref>).</p>
<p>Ms. Taranto conducted further analysis of the technological implementation of the archive.  This included the establishment of the means of gathering the content (the "ingest" methodology), codifying the content so it would be readily retrievable, setting storage and retention policies, and developing a delivery strategy.  Ms. Taranto conducted a detailed investigation into electronic archive modeling and implementation done by other organizations, such as the Reference Model for an Open Archival Information System (OAIS) (<xref doc="wwwclassicccsdsdocumentsCCSDS6500B1">http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf</xref>), and other work sited in the section on "Implementation" below.  Ms. Taranto worked closely with other participants in the Mellon Electronic Journal Archiving Program regarding technical implementation issues.  Both Ms. Krueger and Ms. Taranto conducted investigations into the financial requirements of supporting the implementation of the archive in terms of ongoing content and technology development.  Both also worked closely with other participants in the Mellon Electronic Journal Archiving Program, including Stanford University and the other institutions working collaboratively on the implementation phase of the program in the LOCKSS project.<note target="NYPL02">[2]</note></p>
<p>In addition to support for Library staff assigned to the project, funding from the Andrew W. Mellon Foundation provided support for Dr. Lynch and other consultants as well as travel directly related to the project, including site visits to institutions involved in electronic archiving.  In addition, the Foundation's support allowed for the purchase of a server that will be used for archiving electronic resources on dance in the collaborative LOCKSS project.</p>
</div2>

<div2 type="subsection" n="05"><head>Content development</head>
<p>The vast majority of information found in electronic form on the performing arts does not take the shape of peer-reviewed publications and is not the output of scholarly associations or institutions.  Instead, this information, for the most part, takes the form of single publications produced by single publishers.  The intellectual meat of these publications is not stored as marked-up text, indexed and retrievable through a content management system. Neither are there likely to be persistent style sheets, document type definitions (DTDs), or schemas for storing and rendering output.  For these reasons, the scope of the New York Public Library project was somewhat different than the scope of other projects in the Mellon Electronic Journal Archiving Program that were either publisher-based or subject-based, where the content was produced out of large publishing houses.</p>
<p>Although the Library did considerable preliminary work in advance of the project in preparing its original proposal to the Mellon Foundation, much less was known at that time about the characteristics of the electronic publishing base in the performing arts.  In contrast, e-journals in science, technology, and medicine have been much more widely studied.  The Library's survey of the landscape is a significant contribution of the project.</p>
<p>The scope of the research for the project was determined by the limitations, both financial and technical, of the publishers of performing arts content and their chosen venues of publication. Unlike the large houses such as Wiley and Elsevier, the domain of performing arts publishers is rather narrow. Electronic resources tend to be created, rendered, and stored in a single system, often involving a service provider that is not part of the publishing organization and may or may not share information about its digital architecture to subscribers of the service.</p>
<p>Consequently, a major part of the work plan for the project involved analysis of appropriate candidates for long-term archival commitments.  It was anticipated at the outset that reaching agreements with these various publishers would be the most protracted piece of the work.</p>
</div2>

<div2 type="subsection" n="06"><head>Identifying and prioritizing content</head>
<p>At the outset, it was clear the audience that was aware of significant electronic resources in the performing arts was much narrower than the audience that is aware of STM publications and other areas of academic and scholarly interest that enjoy a wide dissemination.  Partly, this is due to the fact that unlike more traditional scholarly publications in print and electronic form, performing arts publications are not routinely repackaged by aggregators or indexed in any commercially available resource. Consequently, these publications are known and promoted solely on the strength of their dedicated but limited readership and on the mixed professional/commercial content of the venue.<note target="NYPL03">[3]</note>  In fact, the commercial/professional mix of performing arts electronic resources is possibly the most salient feature of these publications.  It affects every aspect of their creation, their delivery format, and most importantly, their viability.</p>
<p>As mentioned above, the Library elected to use an expansive definition of the term "electronic journal," considering many intellectually significant resources in electronic form that do not fit the strict profile of e-journals in science, technology, or medicine.  Still, the Library restricted its study to electronic resources that were "journal-like," that is, resources produced in a serial fashion containing content of interest for serious research by professionals and scholars.  Other significant electronic resources that are not "journal-like" such as collaborative performance Web sites are very useful to sophisticated research.  In fact, one of the Library's most highly prized resources is its Theatre on Film and Tape Archive which has amassed a large collection of videotapes of significant professional theatrical productions, the only complete documentation of many important works extant, including major Broadway and other commercial productions.  Archiving content found in Web sites about these productions might be something the Library could consider for the future, but since these resources did not fall appropriately within the mission of the Mellon Electronic Journal Archiving Program, they were not included as part of the project.  Likewise, the Library did not include Webcasts featuring the work of performing artists.</p>
<p>The staff of the New York Public Library's Library for the Performing Arts has, over the course of many years, developed its own highly prized indices of various resources in the field.  As a result, with the growing use of the Internet as a means of quickly and easily publishing valuable resources, the Library for the Performing Arts began to provide links to external online resources on its public Web site (<xref doc="nyplresearchlpaonline">http://www.nypl.org/research/lpa/online.html</xref>). The effect of this was two-fold:  new and important information was made available to the public, and new and important information was brought to the attention of the Library staff by their Web readership. Professionals, researchers, and publishers of serious performing arts journals solicited the Library's interest in the new venue. The Library began to investigate, evaluate, and ultimately propagate certain trusted publications in the performing arts community.  This accumulated index of invaluable print and electronic publications is one of the richest resources of the Library for the Performing Arts.  It represents years of research, study, and consideration on the part of the Library's professional staff and its governing agencies.  The various indices are available <hi rend="italics">in toto</hi> in the various divisions of the Library; a subset of these are available on the Web.  These seasoned lists formed an important starting point for the project.</p>
<p>A relational database was created for the project to log the entries and to record specific information about each of the publications.  Site URL's were examined for "freshness," and live sites were recorded and entered into the database.  A brief description of the content was included in the database and special note was made regarding the number of pages deep into the site a visitor needed to go in order to get to the meat of the content.  It is important to note that the substance of performing arts electronic resources can often be buried deep beneath layers of advertisements, job postings, auditions, professional service listings, etc.  Finding the content was a significant part of the discovery process.</p>
<p>Once recorded, the entries were analyzed and sorted into three primary categories: sites that were content-light; sites with significant content that needed to be mined by readers; and sites where the content was transparent, that is, where the content was not buried several layers deep within a Web site but could be readily uncovered.  The first category was eliminated from further inquiry since, for the most part, the information was contemporary in nature, including vendor information, instruction, workshops, etc. and was only relevant for current use. Consequently, despite its usefulness to the current performing arts community, it held little appeal or use for future researchers and scholars.</p>
<p>The set of e-journals that formed the core of the content considered for the project reflected a variety of presentation formats and content organization across the disciplines of dance, film, music, and theater.  The list of titles compiled and Web addresses are included in Appendix B.</p>
<p>The publications under consideration were separable into four basic categories:</p>

<list>
<item>Independents/Self Publishers/Web-only Publishers
<q>
Examples: <lb/><hi rend="italics">Consumable Online</hi> (<xref doc="westnetconsumable">http://www.westnet.com/consumable</xref>), published by Bob Gajarsky, Editor-In-Chief <lb/><hi rend="italics">Ape Culture</hi> (<xref doc="apeculture">http://www.apeculture.com</xref>), published by Julie Wiskirchen and Mary Elizabeth Ladd
</q></item>
<item>University and Scholarly Presses
<q>
Examples:  <lb/><hi rend="italics">TDR: The Drama Review</hi> (<xref doc="musejhujournalsthedramareview">http://muse.jhu.edu/journals/the_drama_review</xref>), MIT Press  <lb/><hi rend="italics">The Journal of Seventeenth-Century Music</hi> (JSCM) (<xref doc="sscmjscmpressuiucjscmv1no1editorsnote">http://sscm-jscm.press.uiuc.edu/jscm/v1/no1/editors_note.html</xref>), published by The Society for Seventeenth-Century Music, University of Illinois Press
</q></item>
<item>Commercial Publishers
<q>Examples: <lb/><hi rend="italics">Backstage.com</hi> (<xref doc="backstage">http://www.backstage.com</xref>), published by VNU eMedia, Inc. <lb/><hi rend="italics">Down Beat.com</hi> (<xref doc="downbeat">http://www.downbeat.com</xref>), published by Maher Publications
</q></item>
<item>International Publishers
<q>Examples:  <lb/><hi rend="italics">neue muskzeitung</hi> (nmz) (<xref doc="nmzindex2">http://www.nmz.de/index2.html</xref>) and <hi rend="italics">das ist aktlos</hi> (<xref doc="nmztaktlos">http://www.nmz.de/taktlos</xref>), produced by Neue Musikzeitung und Autoren (Germany) <lb/><hi rend="italics">Dancing Times</hi> (<xref doc="dancingtimes"> http://www.dancing-times.co.uk</xref>), published by The Dancing Times Ltd. (UK)
</q></item>
</list>

<div3 type="part" n="01"><head>Inclusion criteria</head>
<p>Not every Web publication in the area of the performing arts may be appropriate for inclusion in an archive.  The Reference Model for an Open Archival Information System (OAIS), the set of organizational principles adopted in the project by the Library, requires that a statement of policy or, at the very least, a set of inclusion criteria be established in order for the archive to be built in any sustainable mode.  Establishing a set of criteria based on this model is most often done by an advisory board consisting of scholars, professionals, representatives of arts organizations, and librarians from the user community. This mechanism serves double duty.  It provides a solid network of individuals who help shape and review selection criteria and arbitrate on issues when necessary.  It also guarantees a level of "buy in" from the stakeholder community, an essential component of all large enterprises and one that is sometimes undervalued.</p>
<p>To reach the stage of establishing a review board for the planned archive, the project team compiled a working list of titles for inclusion. This refined list was drawn from the original titles that were culled from the Library for Performing Arts's listings of online and paper resources. These resources fit the following criteria:</p>

<list>
<item>They were consistent with the current collection development policies of the Library</item>
<item>They had identifiable publishers</item>
<item>They consisted primarily of original content</item>
<item>They were persistent in terms of publishing schedule and format</item>
<item>They were media rich</item>
</list>

<p>Each of the electronic publications that were selected had to contain the first four of these qualities and a strong emphasis was given to those that met the final criterion.</p>

<p>Although certain other criteria such as a publication's importance in the field and its recognized authority or longevity were desirable, it was determined that including these criteria would rule out candidates that were not well-established but were worthy of consideration nevertheless. This is not to say that these attributes counted against inclusion, but they were not considered necessary for inclusion.  Some of the titles under consideration had ceased to publish on the Web, or anywhere else for that matter. The abiding interest in these publications was their obvious status of being at imminent risk of being lost for future research.</p>
</div3>

<div3 type="part" n="02"><head>Consistency with the current collection development policies of the Library</head>
<p>The subject area of the performing arts was chosen as the focus of the project in part because of the collection strengths of the Library and in part because of the concentrated wealth of knowledge found among the professional staff at the Library for the Performing Arts.  For the project, this staff drew from their expertise about the nature and long-term stewardship of collections and helped evaluate potential electronic resources with regard to the Library's collection development policy.  By extension, the electronic archiving project was the natural and inevitable next step for the Library to make in its long-term strategy to conserve and preserve its materials, and it made sense that the content of the titles nominated were well within the bounds of the Library's current collection practices.  The staff evaluated titles individually, and resources such as <hi rend="italics">Critical Musicology</hi> (<xref doc="leedsmusicinfocritmus">http://www.leeds.ac.uk/music/info/critmus/</xref>), for example, which fell within the policy, were identified as candidates for preservation and subject to further evaluation, whereas Web publications such as "CDNOW: Allstar News" (<xref doc="cdnowmserverpagenameRPALLSTARmain">http://www.cdnow.com/cgi-bin/mserver/pagename=/RP/ALLSTAR/main.html</xref>), which is primarily a commercial site with no content other than an inventory of products, were not considered further.</p>
</div3>

<div3 type="part" n="03"><head>Identifiable publisher</head>
<p>One of the many challenges of dealing with small publications, and especially publications on the Web where the means of production can be entirely in the hands of a single operator, is the problem of identifying and locating the person, persons, or agencies responsible for a publication, an important matter in terms of intellectual property and rights aggregation for rights clearance. Simply finding a corporate or personal name claiming to be the publisher of a site is no guarantee that the agent identified has any legal standing in regard to its content.  Many Web publications, especially those in the performing arts, "crib" material from other sites (see <hi rend="italics">beat thief</hi> at <xref doc="beatthief">http://www.beatthief.com</xref>), or are complex sites that welcome unvetted participation from their readership (see <hi rend="italics">oobr: the off-off-Broadway review</hi> at <xref doc="oobr">http://www.oobr.com</xref>).  It is not so much that the publisher does not control the content or disavows the content, but that the publisher may not know, at any given time, the nature of the content, or may not be completely responsible for or capable of content management.</p>
<p>The <hi rend="italics">ad hoc</hi> practices and behaviors of some electronic resources in the performing arts may be their most salient and attractive features, but the problems presented by these practices make it close to impossible to "collect" the titles for an archive in any meaningful way.  While an agreement might be made with one party involved in the publication, another party may not be reachable or may object to the arrangement.  In some cases, where a single agent can be identified, it might very well be that he or she has no clear right to publish the content.  This is especially true of electronic resources that provide a substantial amount of streamed media, such as music or film clips.  While the text of the site may be the intellectual property of the author/publisher, the media illustration often is not.</p>
</div3>

<div3 type="part" n="04"><head>Primarily original content</head>
<p>It was considered essential that electronic content consist of original information generated by the publishing source and not information that was repackaged from some other source.  The legal ambiguities are considerable for republished digital content generated somewhere other than its primary source which may take on a different format<note target="NYPL04">[4]</note> because of bandwidth limitations and service provider restrictions, even if materials are "born digital" (see <hi rend="italics">Soundout</hi> at <xref doc="soundout">http://www.soundout.net</xref>).  Print publishers, media companies, film studios, and others all have a stake in how evolving copyright legislation in an electronic environment is drawn and enacted.  Until such legislation can address some important issues, what amounts to "buying or licensing" digital rights is unclear at the very best and risky at its worst.  Consequently, electronic resources that required extensive legal and monetary negotiations regarding intellectual property were not considered for the project.</p>
<p>Copyright issues are not necessarily insurmountable.  However, work in obtaining legal rights to content in many performing arts electronic resources has the potential to turn into a legal quagmire. Even if the content is highly desirable, the cost of doing due diligence on the variety of conditions under which the content might be archived and delivered could far outweigh the benefit gained by preserving the material.  Dealing with purveyors who have clear title to materials or at least could indemnify the Library from any liability where rights have not been cleared was considered absolutely necessary.</p>
</div3>

<div3 type="part" n="05"><head>Publishing persistence</head>
<p>The initial list of performing arts titles consisted of a very wide range of e-publications including many that had substantial content but would generate, with more than occasional frequency, the disappointing message "unavailable." To be fair, this was more likely to be the fault of Internet service providers rather than of publishers: in the current economy service providers have been known to retire with little or no notice, leaving their customers in difficult straits.  Still, publications that could not be accessed with some consistency were excluded from consideration.</p>
<p>Planning to archive any serially published materials is most readily done through the establishment of close relationships with the publishers of the content.  There is obviously an extensive lead-time required to set up the legal and technical parameters for deposit, and some of the proposed sites failed to conform to any manageable or predictable schedules of publication.</p>
<p>Other publications in the course of a few months continuously reinvented their sites, changing basic organizational formats,<note target="NYPL05">[5]</note> intellectual direction, and targeted audience.  Still others discontinued publication even though it was clear from the "hit" counter that the site was still actively used. Overcoming the issues raised by dynamic content is a technical challenge that will be addressed later in this report, but in place of either persistent schedule or persistent intellectual format, the Library ruled out these publications for inclusion in the archive.</p>
</div3>

<div3 type="part" n="06"><head>Media rich</head>
<p>The project's focus on the performing arts provided the potential to explore the issues raised by electronic publications with embedded multimedia objects.  As noted, nearly all the titles under consideration contained some form of non-text material.  The amount of audio-visual media included was significant, but lower than anticipated: 45 percent of the titles contained sound and/or video formats.  Some publications, such as <hi rend="italics">African Music Archive</hi> (<xref doc="ntamaunimainzama">http://ntama.uni-mainz.de/~ama</xref>) and <hi rend="italics">Ethnomusicology Research Digest</hi> (<xref doc="informumdEdResNewslettersEthnoMusicology">http://www.inform.umd.edu/EdRes/ReadingRoom/Newsletters/EthnoMusicology</xref>), had a wide range of content including archived audio, streamed audio, and music performance.  <hi rend="italics">African Music Archive</hi>, however, offered its readership MIME types and browser-compatible formats, while <hi rend="italics">Ethnomusicology Research Digest</hi> relied on the ingenuity of its user base to download and then reformat binary objects into human "readable" files.  The probability of successfully archiving standardized formats such as Real Media or QuickTime is much greater than that of archiving idiosyncratic media types. The ingenuity of the site publisher is manageable with human intervention, but daunting when planning an archive based on automated systems for ingest, storage, and retrieval.</p>
<p>The vast majority of e-publications containing media objects did not venture into unusual file types or file types unique to the performing arts, such as MIDI-based musical material or computer-based dance notation, which would represent specialized and complex preservation issues or areas of uncharted technology involving "new media." Here, the term "new media" refers to new types of electronic formats, not new types of performance (see <hi rend="italics">Music by Light</hi> at <xref doc="itpnyuGALLERYmusiclight">http://www.itp.nyu.edu/GALLERY/music_light.html</xref>).  For certain types of performing arts sites that cannot be easily classified as e-journals or e-zines, there may be a potential audience for such new media, but for the purposes of the project these titles or sites were not considered for inclusion in the archive.<note target="NYPL06">[6]</note></p>
<p>Almost all of the titles that were under review included some form of non-text content.  Approximately 85 percent of the electronic resources contained images and graphics beyond that which could be described as organizational logos or publication mastheads, and these resources clearly presented issues for concern regarding intellectual property rights.  In the area of music and recorded sound, a further 45 percent of the listed titles contained various forms of audio media.  Some of this content was available as MP3 files, some as QuickTime. Many sites that were considered, such as <hi rend="italics">das ist taktlos</hi> (<xref doc="nmztaktlosindex">http://www.nmz.de/taktlos/index.shtml</xref>), provided numerous streaming excerpts from radio broadcasts, live performances, and discussions with musicians, composers and reviewers.  Aside from the copyright issues involved, which may or may not be covered by formalized waivers given the legal standing of the publisher and the publisher's ability to clear the rights with all parties involved, the technical challenges this presents were not insignificant.<note target="NYPL07">[7]</note>  Streamed media, whether it is audio, video or Webcast, presents special considerations for archiving that have not been much explored. These formats, including Real Media files or QuickTime files, in fact constitute a third-, fourth-, or sometimes even fifth-generation derivative of a digital source.  In many cases, the digital source is itself a reformat of an analog recording.  That aside, streamed media is not delivered as a "unit." It is pieced out across the telecommunication pipeline in sizeable, downloadable chunks. Streamed media requires browser plug-ins and local transmission-speed configuration files in order to be rendered properly on the desktop.  Unlike other binary objects that can be harvested directly and stored in an archive, streamed media published on the Web is not so much a digital object as an event.  It certainly can be reproduced locally but it cannot be easily harvested.  In addition, some sites offer multiple streams of the same material at different levels of quality (where higher quality streams would be selected for recipient sites with higher bandwidth connections to the Net), raising additional considerations.</p>
<p>Despite the challenges that media-rich resources present, it was felt necessary to give some priority to these resources in identifying potential content for the archive, specifically in order to address such challenges.</p>
</div3>

<div3 type="part" n="07"><head>Further refining the subject focus</head>
<p>At a certain point in the project, as the number of potential electronic resources grew while, at the same time, cost projections for maintaining the archive were being developed, it appeared necessary to narrow the subject focus of the project if there was to be a hope of taking it to an implementation phase.  The key strategic consideration used in narrowing the field was to emphasize congruence with existing programmatic commitments at the Library.</p>
<p>Of the titles that remained after the process of elimination based on the five criteria noted above, the majority fell into one of two areas:  music and dance.  The music titles were by far more electronically sophisticated than most of the dance journals, but several raised significant rights issues and the likelihood of coming to mutually agreeable terms for access with publishers and artists was not encouraging.  Furthermore, the music resources, while more established and containing more content than some other publications, did not complement the subject emphasis of the specialized collections of the Music Division at the Library for the Performing Arts.</p>
<p>On the other hand, the thirty-some dance titles that survived the initial cut were more in line with the goals the Library had set for itself at the onset of the project. The dance titles, which are listed in Appendix C, can be characterized in the following ways:</p>

<list>
<item>Journals were published both nationally and internationally</item>
<item>Most types of dance and movement performance were represented</item>
<item>Publications were split roughly between "born-digital" editions and "digital facsimiles" of hard copies</item>
<item>Publishers were identifiable and locatable</item>
<item>Media clips, both sound and video, were found in many of the publications</item>
<item>New content, for the most part, was still published as "issues"</item>
<item>Most publications were currently offering past issues that have been "archived" on their respective sites</item>
</list>

<p>Another factor that was taken into consideration was the comparatively limited number of institutions and organizations focused specifically on dance research and scholarship, the New York Public Library for the Performing Arts being one of them. The Jerome Robbins Dance Division of the New York Public Library for the Performing Arts is highly respected both nationally and internationally and is considered to be one of the most reliable and rich repositories of materials on dance anywhere in the world.  The Library is a founding member of the Dance Heritage Coalition and hosts the Coalition's Web site (<xref doc="danceheritage">http://www.danceheritage.org</xref>). Given the leadership role of the Library's Jerome Robbins Dance Division among dance libraries, it is quite likely that the Library might be the only organization that could consider taking on a major role in establishing an electronic archive for dance.</p>
<p>Considering this, the Library was in a good position to leverage some of its existing relationships in the dance community to help solicit participation and solidify commitments from publishers.  Given this and the special nature of the dance e-publications, the Library made the decision to focus its efforts "narrow and deep," providing strong depth of coverage in the very specific subject of dance.</p>
<p>By focusing on dance titles the Library believed it could accomplish significant understanding of the process involved in collecting, storing, and delivering electronic content that was not already normalized in some other system.  The challenges predicated by the diversity of document types, media types, and publishing genres were well represented by the dance titles selected.</p>
<p>While in a perfect world it would be best to be able to archive as much electronic content as possible, it was felt that developing an archive containing a modest number of electronic resources on dance would make a contribution to both the dance field and electronic archiving. The challenges for archiving this material are obviously quite different from the challenges of archiving large numbers of regularly generated text files from content management systems, but given the range of participants involved in the Mellon Electronic Journal Archiving Program, it appeared that certain issues of scale were going to be addressed by other parties, and that the Library would make its most significant contribution by exploring areas not particularly relevant to the STM-type archive.</p>
</div3>
</div2>

<div2 type="subsection" n="07"><head>Publishers' roles in an archive</head>
<p>The success or failure of an archive depends in large part on the good will and cooperation received from the publishing community.  For obvious reasons, the archive would be content-less without the publishers' material, but more importantly, without the good will of the parties involved there are no grounds for negotiating or resolving issues as they arise.</p>
<p>This was a lesson learned and generously shared with the participants in the Mellon Electronic Journal Archiving Program by the PubMed Central team at the National Institute of Health in Bethesda, Maryland.  While PubMed's experience was most obviously applicable to the Mellon program participants working in science, technology, and medicine, this experience was also applicable to the performing arts and other fields.</p>
<p>Dr. David Lipman, Director of the National Center for Biotechnology Information at the National Library of Medicine, and his programming team shared the various technical challenges involved in ingesting material from a wide variety of scholarly publishers, many of whom are small, single-title entities like those found in the performing arts group.  In some cases, months of negotiation were necessary between depositors and PubMed Central before an actual document was submitted to the archive.  Most of this time was spent on the development of a document type definition (DTD) for ingest.  Some time, however, was lost in trying to work with publishers who were less than enthusiastic, thinking that with enough technical and professional support from the National Library the publishers would be more receptive to the requirements of the archive.</p>
<p>Dr. Lipman reported that after eighteen months, working with a range of titles, they had come to the conclusion that the only viable arrangements were those where the publishers' involvement was entirely voluntary.  Trying to win interest in the project could not be had by any technical incentive, and the possibility of providing a financial one was slim.</p>
<p>These lessons were valuable ones for the New York Public Library in dealing with publishers in the performing arts.  It should be noted, however, that the PubMed project was operating in a very different milieu than the performing arts, where it is only a small exaggeration to say that publishers cannot even afford backup disks.  Performing arts publishers are typically very aware of the need of preserving information, but any reluctance on their part to participate with regard to financial considerations must be cast in a very different light. Such publishers, it was found, were supportive of the development of an archive, and clearly saw the benefits in the possibility that the Library might be able to offer server space and the technological wherewithal to make an archive come about.</p>
<p>For many of the publishers of electronic resources in dance considered by the Library, the Web is the only publishing medium: no print copy exists.<note target="NYPL08">[8]</note>  Approximately 80 percent of these e-journals and e-zines are currently providing their own online archive, subject to the terms of their Internet provider and the amount of space each can afford to maintain and expand upon with new content.  In some fields, as an attempt to underwrite this service, past issues, which are often indexed by issue date, may be searched by registered readers or by paying a fee to the publisher.</p>
<p>Publisher-based archives are far from stable, however, as we have witnessed by the almost overnight disappearance of rather successful electronic publications such as <hi rend="italics">The Friends of Photography</hi> (<xref doc="friendsofphotography">http://www.friendsofphotography.org</xref>) and the original <hi rend="italics">Time Digital</hi> (continued in a very different form as <hi rend="italics">ON Magazine</hi> which now is no longer being published) among others.<note target="NYPL09">[9]</note>  Unlike some of their more broadly-based cousins who might withstand the loss of an electronic presence, dance e-journals have neither the means nor the wherewithal to assure the public that the online archives will persist.</p>
<p>The short-lived nature of Web editions and the economic realities of producing art publications argue for some degree of receptiveness on the part of the individual publishers.  Consequently, when the Library took a straw poll of e-publishers in February 2001, it was not entirely surprised by the positive response.  A sample of twelve publishers was selected and each felt their audience would find the archive useful.  All but one expressed interest in the development of an electronic archive; the lone dissenting publisher expressed concern, with little explanation, about losing advertisers due the establishment of the archive.  Regarding the idea of making the archive freely available, eleven of the twelve responded positively and also felt it would be unnecessary to limit access for any period of time after publication.  All but one of the publishers were willing to have content from their Web sites harvested by the Library or another archive administrator, although only half were willing to provide files of Web content directly for storage.  Seven of the twelve responded that they allowed their site to be crawled by such resources as Google or the Internet Archive; the others did not know or did not respond.  On a question regarding storage, the publishers indicated the file size of their individual publication issues ranged from 7 to 100 megabytes.  Ten of the twelve indicated they planned to increase multimedia content although a few noted this might take years.</p>
<p>The following illustration provides a matrix of possible relationships between publishers and the New York Public Library.  The publishers' participation ranges from the most active  --  where the Library receives everything it wants, when it wants, and how it wants, with no cost and with total control over delivery  --  to the publishers having no participation at all and the Library essentially adopting a "risk management" approach to archiving content.  When publishers have no formal agreement and the content is freely available on the Web, it may be tempting to harvest sites until an objection is raised.  While this may not be ideal, it is perhaps the only way to handle some of the more elusive candidates. However, this last arrangement seems to be the least tenable and the least desirable. It is somewhat akin to a collection development policy based on taking what you can get and not what you want.</p>

<p><table>
<row><cell cols="6">Archive Publisher Relations</cell></row>
<row><cell role="label"><hi rend="bold">Type</hi></cell><cell role="label"><hi rend="bold">Responsibilities of Publisher</hi></cell><cell role="label"><hi rend="bold">Archival Record</hi></cell><cell role="label"><hi rend="bold">Responsibilities of Archive</hi></cell><cell role="label"><hi rend="bold">Ingest Method</hi></cell><cell role="label"><hi rend="bold">Economic Relation</hi></cell></row>
<row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell><hi rend="bold">Active</hi></cell><cell>Provide regular ingest packets in pre-specified format</cell><cell>Actively participates and desires archival record</cell><cell>Provide formal archive with data integrity assurances and continued support</cell><cell>Deposition</cell><cell>Some payment by publisher to archive if possible</cell></row>
<row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell><hi rend="bold">Explicit</hi></cell><cell>Provides ingest packets, unformatted</cell><cell>Actively participates and desires archival record</cell><cell>Reformat to meet archival standard</cell><cell>Deposition</cell><cell>Archive bears some cost</cell></row>
<row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell><hi rend="bold">Implicit</hi></cell><cell>Acknowledges the archive's right to harvest</cell><cell>May or may not desire archival record</cell><cell>Reformat to meet archival standard</cell><cell>Harvesting</cell><cell>Some payment by publisher to archive if possible</cell></row>
<row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell><hi rend="bold">Null</hi></cell><cell>No agreement between parties</cell><cell>Does not desire archival record</cell><cell>Create archive using materials without permission and remove if necessary</cell><cell>Harvesting without permission</cell><cell>Archive bears cost</cell></row>
</table></p>

<p>In any event, whatever the relationship that is formed between the Library and the e-publishers  --  and of course there will be easier negotiations with some and not with others  --  the terms of ingest for any given title will have to be determined rather specifically if the content is ever to make it to the archive.  Trawling for content may sound like a simple solution (and even roguish) but it does not answer the bigger questions of what to do with it when it is brought home. Neither does it address the issues raised by content that includes streaming media which cannot be readily harvested in this way.</p>
</div2>

<div2 type="subsection" n="08"><head>Implementation planning</head>
<p>Shortly after initial work began that focused on the potential content of the electronic archive, the Library engaged in a separate parallel planning investigation of the archive's implementation, work that proceeded concurrently with the analysis of content with the two processes informing each other along the way.</p>
<p>To implement a viable electronic archive following the OAIS model, there are three key components that must be in place:  an ingest methodology, a storage and retention policy, and a delivery strategy.  In addition, of course, systems and infrastructure components to make all of these operational will be needed.</p>
<p>The Library gave relatively little consideration to delivery issues and these will not be discussed further, other than to note that it appears that many of the other STM-based planning projects were operating in an environment where the archive would, at least in the near term, be largely "dark."  Given what we learned from our discussions with publishers in the dance area, an archive of this material would be mostly "light" (that is, fully accessible to the public) immediately; indeed, the archive at the New York Public Library might well be the only source for back issues of some dance publications, given how critical the lack of storage space is to the publishers and how eager they are to shift responsibilities for archival backfiles elsewhere.  Thus, the Library's project would have to fully address delivery issues as part of any initial implementation, not as a future follow-on to ingest and storage functions.</p>
</div2>

<div2 type="subsection" n="09"><head>Ingest</head>
<p>The situation for ingest of performing arts publications is clearly radically different than that which applies to the STM publications that were the focus of many of the other Mellon planning projects.  There is no hope of contracting for a well-structured Submission Information Package (SIP) which would be delivered from the publisher.  The publishers don't have the technical capabilities or resources to do this, and their content is simply not created and managed in forms that are amenable to such a model.</p>
<p>In many ways, pure harvesting is probably the most practical model for ingesting content from performing arts publishers.  However, there are numerous problems with this approach.  It would be necessary to build a base of highly tailorable, error-checking, adaptive harvesting software that could detect new materials, discard irrelevant content, potentially deal with streamed media components, navigate sites, and perform similar functions.  While the Internet Archive and other groups such as the Research Libraries Group (RLG) have made a start on establishing such a technology base, it is far from ready for use in a closely quality-controlled digital archiving environment.  There are also problems in modeling what is being harvested; one would like to collect incremental new content "units" (such as journal issues) rather than a succession of images of a Web site, but many of the publishers' Web sites simply are not organized in this fashion.</p>
<p>Ideally, the Library's hope going forward would be to use pure harvesting as a last resort and instead, seek to negotiate some form of structured harvesting or publish/subscribe model with the sites being archived whereby they would store new material in some organized way that would make it easy for the Library to harvest or otherwise extract new materials.</p>
<p>Metadata is clearly another problem for the ingest strategy.  A small amount of metadata can be created computationally  --  the site, file details, the date of capture, etc.  --  but most of the materials published in dance are not published with well-structured bibliographic or other descriptive metadata that could be incorporated into a Library-generated SIP from a publisher's Web site without extensive human intervention.</p>
</div2>

<div2 type="subsection" n="10"><head>Retention and storage</head>
<p>Based on an examination of what was actually being done in electronic publications in dance and in the performing arts more broadly, it was possible to establish a few preliminary strategies for retention and storage.</p>
<p>Digital images of what was captured would be kept permanently, available to at least support digital archeology as a failsafe against the limitations of format migrations.</p>
<p>The main strategy for avoiding technical obsolescence over time would be file format migration.  The evidence was that there were a fairly small number of relatively mainstream file formats comprising the vast majority of the dance materials.  There seemed to be only minimal need to deal with specialized digital formats (e.g., MIDI, structured dance notation, etc.) which would call for specialized strategies.  The preservation focus would be on content rather than on trying to retain "look and feel."</p>
<p>The largest unresolved problem in the retention and storage area revolved around units of archiving. Typically, what would be dealt with would be complexes of files, somewhere between capturing a well-structured bundle of files and capturing a series of images of a Web site with opaque structure. Dealing with this tension in both ingest and storage would be a critical problem going forward. The discipline of editions and units of publication are not very well followed in the dance and performing arts literature, and this creates an enormous problem when compared to the STM literature.  This is an important finding from the Library's analysis.  In the STM literature there is  --  at least to a first approximation, leaving aside details such as the listing of editorial boards and editorial policies  --  a well-established intellectual model of the objects being archived and these objects are clearly manifest in the process of producing an STM journal.  In the performing arts publishing world, by contrast, no such consensus on base intellectual models of objects to be archived exists in a visible way within publishing practices.  This represents a sizeable technical hurdle to be overcome.  Another way of viewing this finding is that while the STM literature has closely emulated the practices of print journal publications in its transition to digital form, the performing arts digital literature is much less closely tied to such traditions.  This creates a surprisingly serious problem in developing archival strategies.</p>
</div2>

<div2 type="subsection" n="11"><head>Economic models and sustainability</head>
<p>The literature of the performing arts, as already discussed, is resource-starved. The only economic model that could be realistically devised would be a philanthropic partnership where the Library might lead a consortium of interested institutions, perhaps building on existing organizational structures such as the Dance Heritage Coalition, that would work in close collaboration with the publishers to establish and maintain a lasting archive of publications in the field.  This would be primarily a fully accessible archive that would be maintained as a public good.  For a very small number of participating publications, it might be appropriate to use some form of "moving wall" archival policy for determining when material is made accessible, similar to that used by JSTOR, but the titles for which this would be applicable would be a small minority.</p>
</div2>

<div2 type="subsection" n="12"><head>Implementation decisions</head>
<p>As the work on the planning project drew to a close, the Library had identified a relatively small core of electronic publications in dance for which the Library might mount or lead a digital preservation effort closely aligned with existing programs and priorities.</p>
<p>The economics of this potential program, however, were deeply problematic.  An ingest system would require either very extensive software development which would be hard to reasonably amortize over the small number of serials involved or, alternatively, a more limited software development effort supplemented with an extremely staff-intensive  --  and hence, operationally costly  --  ingest system. There seemed to be little likelihood, at least in the immediate future, of being able to build upon other software development work in this area. The other Mellon planning projects, for example, were identifying development priorities that were very different from those that would be required for performing arts literature.  A much more extensive ingest program covering many more sources would lower the per-journal ingest cost, but would mean a larger storage and retention effort and a much more extensive and costly scale of negotiation with content producers.</p>
<p>In terms of storage and retention (and perhaps delivery), an archiving program for dance literature could share common infrastructure and systems with an institutional asset management and archiving system since much of the work would be in managing and migrating a fairly small number of key file types. However, at the Library such an institutional system is not yet in place.</p>
<p>During the period of the Mellon planning project, the Library was involved in an extensive organizational evaluation and planning process that had as its goal the transition of digital library efforts (collection selection, digitization, management, delivery, and stewardship) from a project-based framework to a permanent, systematic, institutionally-based operational framework.  This would include the establishment of large-scale, sustainable infrastructure components which might be shared by a program to maintain "published" material in the performing arts, once ingest had been accomplished.  However, it was clear the Library was at least another year away from putting a fully developed, reliable, production infrastructure in place to support its own programs to manage internally generated content. There are also deep and complex organizational questions about where to position such functions within the Library's organizational units and how to fund the activities. The debates around these issues are ongoing and challenging.</p>
<p>Since it was evident that digital preservation in the area of performing arts serials would be an ongoing financial investment rather that a revenue generating or even self-sustaining activity, it was clear to the Library's management this was not the time to move forward on such a digital preservation program. Instead, the better strategy seemed to be to focus on developing institutional infrastructure, and then in a year or two, after the institutional infrastructure was established, return to the question of investing in programmatic extensions in the performing arts which encompassed digital preservation goals.  Even at that time, however, it seems likely that only a larger-scale preservation program underwritten by a consortium just focusing on the costs of establishing ingest systems is likely to be viable.  It is useful to note here that even if other Mellon archiving projects produce some type of community storage repository, the ingest problems for performing arts e-resources represent a formidable economic and technical barrier to exploiting such a community resource.</p>
<p>As an interim measure, the Library has chosen to participate in the LOCKSS program along with a number of other institutions.  While this is not a full preservation solution, it allows the Library to gain some experience with highly distributed redundant storage as an infrastructure component, and also to continue to explore some of the ingest issues that will ultimately need to be addressed.</p>
</div2>

<div2 type="subsection" n="13"><head>Endnotes</head>
<note id="NYPL01">[1] Available online at <xref doc="diglibpreservecriteria">http://www.diglib.org/preserve/criteria.htm</xref> and also included elsewhere in this publication.</note>
<note id="NYPL02">[2] The LOCKSS project is developing a decentralized electronic archive, based on the fundamental principle that electronic files are more secure when multiple copies of these files are stored in several locations.  Put another way, "lots of copies keep stuff safe"  --  the basis of the LOCKSS acronym.</note>
<note id="NYPL03">[3] Performing arts electronic resources are rarely a compilation of scholarly articles. Advertisements are often embedded in text and commercial interests openly sponsor some features. For example, see <hi rend="italics">Actingbiz: The Online Actors Resource</hi> at <xref doc="actingbiz">http://www.actingbiz.com</xref>.</note>
<note id="NYPL04">[4] MPEG becomes Real Media, TIFF files become GIF or JPEG files, etc.</note>
<note id="NYPL05">[5] Format in this case means something different from style or layout or MIME type; it refers to whether the publication is a single author site, a cooperative site, an electronic forum, etc.</note>
<note id="NYPL06">[6] It is important to note here that embedded media is in some ways no more challenging than any type of electronic content. Unusual or nonstandard text formats present similar ingest issues. Archiving PDF documents or <hi rend="italics">Mathematica</hi> notebook (NB) documents require ingest protocols and standardized classification schema in the same way media objects do.  The difference here lies in the rather more complex delivery methods required for media, and consequently, the more complex and detailed metadata that must be gathered at the time of ingest.  It may be desirable to deliver text in the format and presentation style it was originally rendered; however, it may turn out to be of no intellectual consequence to the publication in question. On the other hand, media content must be rendered with some verisimilitude. The content in this case cannot be extracted from its form.</note>
<note id="NYPL07">[7]  The preferable solution is to require publishers to sign an indemnity waiver stating that they hold the digital right to the images in question and that the archive will be held blameless should a dispute arise.  Such a waiver may pose problems for publishers who have no knowledge of how early editions of the publication were created and publishers outside the United States for whom different legal obligations apply.  In instances where the publisher does hold the rights to an image, a placeholder may have to be inserted, perhaps describing the image and providing information to locate the image elsewhere.  Copyright and performance rights issues could occur with audio clips.  The waiver mentioned above would need to cover all instances of intellectual property, including these.  If rights issues cannot be satisfactorily negotiated with the publisher, recourse to the individual rights holders may prove to be to daunting due to the numerous individuals involved.  For a title whose content otherwise is desirable to retain, placeholders may be needed.</note>
<note id="NYPL08">[8] Statistical sampling shows that perhaps as much as 70 percent of performing arts journals are only found in digital format.  Another 10 percent include material in the electronic version that is never published on the paper issue.  For example, see  <xref doc="backstage">http://www.backstage.com</xref>.</note>
<note id="NYPL09">[9] Currently there are many e-journals facing imminent closure. See  <xref doc="artchive">http://www.artchive.com/artchive</xref>.</note>
</div2>

<div2 type="subsection" n="14"><head>Appendix A. Project financial report</head>
<p>[Omitted.]</p>
</div2>

<div2 type="subsection" n="15"><head>Appendix B. Performing arts electronic resources</head>

<div3 type="part" n="01"><head>Performing arts in general</head>

<p><table>
<row><cell>Al Jadid: a Review &amp; Record of Arab Culture and Arts</cell><cell><xref doc="aljadidabout">http://www.aljadid.com/about.html</xref></cell></row>
<row><cell>ArtsWire (now NYFA Current)</cell><cell><xref doc="nyfa">http://www.nyfa.org</xref></cell></row>
<row><cell>Australian Humanities Review</cell><cell><xref doc="liblatrobeAHR">http://www.lib.latrobe.edu.au/AHR/</xref></cell></row>
<row><cell>Entertainment Weekly's EW.com</cell><cell><xref doc="ew">http://www.ew.com/ew/</xref></cell></row>
<row><cell>The Hungarian Quarterly</cell><cell><xref doc="nethungq">http://www.net.hu/hungq/</xref></cell></row>
<row><cell>JENdA: A Journal of Culture and African Women Studies</cell><cell><xref doc="jendajournaljenda">http://www.jendajournal.com/jenda/</xref></cell></row>
<row><cell>Psyart Journal: an Online Journal for the Psychological Study of the Arts</cell><cell><xref doc="clasuflipsajournal">http://www.clas.ufl.edu/ipsa/journal/</xref></cell></row>
<row><cell>Shoot the Messenger</cell><cell><xref doc="shootthemessenger">http://www.shootthemessenger.com.au</xref></cell></row>
<row><cell>West Africa Review</cell><cell><xref doc="westafricareviewvol12index12">http://www.westafricareview.com/war/vol1.2/index1.2.htm</xref></cell></row>
</table></p>
</div3>

<div3 type="part" n="02"><head>Dance</head>

<p><table>
<row><cell>BackStage.com</cell><cell><xref doc="backstage">http://www.backstage.com</xref></cell></row>
<row><cell>the-ballet.com</cell><cell><xref doc="theballet">http://www.the-ballet.com</xref></cell></row>
<row><cell>Ballet Alert!</cell><cell><xref doc="balletalert">http://www.balletalert.com</xref></cell></row>
<row><cell>Ballet.co Magazine</cell><cell><xref doc="balletmagazine">http://www.ballet.co.uk/magazine/</xref></cell></row>
<row><cell>ballettanz</cell><cell><xref doc="ballettanz">http://www.ballet-tanz.de</xref></cell></row>
<row><cell>Body Space &amp; Technology Journal</cell><cell><xref doc="bruneldeptspfabstjournal3no1journal31">http://www.brunel.ac.uk/depts/pfa/bstjournal/3no1/journal3_1.htm</xref></cell></row>
<row><cell>Boletin del Tango</cell><cell><xref doc="homesnafutarlo">http://home.snafu.de/tarlo/</xref></cell></row>
<row><cell>Critical Dance</cell><cell><xref doc="criticaldance">http://criticaldance.com</xref></cell></row>
<row><cell>Dance Magazine</cell><cell><xref doc="dancemagazine">http://www.dancemagazine.com</xref></cell></row>
<row><cell>The Dance Insider</cell><cell><xref doc="danceinsider">http://www.danceinsider.com</xref></cell></row>
<row><cell>Dance Online</cell><cell><xref doc="danceonline">http://www.danceonline.com</xref></cell></row>
<row><cell>Dance Spirit Magazine</cell><cell><xref doc="dancespirit">http://dancespirit.com</xref></cell></row>
<row><cell>Dance Teacher Magazine</cell><cell><xref doc="danceteacher">http://www.dance-teacher.com</xref></cell></row>
<row><cell>DanceArt</cell><cell><xref doc="danceart">http://www.danceart.com</xref></cell></row>
<row><cell>DanceView</cell><cell><xref doc="danceviewindex">http://www.danceview.org/index.html</xref></cell></row>
<row><cell>Dancer's Delight</cell><cell><xref doc="msuuserokumurak">http://www.msu.edu/user/okumurak/</xref></cell></row>
<row><cell>Dancesport UK</cell><cell><xref doc="dancesport">http://www.dancesport.uk.com</xref></cell></row>
<row><cell>Dancing Times Ltd</cell><cell><xref doc="dancingtimes">http://www.dancing-times.co.uk</xref></cell></row>
<row><cell>The Electric Ballerina</cell><cell><xref doc="noviajlwelectric">http://www.novia.net/~jlw/electric/electric.html</xref></cell></row>
<row><cell>The Israeli Folk Dance Connection</cell><cell><xref doc="webspanhgpklm">http://www.webspan.net/~hgpklm/</xref></cell></row>
<row><cell>ISTD [The Imperial Society of Teachers of Dancing] News</cell><cell><xref doc="istdnews">http://www.istd.org/news.html</xref></cell></row>
<row><cell>The Letter of Dance</cell><cell><xref doc="pbmlindahllod">http://www.pbm.com/~lindahl/lod/</xref></cell></row>
<row><cell>londondance.com</cell><cell><xref doc="londondance">http://www.londondance.com</xref></cell></row>
<row><cell>The Morris Ring</cell><cell><xref doc="themorrisring">http://www.TheMorrisRing.org</xref></cell></row>
<row><cell>North American Folk Music and Dance Alliance</cell><cell><xref doc="folk">http://www.folk.org</xref></cell></row>
<row><cell>Pointe Magazine</cell><cell><xref doc="pointemagazine">http://pointemagazine.com</xref></cell></row>
<row><cell>Rich Holmes's Morris Site</cell><cell><xref doc="websyrrsholmesmorrisrichindex">http://web.syr.edu/~rsholmes/morris/rich/index.html</xref></cell></row>
<row><cell>Salsaweb</cell><cell><xref doc="salsaweb">http://www.salsaweb.com</xref></cell></row>
<row><cell>Shave The Donkey</cell><cell><xref doc="thedonkey">http://www.thedonkey.org</xref></cell></row>
<row><cell>Sruti</cell><cell><xref doc="sruti">http://www.sruti.com</xref></cell></row>
<row><cell>Star Dancers Ballet</cell><cell><xref doc="sdballet">http://www.sdballet.com</xref></cell></row>
<row><cell>tanznetz.de</cell><cell><xref doc="tanznetz">http://www.tanznetz.de</xref></cell></row>
<row><cell>Voice Of Dance</cell><cell><xref doc="voiceofdance">http://www.voiceofdance.org</xref></cell></row>
</table></p>
</div3>

<div3 type="part" n="03"><head>Film</head>
<p><table>
<row><cell>Africa Film &amp; TV</cell><cell><xref doc="africafilmtv">http://www.africafilmtv.com</xref></cell></row>
<row><cell>Cineaste: New African Cinema</cell><cell><xref doc="libberkeleyMRCnewafricancinema">http://www.lib.berkeley.edu/MRC/newafricancinema.html</xref></cell></row>
<row><cell>Film and Film-making in Africa</cell><cell><xref doc="szsmakingfilminafrica">http://www.szs.net/making-film-in-africa/</xref></cell></row>
<row><cell>Filmkult&#x00FA;ra</cell><cell><xref doc="filmkultura">http://www.filmkultura.hu</xref></cell></row>
<row><cell>H-AfrLitCine: African Literature &amp; Cinema</cell><cell><xref doc="hnetmsuaflitweb">http://www2.h-net.msu.edu/~aflitweb/</xref></cell></row>
<row><cell>Kinema: A Journal for Film and Audiovisual Media</cell><cell><xref doc="artsuwaterlooFINEjuhdekinemahp">http://arts.uwaterloo.ca/FINE/juhde/kinemahp.htm</xref></cell></row>
<row><cell>Production Weekly</cell><cell><xref doc="productionweekly">http://www.productionweekly.com</xref></cell></row>
<row><cell>Reviews and Reflections</cell><cell><xref doc="wpcmathfilmsindex">http://www.wpcmath.com/films/index.html</xref></cell></row>
<row><cell>Senses of Cinema</cell><cell><xref doc="sensesofcinema">http://www.sensesofcinema.com</xref></cell></row>
<row><cell>Sithengi: the Southern African Film &amp; TV Market Initiative</cell><cell><xref doc="sithengi">http://www.sithengi.co.za</xref></cell></row>
<row><cell>The South African Film Site</cell><cell><xref doc="safilm">http://www.safilm.org.za</xref></cell></row>
<row><cell>Urban Desires</cell><cell><xref doc="desiresstoryframe">http://desires.com/storyframe.html</xref></cell></row>
</table></p>
</div3>

<div3 type="part" n="04"><head>Music</head>

<p><table>
<row><cell>Addicted To Noise</cell><cell><xref doc="fortunecitytinpanclapton843index2">http://www.fortunecity.com/tinpan/clapton/843/index2.html</xref></cell></row>
<row><cell>Africa-Iwalewa's World Music Magazine</cell><cell><xref doc="weltmusikiwalewaindex">http://weltmusik.de/iwalewa/index.htm</xref></cell></row>
<row><cell>African Music Archive</cell><cell><xref doc="ntamaunimainzama">http://ntama.uni-mainz.de/~ama/</xref></cell></row>
<row><cell>Afromix</cell><cell><xref doc="afromixindexen">http://www.afromix.org/index.en.html</xref></cell></row>
<row><cell>Albmuzika: Albanian Music &amp; Art Zone</cell><cell><xref doc="albmuzika">http://www.albmuzika.com</xref></cell></row>
<row><cell>allAfrica.com</cell><cell><xref doc="allafricamusic">http://allafrica.com/music/</xref></cell></row>
<row><cell>amadinda</cell><cell><xref doc="amadindafsnet">http://www.amadinda.fsnet.co.uk</xref></cell></row>
<row><cell>Amazing Sounds</cell><cell><xref doc="amazingsingles">http://www.amazings.com/ingles.html</xref></cell></row>
<row><cell>AOR Basement</cell><cell><xref doc="aorbasement">http://www.aorbasement.com</xref></cell></row>
<row><cell>Ateliers d'ethnomusicologie</cell><cell><xref doc="adem">http://www.adem.ch</xref></cell></row>
<row><cell>Australian Institute of Eastern Music</cell><cell><xref doc="aiem">http://www.aiem.org.au</xref></cell></row>
<row><cell>The Balkan Music Website of Muammer Ketencoglu</cell><cell><xref doc="geocitiesVienna3651">http://www.geocities.com/Vienna/3651/</xref></cell></row>
<row><cell>beat thief</cell><cell><xref doc="beatthief">http://www.beatthief.com</xref></cell></row>
<row><cell>British Journal of Ethnomusicology</cell><cell><xref doc="shefuniacademicIMmusstaffjsBJE">http://www.shef.ac.uk/uni/academic/I-M/mus/staff/js/BJE.html</xref></cell></row>
<row><cell>Buda Musique: Music of the World</cell><cell><xref doc="budamusique">http://www.budamusique.com</xref></cell></row>
<row><cell>Chaos Control Digizine</cell><cell><xref doc="chaoscontrol">http://www.chaoscontrol.com</xref></cell></row>
<row><cell>Collection of Articles on Music of the World</cell><cell><xref doc="sunsitekthfeastlibmrfyinyuetextsarticles">http://sunsite.kth.se/feastlib/mrf/yinyue/texts/articles.html</xref></cell></row>
<row><cell>Computer Music Journal</cell><cell><xref doc="mitpress2ejournalsComputerMusicJournal">http://mitpress2.mit.edu/e-journals/Computer-Music-Journal/</xref></cell></row>
<row><cell>Cora Connection</cell><cell><xref doc="coraconnection">http://www.coraconnection.com</xref></cell></row>
<row><cell>Cosmik Debris Magazine</cell><cell><xref doc="cosmik">http://www.cosmik.com</xref></cell></row>
<row><cell>Critical Musicology</cell><cell><xref doc="leedsmusicinfocritmus">http://www.leeds.ac.uk/music/info/critmus/</xref></cell></row>
<row><cell>Croatian Music</cell><cell><xref doc="hrdarkoetfet12">http://www.hr/darko/etf/et12.html</xref></cell></row>
<row><cell>Cross Cultures</cell><cell><xref doc="crossrunews">http://cross.ru/news/</xref></cell></row>
<row><cell>Culture Kiosque</cell><cell><xref doc="culturekiosque">http://www.culturekiosque.com</xref></cell></row>
<row><cell>Current Musicology</cell><cell><xref doc="musiccolumbiacurmus">http://music.columbia.edu/~curmus/</xref></cell></row>
<row><cell>Descarga</cell><cell><xref doc="descarga">http://www.descarga.com</xref></cell></row>
<row><cell>dotmusic</cell><cell><xref doc="dotmusic">http://www.dotmusic.com</xref></cell></row>
<row><cell>Dutch Journal of Music Theory</cell><cell><xref doc="scaahknltvmindex">http://sca.ahk.nl/tvm/index.html</xref></cell></row>
<row><cell>Electronic Musicological Review</cell><cell><xref doc="humanasufprbrrem">http://www.humanas.ufpr.br/rem/</xref></cell></row>
<row><cell>EOL Journal</cell><cell><xref doc="researchumbceduefhmeol">http://research.umbc.edu/efhm/eol.html</xref></cell></row>
<row><cell>Ethnomusicology Research Digest</cell><cell><xref doc="informumdEdResNewslettersEthnoMusicology">http://www.inform.umd.edu/EdRes/ReadingRoom/Newsletters/EthnoMusicology/</xref></cell></row>
<row><cell>Exclaim!</cell><cell><xref doc="exclaim">http://www.exclaim.ca</xref></cell></row>
<row><cell>FZMw: Frankfurter Zeitschrift f&#x00FC;r Musikwissenschaft</cell><cell><xref doc="unifrankfurtfb09muwiFZMw">http://www.uni-frankfurt.de/fb09/muwi/FZMw.html</xref></cell></row>
<row><cell>GearheadEzine</cell><cell><xref doc="instrumentsgearhead">http://www.1800instruments.com/gearhead.htm</xref></cell></row>
<row><cell>Gridface</cell><cell><xref doc="gridface">http://www.gridface.com</xref></cell></row>
<row><cell>Hans Brandeis Homepage</cell><cell><xref
doc="aedvcstuberlinbrandeisindex">http://aedv.cs.tu-berlin.de/~brandeis/index.html</xref></cell></row>
<row><cell>HardC.O.R.E.</cell><cell><xref doc="textfilesmagazinesHARDCORE">http://www.textfiles.com/magazines/HARDCORE/</xref></cell></row>
<row><cell>Hitmakers Magazine</cell><cell><xref doc="hitmakers">http://www.hitmakers.com</xref></cell></row>
<row><cell>The Hungarian Music Page</cell><cell><xref doc="dcommsarvariindex">http://www2.4dcomm.com/sarvari/index.html</xref></cell></row>
<row><cell>International Library African Music</cell><cell><xref doc="archiveilamruhome">http://archive.ilam.ru.ac.za/home.asp</xref></cell></row>
<row><cell>IRCAM ForumNet</cell><cell><xref doc="forumnetircamrubriquephp3idrubrique13">http://forumnet.ircam.fr/rubrique.php3?id_rubrique=13</xref></cell></row>
<row><cell>IUMA</cell><cell><xref doc="iuma">http://www.iuma.com</xref></cell></row>
<row><cell>Jazz Guitar Online</cell><cell><xref doc="jazzguitar">http://www.jazzguitar.com</xref></cell></row>
<row><cell>JazzUSA</cell><cell><xref doc="jazzusa">http://jazzusa.com</xref></cell></row>
<row><cell>Jelly</cell><cell><xref doc="jellyroll">http://www.jellyroll.com</xref></cell></row>
<row><cell>Kulttuurivihkot</cell><cell><xref doc="kulttuurivihkot8m">http://www.kulttuurivihkot.8m.com</xref></cell></row>
<row><cell>'LA'Ritmo.com</cell><cell><xref doc="laritmo">http://www.laritmo.com</xref></cell></row>
<row><cell>MBIRA</cell><cell><xref doc="mbira">http://www.mbira.org</xref></cell></row>
<row><cell>The Mbira Page</cell><cell><xref doc="zambukombirapagemintro">http://www.zambuko.com/mbirapage/m_intro.html</xref></cell></row>
<row><cell>MEMI: Elektronische Musik &amp; Homerecording</cell><cell><xref doc="memimakers">http://www.memi.de/makers.php3</xref></cell></row>
<row><cell>Mi2N: Music Industry News Network</cell><cell><xref doc="mi2n">http://www.mi2n.com</xref></cell></row>
<row><cell>Min-Ad: Israel Studies in Musicology Online</cell><cell><xref doc="biuhumuimsMinad">http://www.biu.ac.il/hu/mu/ims/Min-ad/</xref></cell></row>
<row><cell>Muse Magazine</cell><cell><xref doc="musewelcomehtml">http://www.muse.ie/welcome.html</xref></cell></row>
<row><cell>Museweek</cell><cell><xref doc="stokstadcyberspacecafemuseweek">http://www.stokstad.com/cyberspacecafe/museweek.html</xref></cell></row>
<row><cell>Music &amp; Anthropology</cell><cell><xref doc="researchumbceolMAindex">http://research.umbc.edu/eol/MA/index.htm</xref></cell></row>
<row><cell>Music by Light</cell><cell><xref doc="itpnyuGALLERYmusiclight">http://http://www.itp.nyu.edu/GALLERY/music_light.html</xref></cell></row>
<row><cell>Music in Ghana</cell><cell><xref doc="ghanawebGhanaHomePageghmusic">http://www.ghanaweb.com/GhanaHomePage/ghana/gh_music.html</xref></cell></row>
<row><cell>The Music Magazine</cell><cell><xref doc="themusicmagazine">http://www.themusicmagazine.com</xref></cell></row>
<row><cell>The Music of Zimbabwe</cell><cell><xref doc="scholarsnuslandowpostzimbabwemusiczmusicov">http://www.scholars.nus.edu.sg/landow/post/zimbabwe/music/zmusicov.html</xref></cell></row>
<row><cell>Musical Traditions</cell><cell><xref doc="mustrad">http://www.mustrad.org.uk</xref></cell></row>
<row><cell>MusicAnd: International Site for Music Educational Innovation</cell><cell><xref doc="multimaniamusicandindex">http://www.multimania.com/musicand/index.html</xref></cell></row>
<row><cell>NetMusik.com</cell><cell><xref doc="netmusik">http://www.netmusik.com</xref></cell></row>
<row><cell>Northern Journey Online Journal</cell><cell><xref doc="northernjourneycdnfolkjournalnjojcg">http://www.northernjourney.com/cdnfolk/journal/njojcg.html</xref></cell></row>
<row><cell>Notation Machine</cell><cell><xref doc="notationmachine">http://www.notationmachine.com</xref></cell></row>
<row><cell>NTAMA: Journal of African Music and Popular Culture</cell><cell><xref doc="ntamaunimainz">http://ntama.uni-mainz.de</xref></cell></row>
<row><cell>Organic AlterNETive</cell><cell><xref doc="ufsmalternet">http://www.ufsm.br/alternet/</xref></cell></row>
<row><cell>Orpheus Classical Music Magazines</cell><cell><xref doc="choirandorganchoir">http://www.choirandorgan.com/choir.htm</xref></cell></row>
<row><cell>The Pan Page: A Forum for the Steel Pan Instrument</cell><cell><xref doc="stockholmmusicmuseumpan">http://stockholm.music.museum/pan/</xref></cell></row>
<row><cell>Pop-Culture-Corn Magazine</cell><cell><xref doc="popculturecorn">http://www.popculturecorn.com</xref></cell></row>
<row><cell>Progression</cell><cell><xref doc="progressionmagazine">http://progressionmagazine.com</xref></cell></row>
<row><cell>Publications of the Society for Ethnomusicology</cell><cell><xref doc="indianaethmusicpublications">http://www.indiana.edu/~ethmusic/publications/publications.html</xref></cell></row>
<row><cell>The Rebetiko Club</cell><cell><xref doc="rembetikoclub">http://www.rembetiko.gr/club.htm</xref></cell></row>
<row><cell>(Re)Soundings</cell><cell><xref doc="millersvresound">http://www.millersv.edu/~resound</xref></cell></row>
<row><cell>Rockbites</cell><cell><xref doc="rockbites">http://www.rockbites.com</xref></cell></row>
<row><cell>RollingStone</cell><cell><xref doc="rollingstone">http://www.rollingstone.com</xref></cell></row>
<row><cell>RPM Online: The Review of Popular Music</cell><cell><xref doc="iaspmrpm">http://www.iaspm.net/rpm/</xref></cell></row>
<row><cell>Russian Independent Music</cell><cell><xref doc="gromcomusicrimarchive">http://gromco.com/music/rim_archive/</xref></cell></row>
<row><cell>SIbE</cell><cell><xref doc="sibetrans">http://www.sibetrans.com</xref></cell></row>
<row><cell>Side-Line</cell><cell><xref doc="sideline">http://www.side-line.com</xref></cell></row>
<row><cell>Soundout</cell><cell><xref doc="soundout">http://www.soundout.net</xref></cell></row>
<row><cell>South African Journal of Musicology</cell><cell><xref doc="undsamus">http://www.und.ac.za/und/samus/</xref></cell></row>
<row><cell>Sruti</cell><cell><xref doc="sruti">http://www.sruti.com</xref></cell></row>
<row><cell>STM-Online</cell><cell><xref doc="musikuussmstmonline">http://www.musik.uu.se/ssm/stmonline/</xref></cell></row>
<row><cell>The Tabla Site</cell><cell><xref doc="chandrakanthatablasite">http://chandrakantha.com/tablasite/</xref></cell></row>
<row><cell>Techno Online</cell><cell><xref doc="techno">http://www.techno.de</xref></cell></row>
<row><cell>themusic.com.au</cell><cell><xref doc="themusicimmindex">http://www.themusic.com.au/im_m/index.html</xref></cell></row>
<row><cell>Turkish Music &amp; Voice Library</cell><cell><xref doc="turkishmusic">http://www.turkishmusic.org</xref></cell></row>
</table></p>
</div3>

<div3 type="part" n="05"><head>Theater</head>

<p><table>
<row><cell>About Performance</cell><cell><xref doc="artsusyddepartsperformPUBLICATIONScontactdepartment">http://www.arts.usyd.edu.au/departs/perform/PUBLICATIONS/contact%20department.html</xref></cell></row>
<row><cell>Arena</cell><cell><xref doc="siciliateatro">http://www.siciliateatro.org</xref></cell></row>
<row><cell>Comparative Drama</cell><cell><xref doc="wmichcompdrindex">http://www.wmich.edu/compdr/index.html</xref></cell></row>
<row><cell>CurtainUp</cell><cell><xref doc="curtainup">http://www.curtainup.com</xref></cell></row>
<row><cell>Drama Magazine: the Journal of National Drama</cell><cell><xref doc="dramamagazine">http://www.dramamagazine.co.uk</xref></cell></row>
<row><cell>The Dramatist Magazine</cell><cell><xref doc="dramatistsguilddocdrama">http://www.dramatistsguild.com/doc/drama.htm</xref></cell></row>
<row><cell>The Electronic Newletter of Zimbabwe's National Theatre Organisation</cell><cell><xref doc="infozinemirrortheatre">http://www.infozine.com/mirror/theatre/</xref></cell></row>
<row><cell>The Eugene O'Neill Newsletter</cell><cell><xref doc="eoneilllibrarynewsletterindex">http://www.eoneill.com/library/newsletter/index.htm</xref></cell></row>
<row><cell>Galatea</cell><cell><xref doc="galatealetvu">http://galatea.let.vu.nl</xref></cell></row>
<row><cell>George Coates Performance Works</cell><cell><xref doc="georgecoates">http://www.georgecoates.org</xref></cell></row>
<row><cell>Journal of American Drama and Theater</cell><cell><xref doc="webgccunyMESTCjadt">http://web.gc.cuny.edu/MESTC/jadt.htm</xref></cell></row>
<row><cell>Journal of the Irish Theatre Forum</cell><cell><xref doc="ucdirthfrm">http://www.ucd.ie/~irthfrm/</xref></cell></row>
<row><cell>Journal of Theater and Drama</cell><cell><xref doc="researchhaifatheatrejtd">http://research.haifa.ac.il/~theatre/jtd.html</xref></cell></row>
<row><cell>London Theatre Guide: Back Issues of Newsletters</cell><cell><xref doc="londontheatremembersbackissuesnewsletters">http://www.londontheatre.co.uk/members/backissuesnewsletters.htm</xref></cell></row>
<row><cell>OOBR: the Off-Off-Broadway Review</cell><cell><xref doc="oobr">http://www.oobr.com</xref></cell></row>
<row><cell>PAJ: A Journal of Performance and Art</cell><cell><xref doc="pressjhupressjournalspaj">http://www.press.jhu.edu/press/journals/paj/paj.html</xref></cell></row>
<row><cell>P&#x00E9;ndulo World Wide Web: Teatro</cell><cell><xref doc="hypergraphiapendulo0teat">http://www.hypergraphia.com/pendulo/0teat.html</xref></cell></row>
<row><cell>Performance Art Festival+Archives</cell><cell><xref doc="performanceartpagesindex">http://www.performance-art.org/pages/index.cfm</xref></cell></row>
<row><cell>PLASA Media - Lighting&amp;Sound International</cell><cell><xref doc="plasamedialsi">http://http://www.plasa.org/media/lsi/</xref></cell></row>
<row><cell>Proptology: The Journal of Props Professionals</cell><cell><xref doc="homeeolprops">http://home.eol.ca/~props/</xref></cell></row>
<row><cell>Publications and Theatre News</cell><cell><xref doc="plattevilletheatrepctpubd">http://www.plattevilletheatre.org/pctpubd.htm</xref></cell></row>
<row><cell>La Revue Du Spectacle</cell><cell><xref doc="wwwusersimaginetchauveausomm">http://wwwusers.imaginet.fr/~chauveau/somm.html</xref></cell></row>
<row><cell>Scenography International</cell><cell><xref doc="lbororesearchscenography">http://www.lboro.ac.uk/research/scenography/</xref></cell></row>
<row><cell>Stage Directions</cell><cell><xref doc="stagedirections">http://www.stage-directions.com</xref></cell></row>
<row><cell>The Stage Newspaper Ltd</cell><cell><xref doc="thestage">http://www.thestage.co.uk</xref></cell></row>
<row><cell></cell><cell></cell></row>
<row><cell></cell><cell></cell></row>
</table></p>
</div3>
</div2>

<div2 type="subsection"><head>Appendix C.  Dance electronic resources</head>

<p><table>
<row><cell>ArtsJournal: the Daily Digest of Arts, Culture &amp; Ideas</cell><cell><xref doc="artsjournal">http://www.artsjournal.com</xref></cell></row>
<row><cell>Backstage.com</cell><cell><xref doc="backstage">http://www.backstage.com</xref></cell></row>
<row><cell>Ballet Alert!</cell><cell><xref doc="balletalert">http://www.balletalert.com</xref></cell></row>
<row><cell>Ballet.co Magazine</cell><cell><xref doc="balletmagazine">http://www.ballet.co.uk/magazine/</xref></cell></row>
<row><cell>ballettanz</cell><cell><xref doc="ballettanz">http://www.ballet-tanz.de</xref></cell></row>
<row><cell>Ballroom Dancing Times</cell><cell><xref doc="dancingtimesballroomdt">http://www.dancing-times.co.uk/ballroomdt.html</xref></cell></row>
<row><cell>Body Space &amp; Technology Journal</cell><cell><xref doc="bruneldeptspfabstjournal3no1journal31">http://www.brunel.ac.uk/depts/pfa/bstjournal/3no1/journal3_1.htm</xref></cell></row>
<row><cell>Cambodian Arts</cell><cell><xref doc="researchumbcefhmcambodiaindex">http://research.umbc.edu/efhm/cambodia/index.htm</xref></cell></row>
<row><cell>Critical Dance</cell><cell><xref doc="criticaldance">http://www.criticaldance.com</xref></cell></row>
<row><cell>Culture Kiosque</cell><cell><xref doc="culturekiosque">http://www.culturekiosque.com</xref></cell></row>
<row><cell>Dance Advance</cell><cell><xref doc="danceadvanceindex2">http://www.danceadvance.org/index2.html</xref></cell></row>
<row><cell>Dance Europe</cell><cell><xref doc="danceeurope">http://www.danceeurope.net</xref></cell></row>
<row><cell>Dance Expression</cell><cell><xref doc="danceexpressionmag">http://www.danceexpressionmag.co.uk</xref></cell></row>
<row><cell>The Dance Insider</cell><cell><xref doc="danceinsider">http://danceinsider.com</xref></cell></row>
<row><cell>Dance Magazine</cell><cell><xref doc="dancemagazine">http://www.dancemagazine.com</xref></cell></row>
<row><cell>Dance Online</cell><cell><xref doc="danceonlineindex">http://www.danceonline.com/index.html</xref></cell></row>
<row><cell>Dance Spirit Magazine</cell><cell><xref doc="dancespirit">http://dancespirit.com</xref></cell></row>
<row><cell>Dance Teacher Magazine</cell><cell><xref doc="danceteacher">http://www.dance-teacher.com</xref></cell></row>
<row><cell>DanceArt</cell><cell><xref doc="danceart">http://www.danceart.com</xref></cell></row>
<row><cell>Dancer's Delight</cell><cell><xref doc="msuuserokumurak">http://www.msu.edu/user/okumurak/</xref></cell></row>
<row><cell>Dancesport UK</cell><cell><xref doc="dancesport">http://www.dancesport.uk.com</xref></cell></row>
<row><cell>DanceView</cell><cell><xref doc="danceview">http://www.danceview.org</xref></cell></row>
<row><cell>Danz</cell><cell><xref doc="danz">http://www.danz.org.nz</xref></cell></row>
<row><cell>The Israeli Folk Dance Connection</cell><cell><xref doc="webspanhgpklm">http://www.webspan.net/~hgpklm/</xref></cell></row>
<row><cell>ISTD [The Imperial Society of Teachers of Dancing] News</cell><cell><xref doc="istdnews">http://www.istd.org/news.html</xref></cell></row>
<row><cell>Kulttuurivihkot</cell><cell><xref doc="kulttuurivihkot8m">http://www.kulttuurivihkot.8m.com</xref></cell></row>
<row><cell>Lancashire Folk</cell><cell><xref doc="onetellancashirefolk">http://web.onetel.net.uk/~lancashirefolk/</xref></cell></row>
<row><cell>The Morris Ring</cell><cell><xref doc="themorrisring">http://www.themorrisring.org</xref></cell></row>
<row><cell>North American Folk Music and Dance Alliance</cell><cell><xref doc="folk">http://www.folk.org</xref></cell></row>
<row><cell>Pointe Magazine</cell><cell><xref doc="pointemagazine">http://pointemagazine.com</xref></cell></row>
<row><cell>La Revue du Spectacle</cell><cell><xref doc="wwwusersimaginetchauveausomm">http://wwwusers.imaginet.fr/~chauveau/somm.html</xref></cell></row>
<row><cell>Richard Holme's Morris site</cell><cell><xref doc="websyrrsholmesmorrisrichindex">http://web.syr.edu/~rsholmes/morris/rich/index.html</xref></cell></row>
<row><cell>Shave the Donkey</cell><cell><xref doc="thedonkey">http://www.thedonkey.org</xref></cell></row>
<row><cell>Sruti</cell><cell><xref doc="sruti">http://www.sruti.com</xref></cell></row>
<row><cell>The Stage Newspaper Ltd</cell><cell><xref doc="thestage">http://www.thestage.co.uk</xref></cell></row>
<row><cell>Star Dancers Ballet</cell><cell><xref doc="biglobeneballetstar">http://www2a.biglobe.ne.jp/~ballet/star.html</xref></cell></row>
<row><cell>tanznetz.de</cell><cell><xref doc="tanznetz">http://www.tanznetz.de</xref></cell></row>
<row><cell>TANZOriental</cell><cell><xref doc="tanzoriental">http://www.tanzoriental.com</xref></cell></row>
<row><cell>The Village Voice: Dance</cell><cell><xref doc="villagevoicedance">http://www.villagevoice.com/dance/</xref></cell></row>
<row><cell>Voice of Dance</cell><cell><xref doc="voiceofdance">http://www.voiceofdance.org</xref></cell></row>
<row><cell>Women and Performance: a Journal of Feminist Theory</cell><cell><xref doc="womenandperformance">http://www.womenandperformance.org</xref></cell></row>
</table></p>
</div2>
</div1>

<div1 type="section" n="06"><head>Report On A Mellon-Funded Planning Project <lb/>For Archiving Scholarly Journals</head>
<p rend="center">John Mark Ockerbloom <lb/>University of Pennsylvania Library <lb/>16 September 2002</p>

<div2 type="subsection" n="01"><head>Abstract</head>
<p>We report on the Penn Library's Mellon-funded project to plan for electronic journal archiving.  Our project focused on working with two university-affiliated publishers, Oxford and Cambridge.  We discussed rights and responsibilities, built prototypes for automatic importation of presentation files and metadata, studied issues of migration, particularly of PDF files, and considered archival economics and tradeoffs between funding by publishers and access by libraries.  We recommend a broadly supported archival system and outline two architectures for such a system: a centrally managed archive, supported by libraries and giving libraries access to archived material (extending the JSTOR model),<note target="Penn01">[1]</note> and a widely distributed archival network of library-based lightweight repositories (extending the LOCKSS model).<note target="Penn02">[2]</note>  For both models, we discuss how service providers in the architecture can carry out important archival support tasks while easing the workload on central servers or on library repositories.  We see Penn's immediate role in the archival community not as an integrated archive, but as one of the service providers for key functions including ingestion, migration, and registry services.</p>
</div2>

<div2 type="subsection" n="02"><head>Introduction: Why are we doing this?</head>
<p>Digital and network technologies are rapidly changing the nature of scholarly communication.  Scholars increasingly use the electronic medium to publish their research results. In this medium, new knowledge can be disseminated extremely quickly by anyone with access to the Internet, and accessed at any time from anywhere with a network connection.  Costs to reproduce and disseminate information  --  though not necessarily the costs to produce, review, and edit it  --  can be greatly reduced online, thus enabling organizations that could not afford to publish scholarly information to do so.  The nature of the electronic medium also supports new modes of publishing.  Freed from the constraints of print, scientists can publish long, complex data sets along with their articles.  Sound, video, and interactive programs can be published along with text and still images.  Search and linking facilities can be added to electronic versions of journals and monographs making it substantially easier for researchers to locate and use relevant research.  The interconnectedness of the Internet also allows the nature of journals to change from a set of issues with a static set of articles, to more dynamic collections and databases of published research.</p>
<p>Consumers as well as producers of scholarly content have embraced the electronic medium. A 2002 survey of Penn library users revealed that users overall consider the library's provision of electronic information needed for work more important than its provision of print information needed for work. While some communities, particularly those in the arts and humanities, ranked providing print information as higher priority, others, particularly users of Penn's biomedical, engineering, and business libraries, ranked electronic resources as significantly more important.<note target="Penn03">[3]</note> Electronic journals and databases that describe journal articles (often with links to electronic full text) rank among the most frequently accessed resources in Penn's libraries.  In June 2002, the Penn libraries carried over 6,500 full-text online journals, over 5,600 of which were paid subscriptions.  The most popular of these electronic journals was accessed over 15,000 times per year by Penn researchers, and several others were accessed over 5,000 times per year as well.<note target="Penn04">[4]</note></p>
<p>While electronic journals offer new benefits, they also bring new risks.  Researchers depend not only on current journals, but on the centuries-old back files of journals that they can use for scholarship.  However, electronic journals are not easily preserved.  Unlike print journals they live on fragile media, rely on rapidly changing technology and computing environments for their presentation, and depend on the policies and fortunes of their copyright holders for their disposition.  The new types of content supported by electronic journals, the advanced search and linking facilities, and the rapid access that electronic journal readers are accustomed to, further complicate the preservation problem.</p>
<p>Despite the complexities of the preservation problem, though, libraries cannot afford to ignore it.  Electronic versions of scholarly journals are in many cases becoming the versions of record, with important scholarly communication not included in print publications.  This includes not only multimedia content, but the interactive feedback that appears in journals intended for rapid dissemination of new results, such as BMJ, the online version of the <hi rend="italics">British Medical Journal</hi>.</p>
<p>Understanding the progress of scholarship will require continued access to this record.  At the same time, as other types of work of scholarly interest also move into the electronic realm  --  everything from email to researchers' notes to experimental prototypes to interactive Web sites  --  libraries and archives will have to find ways to preserve relevant materials in those areas as well.  In some respects journals, which tend to have more predictable formats and publication cycles as well as more careful editing than other types of electronic works, are a useful starting point for understanding the general problem of electronic preservation.</p>
<p>We at the University of Pennsylvania Library, then, decided to start planning for electronic journal archiving with the aid of a Mellon Foundation grant.  In this report, we describe our experiences in the planning project, and summarize our findings and recommendations for electronic journal archiving. Originally, we planned to set up a journal archive for particular publishers' journals.  By the end of the grant period, we felt it was best not to commit to a journal archive, but we do see a place for us as a trusted service provider for certain specific archival functions in an archival network.  Some of our experiences in the planning project may also help us in the design of institutional repositories which may eventually play important archival functions as well.</p>
<p>The report is structured as follows: After a brief summary of our past arrangements for journal preservation in the print-only era, we summarize the basic requirements for a reliable electronic journal archive. We consider alternative forms of archived material and for the organization of archival communities. We discuss appropriate rights and responsibilities of archival systems. We then report on a few key points concerning the life cycle of the archival process, focusing in particular on ingestion and adaptation to changing technologies.  Finally, we conclude with a summary of our experience and recommendations for the next stages in developing the electronic journal archiving community.</p>
<p>We will address these issues not only from a theoretical perspective but also by reporting our own experience in the planning stage.  The planning process made it clear that the challenges for electronic journal archives involve technical, social, and economic issues throughout the archival process. We often have to consider tradeoffs between what researchers would desire in an ideal archive and what is economically feasible in a reliable, robust, and sustainable record of scholarly communication.  Also, we have to consider how an archive interacts with other archives and with other stakeholders in the archival community: authors, readers, educational institutions, and publishers.</p>
</div2>

<div2 type="subsection" n="03"><head>Journal preservation in the print era</head>
<p>When considering strategies for preserving electronic journals it is worth asking whether special archives are needed at all.  After all, in the print era libraries have preserved many scholarly journals through their normal operations without having to set up special archival units or to take on formal responsibilities for preservation beyond their own local communities.  Libraries simply retained and bound copies of the journals they originally received from the publishers and kept them on their shelves.  While these bound volumes can deteriorate physically over time or be subject to loss or damage, bound volumes that are over one hundred years old and still perfectly usable are not uncommon in research libraries.  No copyright restrictions prevented libraries from binding and retaining old issues; no technological changes made these print journals unreadable.  Moreover, libraries could exploit redundancy to fill gaps in their own holdings.  Since copies of scholarly journals were sent to multiple universities, many of which attempted to retain them, a library lacking an issue a scholar sought could simply borrow the issue or obtain a photocopy of a needed article from another institution that retained a usable copy.  Similarly, when journals and other materials were copied to microform, these microforms also were distributed to many libraries.  Through these means, libraries could build up a robust preservation mechanism where the only costs beyond initial acquisition of materials were keeping them on the shelves, maintaining interlibrary loan systems, and sometimes acquiring "migrated" forms such as microfilms.<note target="Penn05">[5]</note> Since the libraries owned the journals and the first-sale doctrine of copyright law let them dispose of these journals as they saw fit, their preservation was also largely unconstrained by the journals' copyright holders.</p>
<p>The same approach is not unthinkable for electronic journals, but at present few libraries retain electronic journals and provide them to their readers.  As long as this is the case, an equivalent informal substitute for archiving will not suffice. Most libraries, after all, can provide access to electronic journals simply by pointing to copies on publisher or aggregator sites, without the expense involved in acquiring and storing them locally.  Therefore, unless libraries see definite benefits in keeping local copies that outweigh the costs, redundant local storage networks are unlikely to arise on their own, especially if they lack the durability and freedom to copy of the print journal environment.  Therefore, libraries will either need to organize or support archival organizations, or develop viable local storage networks that can reliably and cost-effectively preserve electronic journals.</p>
<p>An analysis of the informal print journal "archiving" network needs to consider its limitations as well as its advantages. Access to back issues of print journals is much slower than access to electronic journals, especially as libraries increasingly move older journal volumes out of primary stacks and into high-density storage.  When researchers seek journal issues their institutions don't have, they may have to wait weeks for interlibrary loan.  Cumulative storage costs for a journal volume redundantly stored in dozens or hundreds of locations is also significant, taken as a whole, even if the costs per institution are low. Furthermore, there is no guarantee that issues will remain obtainable.</p>
<p>Consider the experience of JSTOR which has digitized back issues of important scholarly print journals in the arts and sciences, with back issues provided by publishers and participating libraries. With over 1,300 participants in June 2002, JSTOR still lacked complete runs of 33 of its 218 online journals, with approximately 300 missing volumes and about 70 missing individual issues.  About half of the missing volumes, and most of the missing individual issues, were not from the start of a run: that is, they represent gaps in holdings made available for digitization after libraries had started subscribing to the journals. If an average volume has six issues, these figures suggest a loss of about one-and-one-half percent of back issues for journals of interest to the JSTOR consortium, counting from the earliest available volume of journals, or a little over three percent counting from the first published issue.  Many of these missing issues may well be in libraries and simply have not been made available to JSTOR.  However, such issues are also likely to be relatively difficult to obtain by a scholar who might need them.  (We have not yet, however, tried obtaining "missing" issues ourselves via interlibrary loan.)<note target="Penn06">[6]</note></p>
</div2>

<div2 type="subsection" n="04"><head>Requirements for electronic journal archives</head>
<p>The alternative to having libraries depend on their own and their neighbors' stored copies of electronic journals is to have them use trusted digital journal repositories.  Several types of organizations could run such repositories, including the publishers of the content, particular academic or national libraries that state a commitment to preserve content, dedicated archival organizations, scholarly societies, or organized consortia of any of the preceding organizations.  Whatever the nature of a repository's maintainer, however, users will have to trust that the repository will preserve content and provide access to it when needed.</p>
<p>Several papers have been published outlining the requirements for a trusted digital repository. In 2000, a Digital Library Federation working group that included both librarians and nonprofit publishers released a set of minimum criteria for a journal archival repository.<note target="Penn07">[7]</note> Here is a condensed paraphrase of these criteria:</p>

<list>
<item>A repository will be a trusted party that conforms to minimum requirements agreed to by both scholarly publishers and libraries.</item>
<item>It will define its mission in regard to the needs of scholarly publishers and research libraries, and be explicit about what it is willing to archive and for whom.</item>
<item>It will negotiate and accept appropriate deposits from scholarly publishers.</item>
<item>It will have sufficient control of deposits to ensure their long-term preservation.</item>
<item>It will follow documented policies and procedures to ensure preservation in all reasonable contingencies.</item>
<item>It will make preserved information available to libraries under conditions negotiated with publishers.</item>
<item>It will work as part of a network.</item>
</list>

<p>What does a repository need to do to be considered a "trusted party"? A more recent paper issued by the Research Libraries Group specified these key attributes of a trusted repository (rearranged from their original ordering):<note target="Penn08">[8]</note></p>

<list>
<item>Administrative responsibility</item>
<item>Organization viability</item>
<item>Financial sustainability</item>
<item>Technological and procedural suitability</item>
<item>System security</item>
<item>Procedural accountability</item>
<item>Compliance with the Reference Model for an Open Archival Information System (OAIS)</item>
</list>

<p>The first three of these attributes deal almost entirely with the persistence of the organization, rather than any technical criteria.  To be trusted, the organization must commit to being responsible for the archived material and be able to sustain this commitment over the long term, including any necessary financial commitments.  Implicitly, this commitment is being made to all of the people who "trust" it: in this case, the scholarly community at large, including the publishers of scholarly material.</p>
<p>Libraries contemplating creating and maintaining a trusted digital archive, then, must consider such a commitment carefully. For many academic libraries, including Penn's, it represents a subtle but significant augmentation of a library's mission. In general, the Penn library is charged with maintaining and providing access to information for the teaching and research needs of the Penn community.  It receives the bulk of its funding from the various schools and departments of the university that make up this community.  If material that the library has acquired no longer is of interest to the community, or is too expensive to maintain compared to other priorities of the university, the library can decide to dispose of it.  Indeed, to properly carry out its mission, the library <hi rend="italics">should</hi> dispose of it if this is necessary to sustain the library's more critical services, and if it has not made promises to others to retain the information.</p>
<p>This does not mean the library should not care about long-term preservation or should not participate in communal archiving efforts involving multiple institutions, but the library does need to carefully consider any commitment made to constituents outside the university to make sure it complements university interests.  Because scholarly journals may have a usage life of centuries or more, the library needs to be sure it can sustain this commitment over such a timespan or can transfer its responsibilities to another trusted party if it cannot.  It must also be sure it can continue to get funds to support this commitment.  If its funds come from the university, the university as well as the library must be committed to the archiving project at the highest levels.  If the funds come from other sources, such as archive depositors or users, the business model for the archive must show that these sources are sufficient to support the archive's commitments.</p>
<p>The more technically-oriented attributes of the RLG list emphasize the importance of prudently chosen, well-documented, secure, and transparent processes for archiving materials.  The requirement to conform to OAIS provides a partial functional specification of such processes, using an established and tested ISO standard that details the archiving process and provides an information model for the data maintained as part of this process.<note target="Penn09">[9]</note></p>
<p>One of the most important aspects of the OAIS model is its modularity.  Archived materials in OAIS, and their metadata, come in Archival Information Packages (AIPs) and are likewise acquired and disseminated in similar packages.  The functions of the archive are also divided into modules operating on the AIPs in various ways.  This model allows us to look at an archival scheme not just as a large, monolithic unit, but as a system whose functions and responsibilities can be disseminated and replicated through a community of archival stakeholders.  Content can be replicated reliably at multiple sites by replicating its AIPs, which contain all of the information needed to access and use the content.  Archival functions such as ingestion and migration, because of their modularity, can also be delegated to multiple service providers (which may be separate from the rest of the archive) with appropriate expertise, certification, and trust. The model, in short, can apply to an archival system as a whole, not just to a single repository.  In some cases, as we saw with the redundant informal network of print journal "archiving", the entire system can have properties that make it trustworthy, even if no individual repository in the system is particularly trustworthy.</p>
</div2>

<div2 type="subsection" n="05"><head>What to archive?</head>
<p>Archives need to decide which of the thousands of electronic journals they will preserve. Two methods of narrowing down the field occurred to us, each with its own advantages:</p>
<list>
<item>We could limit the number of publishers we would work with. This has several appeals.  It limits the number of publisher agreements that need to be made, each of which may require substantial negotiation.  It allows us to work with and support publishers with whom we already have close relationships and wish to see represented in the archive.  It is likely to reduce the number of input formats to the archive, and the diversity of procedures required to ingest journal content, thus lowering overall costs of ingesting material.  Furthermore, in a networked environment, with multiple, independently run archives, responsibilities can be more cleanly partitioned by publisher than by less definite criteria like subjects.</item>
<item>We could limit the topical scope of the journals we would work with.  This also has its advantages.  It allows us to focus on disciplines that are of special interest to the university, and ignore those that are of little or no interest.  It makes it easier for us to find experts in the disciplines that can advise us on which journals are most important to preserve, and on how they should be preserved.  If the archive is sufficiently comprehensive, the archive can also serve as a self-contained research resource in its own right for its specialized disciplines.  Such a resource can be "marketed" as a resource for the community engaged in that discipline, which may then fund the archive through subscriptions or grants.</item>
</list>

<p>We decided initially to only work with a few publishers.  In another Mellon-funded project, we are working with Oxford University Press and Cambridge University Press to put history books online.  We decided it would be fruitful to work with these publishers for journal archiving as well.  We already had relationships with them, they published many high quality journals that Penn already subscribed to, and we wanted to support the role of university-affiliated publishers as important participants in the scholarly communication process.</p>
<p>We also needed to decide what constituted preservable content in the journals we handled.  In online journals, which may have external hyperlinks, auxiliary searching and browsing scripts, dynamically updated and targeted advertisements (which may be out of the control of the actual journal publisher), comment boards, and ephemeral description files, the distinction between journal content that should be preserved and external content can blur. Since the purpose of the archive is to preserve the record of scholarship, though, the archive should at minimum preserve all refereed editorial matter published by the journals we archive.  This includes not only research articles, but also reviews, letters to the editor, and other edited content.  We considered it best not to guarantee archiving or preservation of advertising matter, ephemeral and informal indexes (such as a page with links to current and past journal articles), search engines, other server programs, or auxiliary materials not clearly part of the journal itself.  Hence, an edited Letters column, published as part of an issue, would be included in the archive, an auxiliary, unmoderated threaded Web-discussion board would generally not need to be included in the archive.  Also, while advertising may have some interest to future historians, it is not itself part of the record of scholarship, so it is not as important to an archive of scholarly journals as it might be to an archive of popular or trade journals.  Technical and legal issues around downloading and archiving advertisements make them problematic to commit to archiving them, except in cases where advertisements and scholarly content are integrated in the same file.</p>
<p>Exceptions may need to be made to the rules above for certain journals.  For example, unrefereed submissions are an important part of some journals that focus on the latest progress reports of research.  For example, the BMJ, the online version of the <hi rend="italics">British Medical Journal</hi>, allows appropriately credentialed readers to make "rapid responses" to articles, which are usually posted within twenty-four hours of receipt.  While these responses are moderated for relevance, they are not refereed, and editing is minimal.  But they represent an important part of the scholarly communication provided by this online journal.  An archive of this journal, then, should attempt to preserve these responses, even if archiving an unpredictably-growing set of responses to an article is more difficult to manage than a static set of articles originally published in a journal issue.</p>
<p>Archives also need to decide on the form in which they will preserve journal content.  Will they preserve content as readers see it ("presentation" forms), or as their publishers prepare and structure it ("source" forms), or both?  Each has its advantages and disadvantages, but a comprehensive archival system should ideally preserve both.</p>
<p><hi rend="bold">Presentation forms.</hi> In the case of print journals, libraries save the journals in the form in which they are presented: bound, printed pages.  Electronic journal archives can also save such "presentation" forms.  For many electronic journals these presentation forms consist of PDF or HTML and image files that are delivered to readers when they access journals over the Web.  These files faithfully reproduce the appearance of journal articles and their text.  They are also in many cases automatically harvestable from publisher sites  --  unlike source files which may not come in as consistent formats as presentation forms  --  and are therefore relatively inexpensive to ingest.</p>
<p>However, presentation files usually lack the structural markup available in the publisher's source forms.  They also do not include any server-side scripts or other functionality that would be provided on the original publisher's Web site.  Hence, they might not support functions that readers of electronic journals increasingly expect, such as automatic bibliographic linking, cross-article text searching, and data analysis.  Migration to other formats may also be problematic, at least for anything beyond image capture and simple text streams, particularly if a nonstandard format is used.  However, we believe it is important for archives to include presentation forms of journals because they show what readers actually saw when they read the journals.</p>
<p><hi rend="bold">Source forms.</hi> Electronic journals typically also produce "source" files which are the edited documents on which the presentation forms are based.  For many electronic journals these are SGML files  --  or more recently XML files  --  following a structure known as a document type defintion (DTD) specified by the publisher.  The structure and markup of source files often provides information that cannot practically be extracted from presentation files, such as the structure of equations and formulas, bibliographic records, and tabular data.  If the source files use a well-documented DTD for this information, programs can easily analyze journal articles to support value-added services. On the other hand, archiving only the "source" forms means that viewers of archived journals might not see exactly what readers of the original journals saw. It may be difficult to verify whether the source materials can generate the same content and functionality of the original presentation forms, in part because source forms may not conform exactly to a standardized DTD, and also because publishers may make last-minute edits in presentation files that do not appear in the source files. There is currently no common standard used for various publisher DTDs, although many of them descend from a common ISO standard. A Harvard-sponsored study prepared by Inera recommends a common DTD that incorporates many of the elements of major publisher DTDs.<note target="Penn10">[10]</note>  If such a standard were widely adopted it would substantially reduce the costs and uncertainties of maintaining source files.</p>
<p><hi rend="bold">Auxiliary forms.</hi> One of the appeals of electronic journals is that they can include digital content such as multimedia, programs, or machine-readable data sets that augment the text and illustrations of a traditional scholarly article. These supplements should be preserved in journal archives as well. However, because they often appear in complex formats that may have limited long-term support, an archive may not be able to guarantee that the supplementary content will continue to be usable by future researchers indefinitely.  It may be useful, though, to support some basic supplementary data types, such as character and numeric data stored in relational tables.  For other formats, if the supplementary material can be packaged as a bit-stream, archives should at least be able to preserve this bit-stream.  They should also include some metadata concerning the format of the bit-stream so that new programs can interpret that format, if researchers are sufficiently motivated.  A journal archive itself need not record detailed information about the format specification, so long as it can refer to a reliably preserved copy of the format specification stored elsewhere.</p>
</div2>

<div2 type="subsection" n="06"><head>How should archives be organized?</head>
<p>Any archive that we construct will not stand on its own. Electronic journals will be archived at multiple sites, hence the DLF's requirement that journal archives operate in a network.  In a well-designed archival network, institutions can share the burden of archiving journals, and libraries and researchers needing to use archival materials can locate and retrieve appropriate copies from a participant in the network.  However an archival system is set up, though, it must be clear who takes responsibility for the material being archived and how this responsibility is enforced.</p>
<p><hi rend="bold">Self-archiving.</hi> Some authors and organizations may attempt to archive their own material.  A publisher may declare that it will archive its own back issues indefinitely, for instance.  Many authors have also provided preprints of their papers and journal articles on their Web sites for years. This informal practice is now encouraged by manifestos like the Budapest Open Access Initiative.<note target="Penn11">[11]</note>  "Self-archiving" can also be done by authors' institutions.  For instance, MIT's Dspace repository promises stable long-term storage for the scholarly work of its faculty.<note target="Penn12">[12]</note></p>
<p>Self-archiving, however, will not suffice to preserve scholarly journals, let alone scholarly communication as a whole.  It essentially relies on the self-interest of the original creators and publishers to keep the archive viable, but Web sites often disappear when an individual changes institutions or careers.  Copies of papers on individual sites are often preprints, so they may lack important revisions and supplementary information that appeared in the journal version. Publisher-run archives may disappear without warning if they are no longer cost-effective to the publisher, or if the journal or the publisher fails or is acquired by another company.  Contents of archives may be changed, corrupted, or withdrawn, either by accident or intentionally.  As holders of copyrights to the content they archive, publishers and authors have exclusive rights to disseminate this content unless they grant rights to archives run by disinterested third parties.  With exclusive rights comes near-exclusive responsibility for their material. Without very strong certification and backup strategies, self-archiving with this level of exclusivity is not likely to be widely trusted to preserve scholarly information for the time spans researchers and libraries have come to expect.  This does not mean that self-archiving is useless, however. Self-archiving can be a backup to trusted archives run by other parties.  Also, self-archiving, particularly the institutional self-archiving provided by systems like Dspace, may preserve information of scholarly interest that is not included in standard journal archives.</p>
<p><hi rend="bold">Integrated responsibility.</hi> Whether run by content creators and publishers or by third parties, archives have traditionally taken full responsibility for the content they archive.  They are responsible for quality control, continued preservation, and providing appropriate access.  If they themselves cannot maintain the content in perpetuity, they are responsible for finding someone else who can.  While they may delegate some of their functions, such as ingestion or migration, to outside service providers, they are ultimately responsible to their clients for making sure these functions are carried out correctly and that the content is preserved for future access. This "integrated" responsibility for preserving and providing access to content may earn the trust of users, since the buck stops, as it were, with a definite party.  Publishers, too, may be more willing to grant rights to a specific agent who takes responsibility for their work.  Of course, the archive must live up to this responsibility, with its attendant certification and sustainability requirements.  Penn, and most of the other Mellon-funded electronic journal archive planners, planned to build this sort of archive.</p>
<p><hi rend="bold">Distributed responsibility.</hi> The LOCKSS (Lots of Copies Keep Stuff Safe) project at Stanford suggests a more distributed form of responsibility, similar to the distributed responsibility for print journals discussed earlier.  With LOCKSS, no one institution takes responsibility for a journal.  Instead, many institutions maintain sites that cache copies of journal content published on Web sites.  Content can be accessed from the cache if (and only if) it is no longer available on the original publisher's Web site.  Cache contents are automatically checked against each other on a regular basis, and corrupted or lost copies of items replaced with other copies.  The cache correction protocol is slow and relies on records of past holdings.  These features make it highly unlikely, given enough participants, that a copy of an object will be completely lost, be corrupted, or become unavailable to any site that originally cached the content.  Because the protocol also checks what content a site has previously demonstrated that it owned, the protocol does not "leak" content to sites that were not authorized to see it.<note target="Penn13">[13]</note></p>
<p>LOCKSS is designed to run on low-cost machines with as little maintenance as possible, making it attractive for libraries to set up LOCKSS caches.  If enough libraries continue to cache the same content, that content (at least in its original format) can be preserved reliably even if no single institution takes final responsibility for it.  The system can be queried to see how many sites are caching content.  Institutions that see a need for greater reliability, can arrange to put additional copies on caches run at their own site or other sites.</p>
<p>In its original form, LOCKSS makes a number of simplifying assumptions about what is being cached, that may not be applicable to all journal archives.  For instance, LOCKSS obtains publishers' content by automatically polling their Web sites for HTML and image files, but while those sites may include presentation forms of journals they typically do not include source forms.  However, the basic LOCKSS model can be generalized to cover a broader range of journal archiving strategies, especially if caching sites can individually decide what to cache and how.  Useful generalizations of the model include:</p>

<list>
<item><hi rend="bold">Introducing an explicit representation of trusted sources for journal content.</hi>   The basic LOCKSS model assumes the publisher's Web site is the trusted source for journal content.  However, other trusted sources might be needed to provide content not available on the Web site such as source forms for journal content, metadata, and updates and migrated versions of journal content. Trusted sources could include publishers or well-known, responsible archives and service providers.</item>
<item><hi rend="bold">Caching Archival Information Packages (AIPs).</hi> If AIPs and not just Web pages and images are cached, then a distributed archive can reliably cache both source and presentation forms of content, as well as appropriate metadata and migrated forms.  These AIPs would need to come from a trusted source.</item>
<item><hi rend="bold">Identifiers for AIPs and other journal content</hi>.  A distributed archiving system requires a consistent way of identifying content so that different servers can check consistency between different copies of the same material. As originally designed, LOCKSS simply uses URLs as identifiers, but this only works for material pulled directly from the Web at static URLs.  A distributed archiving system could use AIP identifiers to identify content, but would have to settle on a suitable global scheme for assigning such identifiers.<note target="Penn14">[14]</note>   Other globally addressable entities, such as directories, will need globally unique identifiers as well. </item>
<item><hi rend="bold">Metadata.</hi> A distributed archiving system should agree on a common core set of metadata to maintain for journal content, including descriptive and technical metadata, to support searching and browsing and maintenance of particular journal content.</item>
<item><hi rend="bold">Directory services.</hi> Once the metadata above is in place it should be possible for archive users to be able to see what content is in the system, even if they cannot actually view all the content. They should also be able to search and browse it in customary ways, such as looking up an article by its citation, or browsing tables of contents for a particular journal volume.  Directory information needs to be updateable as more journal content is added.</item>
<item><hi rend="bold">Versioning.</hi> LOCKSS' cache consistency protocol works well for objects that do not change once they are imported into the system,<note target="Penn15">[15]</note> but a general-purpose distributed archiving system includes several types of changing objects.  AIPs for particular journal articles may change as new manifestations of the articles are added (such as through migration) or if publishers issue a corrected version of an article after its original publication.  Directories change as new articles, issues, and journals are added to the system. A versioning discipline would allow LOCKSS-like consistency checks for updates and new manifestations of these objects.  A new version could be identified as an update of an existing version of an object in the system, and distributed archive sites could decide whether or not to accept the version.  The sites could use acceptance criteria of their choosing, such as the trustworthiness of the source and the nature of the differences between the new version and the older version. Some types of updates may be expected to be monotonic: new data gets added, but old data does not get taken away.  Sites could also decide whether or not to retain older versions.<note target="Penn16">[16]</note>  Most legitimate updates to journals would not occur more frequently than issues of journals are published, a pace which is compatible with the deliberately slow coherency protocol that LOCKSS uses. </item>
<item><hi rend="bold">Controlled expansion of access.</hi>   LOCKSS' access control model is also monotonic: if a site has had a copy of some content in the past, it can be given a copy again, if its old copy has been lost or corrupted.  Trusted sources could also grant new copies to sites that previously did not have copies of particular content, when this is permitted, without any further changes in the access control model.  It would also be useful to be able to designate that certain content could be given to a wider set of sites.  The simplest approach would be to include an "open access" flag that could be given to journal content or metadata that can be distributed freely.   Trusted sources could set this flag, either on original distribution, or when previously arranged "triggers" applied that opened access to content.</item>
</list>

<p>In making these extensions, one must avoid introducing so much overhead into the system that the primary advantages of LOCKSS  --  reliable distributed archiving with minimal cost and maintenance  --  are lost.  Each of the enhancements mentioned above should not be overly burdensome in itself, but designers of a distributed archiving system should make sure the enhancements are kept as simple as possible.</p>
<p><hi rend="bold">Service providers.</hi> Service providers perform specific functions on behalf of the archival system.  In an "integrated responsibility" model, service providers are essentially subcontractors for the main archive.  In the "distributed responsibility" model, service providers are trusted sources, as defined above.  Service providers help scale up an archival system by spreading out responsibility for archival tasks.  They can be useful when an archival function requires specialized expertise or resources.  For instance, if a company provides low-cost, highly replicated reliable data storage, an archive might out-source backups to that company rather than maintain backups itself.  Or, if content is submitted or stored in a variety of protocols and formats, ingestion and migration of this content might be usefully parceled out to service providers, each specializing in a particular format or data provider, instead of trying to have one organization handle everything.</p>
<p>Service providers often do not need to make the same sort of long-term commitments as archives themselves do, unless their service includes long term information storage. However, they still need to be visible in the design and operations of an archiving system.  Archive users may want to make sure they are certified for carrying out their service correctly. Publisher agreements may need to allow them to access copyrighted material, and publishers may want to be assured that they do not distribute or alter this material without authorization.  The business model for the archive or archival system also needs to include some sort of compensation for the services of the providers.</p>
<p><hi rend="bold">Registries.</hi> Several organizations, including JSTOR, Highwire, PubMedCentral, and various publishers and national libraries, are currently archiving journal material.  We expect that other archival initiatives will also arise as a result of the Mellon-funded planning process.  As the population of archives and archived materials grows, it will be increasingly important for archive maintainers and users to be able to keep track of who is doing what and with what content.  A registry of journal archiving activity would make this possible.  It would allow users to find content they needed, and allow archive maintainers to find service providers, look up technical information on archiving formats and practices, and track redundant archiving of journal content.</p>
<p>Several architectures are possible for such a registry.  A centralized knowledge base could be set up to accept information about archival activities.  The Jointly Administered Knowledge Environment (Jake) is already set up to record journal information in this manner, though it does not currently record archiving information for journals.<note target="Penn17">[17]</note>  Peer-to-peer systems can also act as decentralized "registries."  The Typed Object Model, for instance, propagates information about data formats and their conversions between peer "type brokers."<note target="Penn18">[18]</note></p>
<p>The Open Archives Initiative (OAI) suggests a particularly promising architecture for a registry.<note target="Penn19">[19]</note>  Using OAI, repositories can expose metadata about their contents which can then be harvested incrementally by any interested service.  The OAI protocol is lightweight and easy to implement and add on to existing systems. We have implemented it from scratch for selected digital collections here at Penn, using existing catalogs and databases combined with about 500 lines of OAI-specific Perl code.  Journal archives could be designed to expose metadata about their contents, and their archiving strategies and policies.  Then, one or more archival information sites could harvest information from appropriately certified archives, and allow archive users and maintainers to search and browse the aggregated metadata.  Setting up such a system would require some agreements on "core" metadata that the archives would export, but it would be in the interest of most archives to agree on such metadata.  The aggregated information site (what would appear to most users as the master registry) would not need to be particularly expensive to maintain.  It would be automatically updated from the certified archives, and the software to browse and search its records would only need to handle the common "core" metadata format.</p>
<p>A journal archive registry should include at least the following information:</p>

<list>
<item>Information on journals being archived including
<list>
<item>their names and identifiers</item>
<item>the archives or archival systems preserving them, the scope of the issues and articles preserved by these archives, and the formats being archived</item>
<item>who is authorized to access the content</item>
</list></item>
<item>Information on the archives and service providers themselves, e.g.,
<list>
<item>For "integrated responsibility" archives, information on their certification including how they are certified, when they were last certified, and relevant reports from the certifiers</item>
<item>For "distributed responsibility" archival systems, information on how to find out the archival status of journal content, including how to locate and check the reliability and redundancy of the storage of particular journal content</item>
</list></item>
</list>
</div2>

<div2 type="subsection" n="07"><head>Archival rights and responsibilities</head>
<p>An electronic journal archive has responsibilities to scholars and their institutions and to publishers.  The archive is responsible for ensuring scholars can access journal content for as long as it is of scholarly value in a form that allows it to be used effectively for research, teaching, and learning.  The archive is responsible for respecting the copyrights of authors and publishers in its stewardship of electronic journal content.  It is also responsible for helping maintain a healthy climate of scholarship and scholarly communication.  It should neither hinder publishers or libraries with overly burdensome procedural and economic constraints, nor hinder scholars themselves with overly restrictive policies for access or deposit.  Archives need to be granted sufficient rights to carry out these responsibilities.</p>
<p>In this section, we summarize the specific rights and responsibilities we believe archives need to have.  The content of this section is based in part on our discussions with our publishing partners.  Note, however, that these publishers have not made any binding agreement to these recommendations.  Since we do not currently plan to archive their journals ourselves, binding agreements would ultimately need to be made with the archive or consortium that does archive the journals.  We at Penn can, however, work with both the archives and publishers to negotiate an appropriate agreement.</p>
<p><hi rend="bold">Responsibilities for selection.</hi> The archive is responsible for identifying journals it wishes to archive and making these selections known to a publisher for the publisher's approval.  The selection does not have to be enumerated.  For instance, archives that plan to include all electronic journals of particular publishers, as we originally planned, could agree that any newly added journal will be included in the selection unless either the publisher or the archive notifies the other that the new journal should be excluded.  In such cases, the publisher should also inform the archive about newly added electronic journals or of journals that it no longer publishes. Of course, this notification, and other provisions of information given in this section, can be made simply by publishing the information in an agreed-upon location, such as a Web page or a mailing list.</p>
<p>The archive and publisher also need to agree on what content in the journals is being selected.  Normally, the archive should collect at least all issues published from the time the agreement is made.  Back issues, where feasible, are also desirable to include.  As mentioned earlier, we expect that a scholarly journal archive should include at minimum all editorial content of the journal, including text and images, in some format.  In our proposals to publishers, we specified that we would not guarantee preservation of "advertising matter, ephemeral and informal indexes (such as a page with links to current and past journal articles), search engines or other server programs, or auxiliary material not clearly part of the journal itself." Dale Flecker of Harvard has also recommended that information about the editing of the journal, such as the editorial board membership, the masthead, and author's submission guidelines, also be collected on a regular basis and preserved because of its potential interest to scholars analyzing the journal.</p>
<p>The archive and the publisher also have to agree on a set of formats that will be collected, and protocols for collecting content and metadata.  Either the archive or the publisher should be able to request, with sufficient advance notice, that archiving for a journal be cut off: that is, no further issues will be deposited into the archive.  The archive is responsible for notifying its clients, including appropriate registries, of its selections.</p>
<p><hi rend="bold">Responsibilities for ingestion.</hi> The publisher is responsible for providing content and metadata for the journal issues being archived.  Content should include the journal content as provided to subscribers in presentation forms such as PDF and HTML.  Even if an archive does not store presentation forms, as we recommend, it is helpful for an archive to be able to compare any source forms it receives against what the publisher actually supplied to subscribers in the electronic journal.  This provision may simply consist of allowing the archive access to the online journal for testing.</p>
<p>When the archive is preserving source forms of content, the publisher is responsible for providing them and for ensuring they are correctly formatted; the publisher is also responsible for ensuring the source forms correspond appropriately to the published presentation forms.  The publisher should likewise be responsible for providing metadata for the journal content in sufficient detail to allow standard scholarly citations to be built for all articles and other citable contributions.  This includes title, authors, issue information, page numbers or other section delimiters where applicable, and other standard identifiers for the content such as ISSNs and DOIs.  Abstracts and keywords would also be useful, when available.</p>
<p>The archive is responsible for collecting content and metadata in a timely fashion, checking it for consistency and proper formatting, and either ingesting it into its repository or informing the publisher of any errors or problems with the data. If the archive reports errors the publisher should remedy them, and the archive should then reingest content.  Generally, the archive should try to ingest an issue while it is still the current issue.  If the archive is harvesting data from the Web or another published source, it should be able to assume the data is in its final form unless the publisher has notified it otherwise. For example, if the publisher posts "draft" or pre-publication material which it then modifies before an issue's "official" publication, the publisher is responsible for telling the archive when and when not to harvest this information.</p>
<p>The archive is responsible for collecting appendices to articles such as datasets, audiovisual clips, program code, and other multimedia when this is within the archive's stated selection criteria.  The publisher may need to assist the archive in collecting these appendices.  If the appendices have unusual size or format, they might not be required to be migrated as is regular content. "Appendices" external to the journal itself  --  a Web site referred to by a URL in a journal article, for example  --  need not be collected.</p>
<p>If content is to be collected by harvesting from the publisher's site, the publisher is responsible for allowing access by the archive's harvesters, while the archive is responsible for ensuring the harvesters do not unduly load the archive's servers.</p>
<p><hi rend="bold">Rights and responsibilities for storage and maintenance.</hi> The archive is responsible for ensuring the long-term persistence and stability of the archived content. It is also responsible for making sure the content does not become unusable due to technological obsolescence.  Therefore, the publisher should give the archive the right to store copies of the journal content and metadata, make and store backup copies, and create derivative works based on the original data for the purpose of maintaining their suitability for research and scholarship.  Such derivative works could include migrations to new formats, indexing for searching and browsing, and transformations required for emulation.  Ideally, the right to create derivative works would also allow enhancements to the content, at least when the enhancements are for services that researchers come to expect in online journals.  Such enhancements, for instance, could include converting static images to wavelet-based forms that allow panning and zooming, or inserting hyperlinks to make it possible for readers to go to referenced articles.</p>
<p>Users expect that reliable, persistent electronic archives will not lose content.   Therefore, the rights above and other intellectual property rights given to the archive should be irrevocable by the publisher, provided that the archive fulfills its responsibilities.  Publishers can retain copyright; they just need to assign appropriate rights for the archive to do its job.</p>
<p><hi rend="bold">Rights and responsibilities for access and distribution.</hi> The archive is responsible to its clients for providing authorized users with its content and metadata, and it is responsible to publishers for providing content only to authorized users.  Content provided to authorized users should include</p>

<list>
<item>Copies of the journal content as originally published (byte-for-byte copy, in original formats) for journals archived in presentation form.</item>
<item>Images of the journal pages in formats commonly readable at the time of access for journals archived in presentation form. This may require migration if common data formats change. </item>
<item>The text of the journal content in formats commonly readable at the time of access.  This may also require migration. </item>
<item>Where feasible and cost-effective, other journal content, such as data sets and audiovisual materials, in formats commonly readable at the time of access.</item>
</list>

<p>Metadata should include at least citation information for the journals and their articles.  The archive should also provide reasonable facilities for locating an article or journal with a known citation.</p>
<p>The difficult issue for negotiations in this area concerns who should be "authorized users" for content and metadata and under what circumstances.  Indeed, this was a sticky point not fully resolved in our own publisher negotiations.</p>
<p>It seems relatively uncontroversial to allow general access at least to citation-level descriptive metadata.  This allows users to know what is in an archive.  Richer descriptions, such as abstracts, may be more controversial, but if they encourage a user to seek out the full content and become more interested in the journal as a whole, providing such detailed metadata can benefit both archive and publisher.</p>
<p>Likewise, allowing access to content by the publisher and by the archive maintainers seems uncontroversial.  Widening access further, though, proved more problematic.  Even providing access to subscribers to the journal for content that was also available on the publisher's Web site raised concerns that the archive would compete with the publisher's own offerings.  The concerns here seemed to be not just possible loss of marketing opportunities on the publisher's own Web site, but also possible degradation of image.  The look, the services, and the authority that the publisher took pains to establish on their Web site could be lost on the archive site, thus weakening the "brand" or reputation of the publisher.  This seemed to be less of a concern if the archive just offered material that was no longer available on the publisher's own Web site. Concerns about image may also be alleviated if appropriate links (and distinctions) are made between the archive site and the publisher's site.</p>
<p>Even more controversial is allowing access to archived journal content to those who are not subscribers to the journal.  JSTOR and Highwire, two established projects that archive journal content, allow such access after a certain time has passed from publication. The point at which access is opened is referred to as the "moving wall."  There are several advantages to this sort of access:</p>

<list>
<item>It satisfies, at least in part, the desire of many scholars that scholarly information should be generally accessible to all for little or no cost, whenever feasible.</item>
<item>It provides an electronic counterpart to the long-standing custom of researchers obtaining older journal articles by interlibrary loan if their institution did not subscribe to the journal or retain their volumes.</item>
<item>It avoids the overhead of the archive having to keep track of exactly what users should be allowed to access each item in the archive.</item>
<item>It allows a wide audience of readers and third-party automated programs to examine the archived content and verify that it is being accurately preserved or report problems if it is not, thus enhancing trust in the archive.  This may be especially important when material needs to be migrated to a new format, a process that may risk losing information or usability in unexpected ways.</item>
<item>It may make it easier for mirror sites and other service providers to access the content.</item>
<item>It provides an ongoing service of document delivery to the scholarly community, instead of just being an unseen "insurance" policy as an inaccessible or "dark" archive would be.  This strengthens support for the archive in that community.</item>
</list>

<p>These are all benefits for the archive and its users, but they are not direct benefits to publishers. Of greatest concern was the possibility that libraries would cancel subscriptions to their journals or not sign up for them in the first place if they could have access to the archive without a journal subscription.  Martin Richardson of Oxford University Press, for instance, reported that institutional subscriptions to eleven journals made available via Highwire had declined by three percent per year in the three years since they had been placed online, even though they had been increasing prior to that time.  (The moving wall for free access to these journals ranged from twelve to twenty-four months after publication.)  Faced with such declines in subscriptions, publishers might have to raise prices for the subscribers that are left, or cut the budgets to produce the journals. As an alternative to general free access Richardson recommended free access to readers in developing countries and low article pricing for infrequent users of journals.<note target="Penn20">[20]</note></p>
<p>Richardson's report does not prove that opening access caused the drop in subscriptions or that a more distant moving wall, such as the three to five years that is common for JSTOR journals, would not solve the problem.  Both Oxford and Cambridge have been willing to experiment with allowing some of their journal content to be accessible to nonsubscribers through JSTOR and Highwire as well as PubMedCentral.  We recommend that electronic journal archives conduct further experiments to determine the relationship between events that would "trigger" nonsubscriber access rights versus paid subscriptions, since the potential benefits of general access to the archive and its users are substantial.  Some may argue that copyright law already specifies a moving wall when works enter the public domain and are available to anyone.  However, this moving wall has been extended repeatedly in the United States and is now up to ninety-five years after publication for older publications and works for hire, and to seventy years after the death of the last surviving author for other works.  The distance and uncertainty of copyright expiration in these circumstances makes an archive that requires public domain verification before providing access to electronic journal content equivalent to a "dark" archive for most practical purposes.</p>
<p>Other "trigger" events besides a fixed moving wall are also worth considering. For example, opening up access when migration is required would ease user concerns that migration might not be successful.  It might also benefit publishers if they found migration too expensive or troublesome to carry out themselves.  It is also reasonable for archives to be able to provide general access to content that is no longer being offered online by the publisher or the publisher's agents.</p>
<p>The archiving agreement should not abridge the traditional rights recognized by copyright law.  These rights include fair use, first-sale rights, and unrestricted use of public domain material.  All of these rights play important roles in scholarship, so archives whose purpose is to support scholarship should avoid restricting them.  Some publishers digitizing older material may want to make an exception to this rule for new digitizations of public domain content from early in a journal's run.  An archive should weigh this proposed exception carefully. In some cases, a short-term embargo on unrestricted use of this material may be necessary if the only likely digitizer of the content is worried about the investment going to waste, but there is little justification for extending this embargo beyond the same moving wall term (with the term in this case starting at the time of digitization) that is given to copyrighted content. On the whole, the copyrighted content of most electronic journal archives will usually be much more valuable than recently-digitized public domain content.  Users are also much more likely to trust and support a comprehensive and authorized archive of a journal's run than an unauthorized provider of part of the journal's run.</p>
<p><hi rend="bold">Rights and responsibilities for certification and evaluation.</hi> The archive is responsible for specifying a process for certification of its content and procedures, and for reporting the results of this certification to its clients, including its publisher partners.  The RLG-OCLC Trusted Repositories paper notes two basic approaches to certification: an approach based on auditing and an approach based on standards and usage. For a "dark" archive, or an archival system that uses software that is not available for public inspection, certification will generally need to involve auditing, to satisfy the concerns of constituents who cannot examine the content or the software themselves. In a more open system, such as LOCKSS, each site can examine its own contents and the software it is using.  In such cases, separate auditing is less important though it may be desirable for the designers of the system to have the code reviewed and certified by an outside party.</p>
<p>Publishers may want to know how the content they publish is being used in an archive as well as the cost of the archiving processes.  It is reasonable for an archive to share aggregated usage information with publishers as long as the form of the information sharing protects the privacy of individual readers. If publishers are subsidizing the archiving they also have a right to be informed of the costs involved.  Archives and publishers should agree in advance on the data an archive will collect, what an archive can be expected to provide, and for how long an archive should retain usage data.</p>
<p><hi rend="bold">Responsibilities for sustainability.</hi> The archive is responsible for ensuring it has appropriate technology, procedures, and funding for it to continue archiving activities for as long as needed. We will discuss technology and procedures in the next section.  Responsibility for funding, however, is related to the other rights and responsibilities of an archive.</p>
<p>Funding for an archive can come from various sources including:</p>

<list>
<item>The organization running the archive (self-funding)</item>
<item>External sponsors (e.g., private foundations, government grants, marketers)</item>
<item>The publishers of the journals in the archive</item>
<item>Users of the archive materials (e.g., individual researchers and libraries)</item>
</list>

<p>Self-funding is viable for most academic libraries if the archival system is sufficiently lightweight and inexpensive to run and provides commensurate benefits.  We can run a LOCKSS server on a commodity PC, for example, and in its current form it requires very little maintenance.  Even a more ambitious system, such as the distributed archiving system described earlier, could easily pay for itself if its cost were similar to the original LOCKSS system and it made it easier for us to move older journals to inexpensive remote storage.</p>
<p>Full-service "integrated responsibility" archives are much more heavyweight.  According to discussions with its maintainers, PubMedCentral, run by the National Center for Biotechnology Information (NCBI) of the National Institutes of Health (NIH), requires seven full-time employees to run on an ongoing basis.  The project archives fewer than thirty externally published journals, plus a few dozen very low volume journals published by NCBI, and makes extensive use of automation.  PubMedCentral staff represent only a small fraction of the staff of the NCBI, itself a small division of NIH.  Organizations like this, which have national mandates as collectors and providers of research information, should find it a relatively small stretch to maintain an archive of online scholarly journals in-house and to justify it in their budgets.</p>
<p>On the other hand, most university libraries, including Penn's, would consume significant portions of their current budgets and staff to run an electronic journal archive. Penn currently has fewer than seven FTE equivalents designing and maintaining its digital library systems.  If Penn were to archive all of the hundreds of journals published by Oxford and Cambridge its costs are likely to be considerably higher than for PubMedCentral's archiving of a few dozen journals. The Penn Library's mandate is not primarily archiving for an external community. Hence, internal funding for an archive that mostly deals with external publishers and users and that has significant costs without clear bounds is not a viable long-term funding model. External grants, while they can be tremendously helpful for research and development and for startup costs, are much harder to obtain for ongoing operations which will continue to be expensive. Advertising support, as seen in the recent dot-com boom-and-bust cycle, is also highly unstable, and in a university environment can create problematic entanglements with commercialization.  Neither external grants nor advertising or marketing support, then, will provide the reliable ongoing funding that an archive needs.</p>
<p>Many publishers can fund an archive if the archive provides them sufficient benefit.  The costs of funding will ultimately be passed on to someone else.  For subscription-based journals, the price of subscriptions may account for the cost of funding the archive.  Journals that charge authors for publication might build charges for preservation of the article into the author's fee.  Journals published by scholarly societies may have those societies fund their preservation.</p>
<p>Costs for preserving journal material are ongoing but publishers may be unwilling or unable to pay for archiving the material indefinitely.  One solution to this problem is to structure publisher funding as an endowment.  When a publisher deposits a journal volume or issue in an archive, it would also include a one-time payment to endow the future archive needs of the deposited content.  Income from this endowment would fund ongoing archiving, backup, mirroring, maintenance, and migration of that journal content in perpetuity. If the archive decided to transfer responsibility for the content to another institution or back to the publisher, the content's endowment would be transferred as well.  If a publisher stopped supporting an archive, the endowments associated with previously deposited content could still fund the preservation of that content.</p>
<p>For the publisher and journal subscribers, the endowment would provide a guaranteed source of funds to ensure the ongoing availability of journal content.  Funding would not be dependent on an archive's ongoing revenue stream.  By guaranteeing long-term availability of journal content, an endowment-funded archive could ultimately save money both for the publisher and subscribers to the journal.  Subscribers who can rely on preserved electronic copies may be willing to forgo print versions or keep them in less expensive storage, thereby lowering their costs.  Hence, they may be willing to contribute to an endowment fund via their subscription fees.  If the archive is sufficiently trustworthy and accessible, it may even be possible to discontinue print production which would lower costs and subscription fees for the publisher.</p>
<p>For the endowment model to work, however, costs have to be well-understood and kept under control.  If the costs can be kept down to a small percentage of subscription revenue, the endowment model may be financially viable.  For instance, a journal that costs $350 per volume, with 300 annual subscribers, brings in about $100,000 of subscription revenue.  If endowment income were five percent per year, then each one percent surcharge for archiving would pay $50 per year of archiving costs for that volume.  So if the true costs to the archive were $150 per year per volume, three percent of subscription revenues would need to go towards archiving.</p>
<p>Unfortunately, this may be an optimistic estimate of archiving costs, which are still uncertain and likely to change as archives develop and as technology changes.  Long-term costs may be difficult to measure in the early stages of an archiving project, especially since it may be unclear what costs are startup costs and what costs are ongoing or recurrent, given the fluid nature of technology and archiving standards. Automation of as many tasks as possible may help, as long as the cost of computers continues to decrease while the cost of labor increases.  The endowment model also works best when an archive's fixed costs of operation are low compared to costs that vary with the size of the archive, favoring larger archives.  For similar reasons, high endowment requirements may also favor larger publishers which might be an undesirable side-effect for libraries already worried about over-consolidation of scholarly journal publishing in for-profit conglomerates.  If scholarly archives are ultimately designed to meet the needs of scholars and scholarly institutions, a funding model that relies on publishers may produce a less useful archive than one that is funded more directly by scholars and their libraries.</p>
<p>Funding by users appears to be a viable alternative to endowments by publishers.  JSTOR has found success through funding from libraries and other journal users.  Libraries pay a one-time capital development fee and an annual subscription fee to access JSTOR content.  Publishers are not charged for deposits into the archive.  JSTOR has proven highly popular with libraries and their patrons.  At Penn, where it is one of 1,300 subscription sites, JSTOR's usage is in the top ten percent of the 300 databases we provide access to, with up to 1,000 logins per month during peak times of the academic year. Our scholars value JSTOR not just because it preserves journals from possible loss but because it provides them for everyday access, including access to materials not available in print form at our libraries since JSTOR subscribers can retrieve articles past the moving wall for any journal in the archive, regardless of whether they originally subscribed to the journal or not.  In effect, JSTOR's convenient access is the carrot that encourages libraries to pay for subscriptions that cover both access services and archiving.  JSTOR's success with libraries, scholars, and publishers makes a powerful case for this type of funding model.</p>
<p>Of course, it is possible for journal archives to have multiple funding sources, but complicated funding models may produce more problems than they solve.  In an early proposal to our publishing partners, we proposed that publishers would pay for the core archival functions via an endowment and users would pay for user-friendly access services via a subscription.  However, this model, even though it theoretically divided responsibilities between two types of functions, proved too difficult for people to keep straight, even within our own library, without repeated reiteration.  Even when explained, its two-stream funding model made it too easy to argue about which stream should be responsible for which costs.  We were also warned by the developers of some content sites that "enhanced" access services could have unexpectedly large costs to develop and maintain.</p>
<p>It seems more promising to have one main stream of ongoing funding for an archive, perhaps with additional assessments of funds for particular, well-defined functions.  Such assessments may actually improve the operation of the archive.  For example, ingestion is likely to be expensive for many electronic journals, given the diversity of their delivery formats and the need to verify submissions before archiving them.  An archive faced with high ingestion costs could depend on users to fund its general operations and development, as JSTOR does, but charge publishers for ingesting their content unless their content came in a prepackaged, easily-validated form prescribed by the archive.  In effect, the archive would offer to sell publishers a packaging service for their content.  The publisher could pay for the archive to package their content, or pay some other service provider to do it, or do it on its own and avoid having to pay. In any case, the archive's own costs for ingestion would be reduced and publishers would have an incentive to provide their content in accordance with archival standards.  Both of these developments would make the archive more reliable and sustainable.</p>
<p>Funding and control of access rights represent a tradeoff. Publishers can provide funds or they can provide access rights to users after a suitable delay.  They are reluctant to provide both.  Libraries and scholars, on the other hand, may be disinclined to fund an archive that does not give them access except in some far-distant or unforeseeable circumstances.  Thus, archives funded primarily by publishers may tend to be "dark," whereas archives funded primarily by libraries and archives should be more open to access by their funders.  We at the Penn library prefer the latter for an archive that we run or help support.</p>
<p><hi rend="bold">Responsibilities and rights for transfer and delegation.  </hi> Archives must be ready for unforeseen changes in the scholarly or online community that may render the archive unsustainable or make it far preferable to archive content elsewhere.  Therefore, agreements with the publisher should allow the transfer, if necessary, of the archival material and its associated rights to another party that agrees to assume the archive's responsibilities. The publisher, if it is still in existence, may want to stipulate some additional qualities of the new party, for instance, that it not be a commercial competitor.</p>
<p>Similarly, the agreement should allow third parties to act as service providers for delegated archival functions as long as the third parties do not distribute archival material or use it for any purpose other than to carry out legitimate archival functions on the archive's behalf.  For example, integrated archives may need to have a third-party off-site mirror of the archive's contents in case of a disaster at the main archival site.</p>
</div2>

<div2 type="subsection" n="08"><head>The archival life cycle</head>
<p>In this section we discuss our experiences and findings in respect to the archival process.  The OAIS model, as mentioned earlier, breaks down the archiving process into distinct functional modules which manage archival information packages throughout their life cycles.  The key modules defined by OAIS and some of their functions are:</p>

<list>
<item><hi rend="bold">Ingest.</hi>  This includes the archive's acquisition of journal content and metadata, validation of the content, and packaging for archival storage as Archive Information Packages (AIPs).</item>
<item><hi rend="bold">Archival storage.</hi>  This includes maintaining AIP data and ensuring the continued survival and integrity of binary representations of archival data.</item>
<item><hi rend="bold">Data management.</hi>  This includes, among other things, maintaining metadata on archived content, managing storage, and handling queries on stored data.</item>
<item><hi rend="bold">Administration.</hi>  Among other things, this includes migration.</item>
<item><hi rend="bold">Preservation planning.</hi>  This includes planning and implementing further development of the archival system, including migration planning.</item>
<item><hi rend="bold">Access.</hi>  This includes delivery of content both to end users and to other archives under appropriate access controls.</item>
</list>

<p>While we had originally hoped to construct a full prototype archive for testing, this proved to be impractical for us, particularly if it had implemented the entire OAIS framework. Instead, our implementation planning and coding concentrated on a few of the archival functions we saw as needing special attention.</p>
<p><hi rend="bold">Ingestion.</hi> One of our focuses in planning was ingestion of presentation content and metadata from Web sites. We wrote routines to harvest information from publisher Web sites.  Two programmers coded the implementation and an Oracle database server was used for data collection.  The purpose was to construct a modular prototype harvester that could collect metadata and links to content from different publisher Web sites, then deposit the metadata and links into a common data structure that could be browsed and accessed uniformly.</p>
<p>Web sites for most Oxford and Cambridge electronic journals followed one of a few particular templates, so a few harvesting modules and templates could retrieve metadata for a large number of titles.<note target="Penn21">[21]</note> The modules successfully retrieved citation-level metadata as well as links to the article content, which in the journals we looked at tended to be PDF, HTML, or both. Article and issue metadata, including pointers to content, was then entered into a relational database using Structured Query Language (SQL).  Another module repackaged metadata for particular journals in XML forms and assigned persistent identifiers to the content. A Web interface was built that used the XML to allow hierarchical browsing of journal content online.</p>
<p>Size of the content varied greatly among journals.  For example, PDFs for <hi rend="italics">American Law and Economics Review</hi>, a semi-annual journal, took up little more than 2 MB of storage space per year, whereas PDFs for <hi rend="italics">Brain</hi>, a monthly medical journal, took up closer to 100 MB of storage space per year.</p>
<p>Articles in PDF form were generally easy to harvest, usually as one PDF file per article, although in some instances the PDFs were page-oriented instead and included content from multiple or adjacent items in the same file.</p>
<p>Correctly harvesting HTML presentation forms was considerably more problematic.  Many of the HTML-formatted articles were clearly generated from source files and included numerous automatically generated links, some of which led to content that was important to the article, such as high-resolution versions of illustrations, while others led to related material that was not part of the article itself.  Many of these HTML articles were produced by the same organization, Highwire Press.  We did not attempt to harvest the HTML articles in this case although careful coordination with the online publisher probably could have facilitated reliable extraction of the actual article content.  Since Highwire generates these HTML displays from archived source files, it would probably have been easier to archive the source files.  It might, however, still be useful to harvest the top-level HTML page of an article and temporarily store it for error checking.</p>
<p>Ingesting material into an archive, whether manually or automatically, is far from foolproof.  When publishers manually send a journal issue to an archive they may accidentally leave out articles, send misformatted files, or even send the wrong files altogether.  Similarly, our harvesters were vulnerable to small changes in the HTML generated by the Web sites and could misparse or miss metadata when changes were encountered.</p>
<p>Occasionally, articles published on Web sites included mistakes. An early spot-check of one mathematics journal article revealed a PDF file in which the last pages could not be read as the file was initially posted.  Human checks may turn up some of these errors but can be expensive to perform.</p>
<p>We found that the harvesting process afforded several opportunities to collect "redundant" data which could help flag errors in ingestion.  In many cases, "table of contents" information for journals is sent out to interested subscribers by email. We are already collecting such email notifications and hope to eventually parse their contents for a "virtual subscription" service we plan to provide to e-journal readers at Penn.  The parsed versions of these email messages can be compared against the metadata harvested from the journal Web pages and any significant differences flagged for human investigation.  Similarly, our harvesting modules can be used to selectively harvest back-issue content as well as newly published content.  At some specified time after the PDF for an article was first harvested the system could attempt to harvest the same article again.  Differences could indicate that the content has changed or that one of the harvest attempts did not complete successfully.  Either way, the anomaly could be flagged for an archive maintainer to check.  We have not yet determined how useful these redundant checks would prove in practice, but suspect that given reasonably consistent publishing formats and well-tested software they could help reduce error rates substantially for low costs relative to volume.</p>
<p><hi rend="bold">Migration.</hi> Left alone, archived content and metadata are not likely to stay usable forever.  Preserving the integrity of the original digital forms of archived electronic journals is not difficult with proper planning and the right to make copies as needed for archiving.  The strategies of generating checksums, making backups and offsite mirrors, regularly refreshing media, and conducting regularly scheduled consistency checks and disaster drills are well-known in digital preservation and data security circles.  However, more uncertainty exists about whether the digital forms can continue to be understood and used effectively as technologies and expectations change.</p>
<p>Data structures and formats based on simple, openly-specified, and widely-used standards are the easiest to preserve, and journal archives should encourage their use.  The definition of XML, for instance, is straightforward and widely publicized. Even if XML is eventually replaced by some other standard for structured data, it would not be difficult to migrate XML files to the new standard or to maintain programs that continue to parse XML in its original form.</p>
<p>To understand and use archival files formatted in XML or SGML, though, it is not sufficient to be able to parse the markup; it is also necessary to know what the markup represents.  In addition, we need to preserve the DTDs or schemas used, as well as the documentation for defining DTDs, schemas, or whatever syntactic convention next comes along to describe markup formats. And, above the level of DTDs or schemas, we need to document and preserve the semantics of the schemas: the meaning of the markup elements and how their composition turns a set of angle-bracketed words and sentences into a journal that speaks from mind to mind.  The semantics may be expressed in English-language descriptions, stylesheets, a program that renders markup as a visual display like that of a Web browser, or all of these.  Particularly since some of the syntax and semantics may be specific to the world of electronic journal publishing and archiving, the archival system will need to include a preservation mechanism for both the syntax and semantics of its data.</p>
<p>Preserving format information is not a new idea.  The Multipurpose Internet Mail Extensions (MIME) registry maintained by the Internet Assigned Numbers Authority (IANA) preserves descriptions of data formats commonly used on the Internet, as well as standard methods for encoding, packaging, and transmitting them.  The Typed Object Model (TOM), now maintained at Penn, adds semantic capabilities to a distributed format registry mechanism, supporting automated services like migration (with configurable degrees of fidelity),<note target="Penn22">[22]</note> format identification, and interpretation of data formats by remote servers. An ideal registry for journal archiving data structures would allow the combination of the prose descriptions and canonical authority of IANA's MIME registry, the computational power of TOM, and the expertise of digital librarians, archivists, and publishers.  In conversations with other digital library projects, we have found that such a registry would be useful to several types of digital library applications.  We are now investigating the design and support of such a registry which could be the basis for a data format management service provider in an electronic journal archiving architecture.</p>
<p>Preserving presentation forms presents some special problems: they are often complicated, defined by vendors (in practice, if not in theory), and dependent on external information in unexpected ways.  Fortunately, the presentation forms of most electronic journals are designed to be viewable by ordinary Web browsers without esoteric plugins.  The capabilities of Web browsers are well-documented, for the most part, so it should be possible to deal with the formats they handle.</p>
<p>Articles in the journals we examined were presented in HTML or PDF. HTML is a well-known standard, and variations from the standard in practice are effectively defined by the behavior of the two major browsers, Netscape and Internet Explorer (the latter having a near-overwhelming share of browsers at this writing). These variations are also well-documented.  Images inlined in HTML articles represented image formats  --  such as GIF, JPEG, PNG, and TIFF  --  that are also well-documented and that are each supported by a variety of tools.  The most difficult challenges in preserving HTML involve embedded scripting, which has been handled noticeably differently in different browsers and browser versions, and hyperlinks to other content. The data at the end of these links may or may not be journal content that needs to be preserved, and in some instances may be dynamically generated by a server that is not likely to persist for nearly as long as the electronic journal itself.</p>
<p>Adobe's PDF, though defined by a particular proprietor and more complicated than HTML, is also practical to migrate in many cases, as long as Adobe continues to publish its specification and provide tools for viewing and manipulating the format.  We have published an <hi rend="italics">RLG DigiNews</hi> article giving recommendations for preserving PDF, including migrations that preserve the image and the main text of PDF files.<note target="Penn23">[23]</note>  Again, scripting and external links pose potential problems.  An important external linking problem in PDF concerns fonts, which may not be embedded in a PDF document but only referenced.  As long as the fonts are for standard ASCII, ISO, or Unicode character encodings, external fonts pose little problem; programs that render or migrate PDF files can substitute standard fonts if necessary, and the PDF will still have sufficient information for correctly sizing and spacing the text.  Occasionally, though, special fonts may be used to encode nonstandard characters, such as one might find in complex mathematical equations or chemical formulas.  These may be unintelligible unless the specific font is preserved. The variety of characters available in Unicode should make the use of idiosyncratic fonts unnecessary in most cases but not all publishers have fully transitioned to Unicode. If nonstandard character sets prove to create significant problems, it may be desirable to also preserve a registry of unusual fonts or to embed the fonts into the PDF file at ingestion time. Both strategies have the potential for conflicts with copyright law, although the law allows some of these conflicts to be avoided as long as the fonts are only copied or embedded for nonprofit archiving.</p>
<p>We recommend attempting to migrate presentation files to other presentation formats, such as page images and plain text, as soon as possible, even if the migrations are not immediately needed. Archives will then have the tools and procedures they need for migration ahead of time.  Testing of these procedures, even if the results are discarded after testing, should help the archive control its costs and improve its reliability.</p>
<p>The static appearance of presentation files can also be preserved through printouts, as other digital preservation studies have observed.<note target="Penn24">[24]</note>  However, printout-based preservation can get expensive, particularly if the originals are in full color, and it loses the extra information in the electronic version, including a machine-readable and machine-searchable form of the text.  Particularly prudent and well-funded archives may want to consider printout backups, but as long as electronic journals are published in conservatively-structured files with standard formats, full printed backups are probably not necessary. There may be a place, however, for selective printouts, triggered when an analyzer detects that a file has unusual characteristics that might make it hard to use or migrate optimally.</p>
<p>As with ingestion, preservation and migration of journal content can be simplified if publishers settle on standard forms to use in their source and presentation files.  Archives and their users should encourage publishers to use standard forms when possible and help define such forms where necessary, such as the standard XML form for e-journal source files recommended by the Inera study. They should also make sure that "standard" formats and delivery mechanisms continue to be open and supportive of archiving functions. Archives should be much more wary of proprietary formats without openly published definitions (Microsoft Word, for example).  If it is necessary to ingest such formats, archives should try to migrate the files to formats more suitable to archiving as soon as possible since the only tools available for this migration might be proprietary programs with a limited useful lifespan. The introduction of "Digital Rights Management" should also be critically scrutinized. Such capability, designed to protect copyrights by restricting copying and use, may severely impede many archival functions and may be very difficult, both technically and legally, to work around.</p>
<p>Finally, even when journals have been fully and successfully migrated to new forms, we recommend also keeping the forms originally ingested by the archiving system if it is not cost-prohibitive to do so.  Scholars have long found value in going to the original form of a document, or as close to the original as possible, often for reasons the original preservers did not anticipate. For example, the location of line breaks may seem like trivial information, but it may be of value to scholars, and since most migration of nontrivial data formats typically lose some information, the location of line breaks may not survive a migration. Even if no one cares to directly study the original binary representations of an electronic journal, archivists may in the future find new ways to migrate or display content that are more reliable and preserve more information which they can then apply if the original forms have been preserved.</p>
</div2>

<div2 type="subsection" n="09"><head>Summary and conclusions</head>
<p>By the time we reached the end of the planning project at Penn, we found that many of our initial assumptions had changed. When we embarked on the planning project, we hoped to act as a primary archive for most or all of the journals of two university-affiliated publishers. We initially focused on preserving presentation forms of journals, automation of as many functions as possible, pre-planned migration strategies, relatively open access to content after a few years, and verification of the content by its users, as well as by automated checks.  Funding would come from publisher endowments and from users of advanced access services.  By the end of the project, we hoped to have both a full working prototype archive and agreements with publishers for permanent archiving of the journals.  We found that our reach exceeded our grasp but that the planning process and the problems we uncovered could help guide formation of viable archival communities.</p>
<p>In our planning year, we negotiated with Oxford and Cambridge for the archiving of their electronic journals.  We also developed prototype code to harvest journal metadata and content from their Web sites to facilitate low-cost, automated archiving of presentation forms for the journals.  We have not come to a final agreement with the publishers, in part because we do not now plan to be the primary archive for their journals as we had originally intended, and because the consortium-based archiving solution we hope will archive their content has not yet been established. However, both publishers are interested in having third parties archive their material under appropriate conditions and safeguards and have made agreements for third parties, such as Highwire and PubMedCentral, to archive and share at least some of their journals.  If a viable consortial archiving arrangement does emerge, we would be happy to work with Oxford and Cambridge in negotiating their agreements with the consortium.  We may also be able to assist in ingestion of their content by further developing and maintaining our code to harvest material from the Web.</p>
<p>Our discussions with publishers and peer libraries and archives were also illuminating.  While we initially intended to focus on preserving presentation files, both publishers and other libraries made it clear that they found the extra structure and functionality of source files to be an important part of preserving the journal content.  While archiving source files can be costly, particularly in the ingestion stage, they do appear to be desirable enough to archive along with presentation files. Standardization of source file format, such as recommended in the Harvard-commissioned Inera study, would help control these costs and allow more consistent levels of service in archive access. Source file standardization was also appealing to publishers.</p>
<p>Migration and other types of conversion will be necessary in the archive, and we continue to believe that pre-planning these migrations is important.  Standardized XML formats for source files should be easy to migrate since XML is now ubiquitous.  Migration of HTML files without extra scripting beyond standard stylesheet forms or server-side support should be accomplishable without difficulty as well. Migration of PDF, while more complex, also should remain feasible in all versions up to the current version (1.4), as long as the files are checked to ensure that fonts, scripting, and digital rights management do not get in the way.  We recommend retaining the original file format of archive submissions as well, if they are not unreasonably large, since we cannot always anticipate what information might be lost in a migration step that would be of interest to future scholars.  Setting up distinct services to maintain information on archival data formats as well as conversions and other operations on those formats will help keep archive content usable as technology changes.</p>
<p>The experience of JSTOR shows that one organization can coordinate many of the core functions of an electronic journal archive.  It also shows that given sufficient delay, a moving wall for opening access to older journal materials does not appear to jeopardize subscription revenues.  Wide access to these materials both increases confidence in their reliability and provides a broad base of financial support to the archive from its subscribers.  A critical mass of journals in the archive also helps gain subscriber support.  An integrated journal archiving organization is more likely to be sustainable, at least in the short term, than a large number of smaller, independently run archival organizations, each creating redundant technology and systems and each having to compete for subscriber support.</p>
<p>In a JSTOR-like access model, funding by libraries and other users of an archive is more likely to be viable than heavy reliance on publisher funding. The endowment model we originally proposed for subsidizing archiving in perpetuity, even if feasible for some larger publishers, may be overly burdensome on small publishers and on new cooperative scholarly publishing ventures.  Moreover, publishers that do fund all or most of the archiving are likely to want more restrictive access terms than many scholars and libraries want.  Except for charges for specific services, such as initial publication or archival ingestion of journal content, it is best that integrated archives supported by the scholarly community also be funded by that community, that is, by the libraries and other users of the archive.  That community should also have access to the contents of the archive after a suitable interval (in the neighborhood of five years) has passed from original publication.</p>
<p>A consortially-run archive is not likely to please everyone nor archive all of the journals that will be of interest to scholars. Therefore, development should also continue on lightweight, distributed archival technology like LOCKSS, which allows individual libraries and other journal subscribers to decide what they want to store, with increasing reliability of the content as more participants decide to store the content. When the technology is fully developed each library can retain the power to archive what it finds important, while being able to delegate archiving of established, widely-recognized journals to a central organization.</p>
<p>With several archival efforts by publishers, academic libraries, and national libraries already underway in various parts of the world, and with more informal distributed archival networks in development, the archival community will need some way of keeping track of what journals are being archived and by whom.  It will also be useful to keep track of service providers for archival support functions including format and migration handling.  A registry service could fill a needed role here.   It could be set up in conjunction with a consortial archive or it could augment existing or planned registry and directory services like Jake or TOM.</p>
<p>The Penn Library is ready to support a well-organized electronic scholarly journal archive that meets the needs of researchers here and at other universities.  The success of the JSTOR project, to which Penn subscribes, shows the feasibility of providing substantial collections of journal runs to benefit scholars and the widespread support it can draw.  We hope our experiences and recommendations can help make JSTOR-like archives of electronic content beneficial to scholars, cost-effective, and sustainable.  We are also interested in participating in future tests of LOCKSS improvements, to advance the complementary model of distributed library-based archiving, and can dedicate some of the equipment acquired in our planning year towards this end.  Finally, we are interested in the possibility of offering services to the archiving community such as ingestion of journal material and registry support for data format information and migration.</p>
<p>To summarize the next steps we recommend taking:</p>

<list>
<item>We recommend following in the footsteps of JSTOR in setting up a library-supported organization for archiving electronic journals.  We will encourage our publishing partners to submit electronic journals to a well-designed archive along these lines and can work with them to help set up appropriate agreements and ingestion procedures.</item>
<item>We recommend further development of LOCKSS technology (with the enhancements recommended in this report) to support lightweight distributed library archiving as a complementary strategy to setting up an archival organization.  We will set up a LOCKSS cache at this site so we can help test the technology and will suggest ways it can be optimized for reliable journal preservation.</item>
<item>We recommend setting up service providers and registries to support archival functions and user needs.  We will plan to provide such services ourselves.  Initially, we plan to further develop TOM to better support data formats, migrations, and systems used for digital preservation, and to explore possible use of the technology as a basis for a community registry of data formats and services for preservation.</item>
</list>

<p>With several years' worth of electronically published scholarly journals now online and increasing dependence of scholars on the electronic medium, the time is riper than ever to move forward with electronic journal archives.  We look forward to working with the community to help build and sustain them to ensure reliable, accessible, and robust scholarly communication.</p>
</div2>

<div2 type="subsection" n="10"><head>Postscript: 2003</head>
<p>Since this report was written, the Penn Library has continued its involvement in technical initiatives to support long-term preservation of electronic journals and other digital information.</p>
<p>We are working with the Library of Congress-led National Digital Information Infrastructure and Preservation Program (NDIIPP) to help develop a distributed architecture for archiving digital information. The architecture is being designed to support a wide range of archival systems and strategies, and to allow institutions to collaborate in preserving, migrating, and exchanging digital information. The NDIIPP architecture group is designing tests of archival interoperation to be conducted next year, using an existing multimedia Web collection.  More information on NDIIPP can be found at <xref doc="digitalpreservation">http://www.digitalpreservation.gov/</xref>.</p>
<p>We have also now joined the LOCKSS network, described in our report, and are helping integrate LOCKSS with proxy systems for everyday use of LOCKSS-cached content.  The LOCKSS project is also working on archiving a wider variety of content, which we hope will test and improve its robustness as a general preservation system.</p>
<p>The need for long-term support of data formats has been a recurring theme in meetings of NDIIPP and other preservaion initiatives.  Penn has recently received a grant from the Mellon Foundation to develop practical applications of TOM (which we described in the report) to support the handling of diverse data formats for digital preservation and online learning systems. We will be releasing TOM-based conversion services, format brokers, and program libraries this fall as open source software.  With this software, publishers and archives can describe relevant data formats and provide identification, migration, and emulation services for them.  We hope that this software will also support data format registries serving the digital preservation community.  Updates and additional information on TOM and its services can be found at <xref doc="tomlibraryupenn">http://tom.library.upenn.edu/</xref>.</p>
<p>Our report found that documents in the PDF format were preservable if they conformed to certain constraints.  Since then, international efforts have proposed a standard for restricted forms of PDF designed to facilitate preservation.  We hope that this standard, known as PDF/A, will be widely adopted and aid in the preservation of PDF-based documents.  More information on PDF/A can be found at <xref doc="aiima">http://www.aiim.org/pdf_a/</xref>.</p>
</div2>

<div2 type="subsection" n="11"><head>Endnotes</head>
<note id="Penn01">[1] For more on the JSTOR model, see <xref doc="jstorabout">http://www.jstor.org/about/</xref>.</note>
<note id="Penn02">[2] For more on the LOCKSS model, see Stanford's report in this publication. See also <xref doc="lockss">http://www.lockss.org/</xref>.</note>
<note id="Penn03">[3] University of Pennsylvania Library, "2002 Quality/Impact Survey,"  Unpublished report (2002).</note>
<note id="Penn04">[4] University of Pennsylvania Library, "Usage statistics for July 2001-2002." The most popular e-journal, <hi rend="italics">Nature</hi>, had 15,396 logins through the Penn Library in this timeframe.</note>
<note id="Penn05">[5] These migrations were infrequent, typically occurring only once in decades of use and bringing with them other opportunities to save costs: for instance, by freeing shelf space once taken up by full-sized print copies.</note>
<note id="Penn06">[6] From an analysis of <xref doc="jstoraboutissues">http://www.jstor.org/about/issues/</xref>.</note>
<note id="Penn07">[7] Dan Greenstein and Deanna Marcum, "Minimum Criteria for an Archival Repository of Digital Scholarly Journals,"  Version 1.2 (Washington, DC: Digital Library Federation, 15 May 2000). Online at <xref doc="diglibpreservecriteria">http://www.diglib.org/preserve/criteria.htm</xref>. This document is also included elsewhere in this publication.</note>
<note id="Penn08">[8] RLG-OCLC, <hi rend="italics">Trusted Digital Repositories: Attributes and Responsibilities</hi> (Mountain View, CA: Research Libraries Group, May 2002). Online at <xref doc="rlglongtermrepositories">http://www.rlg.org/longterm/repositories.pdf</xref>.</note>
<note id="Penn09">[9] Consultative Committee for Space Data Systems,  <hi rend="italics">Reference Model for an Open Archival Information System (OAIS)</hi>, CCSDS-650.0-B-1 Blue Book (Washington, DC: National Aeronautics and Space Administration, January 2002).  Online at <xref doc="wwwclassicccsdsdocumentsCCSDS6500B1">http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf</xref>.</note>
<note id="Penn10">[10] Inera Inc., <hi rend="italics">E-Journal Archive DTD Feasibility Study</hi> (5 December 2001). Online at <xref doc="diglibpreservehadtdfs">http://www.diglib.org/preserve/hadtdfs.pdf</xref>.</note>
<note id="Penn11">[11] Budapest Open Access Initiative, "Statement of 14 February 2002." Online at <xref doc="sorosopenaccessread">http://www.soros.org/openaccess/read.shtml</xref>.</note>
<note id="Penn12">[12] <hi rend="italics">DSpace Federation</hi>.  Online at <xref doc="dspace">http://www.dspace.org/</xref>.</note>
<note id="Penn13">[13] Vicky Reich and David S. H. Rosenthal, "LOCKSS: A Permanent Web Publishing and Access System,"  <hi rend="italics">D-Lib Magazine</hi> 7.6 (June 2001). Online at <xref doc="dlibjune01reich06reich">http://www.dlib.org/dlib/june01/reich/06reich.html</xref>.</note>
<note id="Penn14">[14] The OAIS model itself does not enforce unique identifiers beyond the scope of a particular archive, though federations can create globally unique identifiers.</note>
<note id="Penn15">[15] If a LOCKSS server changes the content of an object, but other servers do not, the changed copy is considered to be corrupt and is corrected to agree with the others.</note>
<note id="Penn16">[16] Note that sequences of monotonic updates require very little extra storage space for older versions, since only differences from the newer version need to be specified.</note>
<note id="Penn17">[17] Kimberly Parker, Cynthia Crooker, and Dan Chudnov, "Jake: Overview and Status Report," <hi rend="italics">Serials Review</hi> 26.4 (2000): 12-17.  Online at <xref doc="jakedbdocsjakeoverviewserrev">http://jake-db.org/docs/jake-overview-serrev.pdf</xref>.</note>
<note id="Penn18">[18] John Ockerbloom,  "Mediating Among Diverse Data Formats," diss.,  Carnegie Mellon University. Technical Report CMU-CS-92-102 (1998). Available online in Postscript from <xref doc="tomlibraryupennpubsindex">http://tom.library.upenn.edu/pubs/index.html</xref>.</note>
<note id="Penn19">[19] The Open Archives Initiative (OAI) is a different initiative altogether from OAIS. See <xref doc="openarchives">http://www.openarchives.org/</xref>.</note>
<note id="Penn20">[20] Martin Richardson, "Impacts of Free Access,"  Letter to <hi rend="italics">Nature</hi> (5 April 2001).  Online at <xref doc="naturedebateseaccessArticlesrichardson">http://www.nature.com/nature/debates/e-access/Articles/richardson.html</xref>.</note>
<note id="Penn21">[21] There were, however, some exceptions for older content and for journals with experimental features.</note>
<note id="Penn22">[22] Jeannette Wing and John Ockerbloom, "Respectful Type Converters," <hi rend="italics">IEEE Transations on Software Engineering</hi> 26.7 (July 2000): 579-593.</note>
<note id="Penn23">[23] John Mark Ockerbloom,  "Archiving and Preserving PDF Files,"  <hi rend="italics">RLG DigiNews</hi> 5.1 (15 February 2001).  Online at <xref doc="rlgpreservdiginews51feature2">http://www.rlg.org/preserv/diginews/diginews5-1.html#feature2</xref>.</note>
<note id="Penn24">[24] For example, see Donald Waters and John Garrett, co-chairs, <hi rend="italics">Preserving Digital Information: Report of the Task Force on Archiving of Digital Information</hi>. Commission on Preservation and Access and the Research Libraries Group (1 May 1996): 27. Online at <xref doc="ftprlgpubarchtffinalreport">ftp://ftp.rlg.org/pub/archtf/final-report.pdf</xref>.</note>
</div2>
</div1>

<div1 type="section" n="07"><head>Lockss: A Distributed <lb/>Digital Archiving System</head>
<p rend="center">Progress Report For The <lb/>Digital Library Federation <lb/>Preservation Web Site <lb/>Mellon Electronic Journal Archiving Program</p>
<p rend="center">Stanford University Libraries <lb/>8 October 2002</p>
<div2 type="subsection" n="01"><head>Introduction</head>
<p>With funds from the Andrew W. Mellon Foundation, Stanford University validated the LOCKSS software and protocol through a rigorous beta test conducted from January 2001 to August 2002.  The software is licensed as open source and is available for download from <xref doc="sourceforgeprojectslockss">http://sourceforge.net/projects/lockss/</xref>. The success of the beta test can, in large part, be measured by community support and enthusiasm; over fifty libraries and over forty publishers are currently participating in the program. In addition, for the immediate future, all three of the project's funding agencies  --  the National Science Foundation, Sun Microsystems, and the Mellon Foundation  --  continue to support ongoing work.</p>
</div2>

<div2 type="subsection" n="02"><head>Key Accomplishments</head>
<p>The LOCKSS model, which is based on analysis of cultural continuity epitomized by "Lots of Copies Keeps Stuff Safe," creates low-cost, persistent digital "caches" of e-journal content at institutions that 1) subscribe to that content and 2) actively choose to preserve it. Accuracy and completeness of LOCKSS caches are assured through a peer-to-peer polling system, operated through the Library Cache Auditing Protocol (LCAP), LOCKSS' communication protocol, which is both robust and secure. The creation of such caches, given the requirement that the caching library already have the right through subscription to obtain that content, has met with a high degree of publisher and library engagement and commitment.</p>

<list>
<item>1. <hi rend="bold">Technology:</hi> Through its technical development and beta testing (1999-2002), the LOCKSS project has demonstrated that its model and protocol are technically viable.
<list>
<item>The beta system has been deployed successfully to more than fifty sites around the world.</item>
<item>Fifty sites have run with little operator intervention for nearly a year. The average site has spent about an hour a month dealing with its cache. Almost all of this time has been on cache-level problems rather than journal-level problems, e.g.: because a cache was unplugged from the network or from power, the cache needed an IP address change, or the packet filters between the cache and the Internet were changed. </item>
<item>The test sites have been happy with the support provided by the LOCKSS team. The team has spent one to two person-days per week supporting the beta sites.</item>
<item>The beta test implementation successfully collected and preserved e-journal content, both from static mirrors and from dynamic "clones" of the online editions of PNAS (<hi rend="italics">Proceedings of the National Academy of Sciences</hi>), BMJ (<hi rend="italics">British Medical Journal</hi>), and <hi rend="italics">Science</hi>.</item>
<item>The system detected and repaired both deliberate and accidental damage.</item>
<item>The system survived hardware failures, network outages, and attacks by "bad guys."</item>
<item>Experience with the current system and analogies with such environments as Google's caching architecture (a collection of several thousand PCs that caches the entire accessible Web), give us confidence that the system can scale to many terabytes of journal content.</item>
<item>Experience with the current system and analogies with the Gnutella peer-to-peer file sharing system give us confidence that the system can scale to many thousands of LOCKSS caches without generating excessive network traffic. The LOCKSS protocol should avoid the scaling problems of the Gnutella protocol.<note target="Lockss01">[1]</note></item>
<item>The system preserved content in a wide range of formats and delivered it unchanged to readers who directly accessed the beta test caches.</item>
</list></item>
<item>2. <hi rend="bold">Libraries and Publishers:</hi> Support from the library and publishing communities has been gratifying. Involved in the alpha test were six libraries and one publisher. For the beta test, more than fifty libraries worldwide are running LOCKSS caches and several dozen more are waiting to come online. More than forty publishers are listed on the Web site as LOCKSS program supporters. Many of these publishers are "supporting the project in principle" while some have committed to grant needed permissions for full deployment of the system once production software is released.</item>
<item><hi rend="bold">Intellectual Property:</hi> Ropes and Gray, the IP law firm retained by Stanford University, consulted with us on the legal implications and requirements of the LOCKSS system. Ropes and Gray recommended that publishers be required to provide two kinds of permission: for libraries, written permission to cache and archive content; for the LOCKSS caches, "machine readable permission" to collect and preserve content. This second "machine" permission fulfills Digital Millennium Copyright Act (DMCA) obligations.<note target="Lockss02">[2]</note> <lb/>
For LOCKSS to work as designed, publishers will need to grant libraries blanket permission to use the LOCKSS software. We recommend adoption of the following (or similar) language in subscription agreements:
<q>
<hi rend="italics">Publisher acknowledges that Licensee participates in the LOCKSS system for archiving digitized publications. Licensee may perpetually use the LOCKSS system to archive and restore the Licensed Materials, so long as Licensee's use is otherwise consistent with this Agreement. Licensee may also provide its digital copies of Licensed Materials to other LOCKSS systems in support of the overall preservation and restoration purposes of LOCKSS, so long as any other LOCKSS system demonstrates it has the rights to the Licensed Materials necessary to access and copy them.</hi>
</q>
Currently LOCKSS caches collect content as it is published so permission must be granted at the point of subscription. Our intent is to avoid the need for negotiations with each library for each title. This language grants permission for libraries to:
<list>
<item>Hold copies of subscribed (or otherwise authorized) materials</item>
<item>Use cached material consistent with original subscription terms</item>
<item>Provide access to the local community</item>
<item>Provide copies for audit and repair to other caches only if they have had a copy in the past</item>
</list>
Publishers must give the LOCKSS crawler permission to slowly crawl, collect, and cache content. We ask that this permission be granted through a Web page that lists at minimum the top level URLs for whatever is the "archival unit" of a title. We call this Web page the "publisher manifest." The LOCKSS system will work more efficiently as the "publisher manifest" becomes more detailed (for example, article level file description for each issue/volume). We are urging publishers to provide in this manifest the front matter information not usually included in the electronic journal, such as the editorial board, author instructions, etc. This is not an intellectual property concern, but will help ensure collection and preservation of complete content.</item>
<item>4. <hi rend="bold">Economics:</hi> The LOCKSS software is open source and freely available for download from <xref doc="sourceforgeprojectslockss">http://www.sourceforge.org/projects/lockss/</xref>. No fees are required from any party to use the LOCKSS software to archive content. In theory, the LOCKSS system is decentralized and does not require coordination. In practice, for a sustainable distributed e-journal archival system, some coordinating program infrastructure is advised both for software development and support, and for coordination of collection management initiatives. <lb/>During the period of this grant award, we verified through hour-long interviews with most of the participating organizations that libraries and publishers are interested in working together through a for-fee service organization to pay for tangible LOCKSS technology, collection development services, and management coordination services. The business plan is under development.</item>
</list>
</div2>

<div2 type="subsection" n="03"><head>Lessons Learned</head>
<p>Beyond validating that the LOCKSS model is viable, the beta test has revealed, as hoped, a number of strengths and weaknesses to the initial technical design. We now need to perfect the technology and to establish the LOCKSS model as an ongoing, operating archival solution based on the knowledge and insight gleaned over the past twenty months.</p>
<list>
<item>1. <hi rend="bold">Technology:</hi> Much additional work is needed to produce an "appliance" based on the LOCKSS technology that can be used by a community of libraries as a sustainable e-journal archiving system. In particular, we determined we need to build a set of content-specific plug-in modules that drive the processes of collecting, preserving, and providing access to specific e-journals. Each "online publishing platform" will require a separate plug-in module (for example, one for HighWire Press titles, one for Blackwell Synergy titles, etc.). This will entail rewriting the existing Java daemon to segregate all potentially journal-specific knowledge behind a set of Java interface definitions (i.e., an API) that can be implemented by downloadable Java classes. This software will be designed to use whatever journal-specific information is available to make more efficient the searches for new content and for damage to preserved content by:
<list>
<item>Exploiting knowledge of the e-journal's URL structure to target the search for newly published content</item>
<item>Exploiting knowledge of the e-journal's URL structure to drive the checking process and target the search for damage</item>
<item>Using knowledge of the e-journal's HTML formatting to assist the comparison process by filtering out variable content such as advertisements</item>
<item>Mapping between bibliographic information, URL, and file names for content</item>
</list>
From the development point of view, the platform or system on which e-journals are mounted is critical. The addition of an e-journal to a library's collection is dependent on the presence of an appropriate plug-in for the technology supporting that e-journal. While it is more efficient to develop plug-ins for widely-used platforms rather than idiosyncratic, one-off or few-title platforms, there is a parallel need to acquire competence and to embrace smaller and/or less sophisticated titles.</item>
<item>2. <hi rend="bold">Libraries and Publishers:</hi>
<list>
<item>For LOCKSS to work in production, publishers must provide written permission to libraries to cache and archive content and "machine-readable permission" to the LOCKSS caches to collect and preserve content. It is our challenge and the challenge of librarians worldwide to obtain these permissions from publishers. The LOCKSS Alliance (under development) is designed to assist with this process. <lb/>The LOCKSS software provides libraries a tool for building local digital collections. Local use of the LOCKSS software will impose tasks and responsibilities on the collection development, technical services, and system librarian staffs. At minimum, libraries must develop and implement collection development decisions and then make locally cached content available to their local communities of readers. As libraries choose ever-larger numbers of e-journals for preservation, they will need collection management tools and support for the LOCKSS administrative interface to interoperate with collection management programs. In our current LOCKSS Mellon grant, Indiana University is leading efforts to assess collection management user needs, to specify data flows between LOCKSS caches and collection management systems, and to build a "proof of concept" prototype.</item>
</list></item>
<item>3. <hi rend="bold">Economics:</hi> Both libraries and publishers have expressed interest in participating in a new organization supporting the LOCKSS Program. We proceed with "enthusiastic realism" to build a LOCKSS Alliance.</item>
</list>
</div2>

<div2 type="subsection" n="04"><head>Immediate Plans</head>
<p>With continued support from the Mellon Foundation, Stanford University Libraries is endeavoring to build a production archive system for electronic journals. Mellon Project Officer Don Waters has publicly stated our charge succinctly:</p>
<q>
During the next phase of development, the key issues for the LOCKSS system are to separate the underlying technology from its application as an e-journal archiving tool; explore ways of ensuring the completeness and quality of e-journal content on acquisition and of managing the content as bibliographic entities rather than simply as Web-addressed files; expand the coverage of journals; maintain the LOCKSS software; and identify strategies for migrating the e-journal content. To help undertake and finance these tasks, Stanford has identified a variety of partners and is planning the development of a LOCKSS consortium.<note target="Lockss03">[3]</note>
</q>

<p>With our partners (Emory University, Indiana University, and the New York Public Library), Stanford University Libraries intends to construct a process so the community can drive functional specifications, design a general set of query/response interactions so the functional specifications can be implemented within most library technical environments, and as possible, prototype one potential implementation of collection management software.</p>
<p>Continued Sun Microsystems and National Science Foundation support will allow us to continue core technology development, focusing on the peer-to-peer, fault-tolerant aspects of the system.</p>
</div2>

<div2 type="subsection" n="05"><head>Postscript: 2003</head>
<p>The development of the LOCKSS system continues to move forward at a considerable pace. For current status please see the LOCKSS Web Site at <xref doc="lockssstanford">http://lockss.stanford.edu</xref> or contact vreich "at" stanford "dot" edu (<xref doc="vreichstanford">mailto:vreich@stanford.edu</xref>).</p>
</div2>

<div2 type="subsection" n="06"><head>Endnotes</head>
<note id="Lockss01">[1] See the Gnutella Protocol Specification v0.4 online at <xref doc="limewiredevelopergnutellaprotocol04">http://www9.limewire.com/developer/gnutella_protocol_0.4.pdf</xref>.</note>
<note id="Lockss02">[2] See <xref doc="loccopyrightlegislationdmca">http://www.loc.gov/copyright/legislation/dmca.pdf</xref>.</note>
<note id="Lockss03">[3] See Donald Waters, "Good Archives Make Good Scholars: Reflections on Recent Steps Toward the Archiving of Digital Information," <hi rend="italics">The State of Digital Preservation: An International Perspective: Conference Proceedings</hi>, Publication 107 (Washington, DC: Council on Library and Information Resources, July 2002). Online at <xref doc="clirpubsreportspub107waters">http://www.clir.org/pubs/reports/pub107/waters.html</xref>.</note>
</div2>
</div1>

<div1 type="section" n="08"><head>YEA: The Yale Electronic Archive <lb/>One Year of Progress</head>
<p rend="center">Report on the Digital Preservation Planning Project</p>
<p rend="center">A collaboration between <lb/>Yale University Library and Elsevier Science</p>
<p rend="center">Funded by the Andrew W. Mellon Foundation</p>
<p rend="center">New Haven, CT <lb/>February 2002</p>

<p><q>
<hi rend="italics">Librarianship is a curious profession in which we select materials we don't know will be wanted, which we can only imperfectly assess, against criteria which cannot be precisely defined, for people we've usually never met and if anything important happens as a result we shall probably never know, often because the user doesn't realize it himself.</hi>  --  Charlton quoted by Revill in presentation by Peter Brophy, Manchester Metropolitan University, 4th Northumbria Conference, August 2001
</q></p>

<div2 type="subsection" n="01"><head>The Project Team</head>
<p><hi rend="italics">Project members began in January 2001 and are continuing with the project unless otherwise indicated)</hi></p>

<div3 type="part" n="01"><head>Yale University Library</head>
<list>
<item>Scott Bennett, University Librarian (Principal Investigator, January  -  July 2001)</item>
<item>Paul Conway, Director of Preservation (Project Manager, January  -  June 2001)</item>
<item>David Gewirtz, Senior Systems Manager, Yale ITS (Project Technical Director)</item>
<item>Fred Martz, Director of Library Systems (Project Technical Advisor)</item>
<item>Ann Okerson, Associate University Librarian (Co-Principal Investigator, January  -  July 2001; Principal Investigator July 2001 -)</item>
<item>Kimberly Parker, Electronic Publishing &amp; Collections Librarian (Metadata Investigator)</item>
<item>Richard Szary, Director of University Manuscripts &amp; Archives (Investigator for Archival Uses)</item>
</list>
<p><hi rend="italics">Additional advice and support from:</hi></p>
<list>
<item>Matthew Beacom, Catalog Librarian for Networked Information, Yale Library</item>
<item>Jean-Claude Gu&#x00E9;don, Professor of Comparative Literature and History of Sciences, Universit&#x00E9; de Montreal</item>
<item>James Shetler, Asst. Head of Acquisitions, Yale Library</item>
<item>Rodney Stenlake, Esq., Independent Legal Consultant</item>
<item>Stephen Yearl, Digital Systems Archivist, Yale Library</item>
</list>
<p><hi rend="bold">Elsevier Science</hi></p>
<list>
<item>Karen Hunter, Senior Vice President for Strategy</item>
<item>Geoffrey Adams, Director of IT Solutions</item>
<item>Emeka Akaezuwa, Associate Director, Information Technology Implementation</item>
</list>
<p><hi rend="italics">Additional advice and support from:</hi></p>
<list>
<item>Haroon Chohan, Elsevier Science, IT Consultant</item>
<item>Paul Mostert, Senior Production IT Manager, Hybrid/Local Solutions, ScienceDirect, Elsevier Amsterdam</item>
</list>
</div3>
</div2>

<div2 type="subsection" n="02"><head>Acknowledgments</head>
<p>Particular thanks go to the following:</p>
<p>Scott Bennett, for his thoughtful and elegant framing of the issues from the outset to the midpoint of the Project and for always keeping our team on target and on time. From the point of his retirement as of July 31, 2001, we have sincerely missed his dedication and contributions to digital preservation, in which he believed passionately.</p>
<p>The Andrew W. Mellon Foundation, for a tangible demonstration of faith, both in the scholarly community's ability to tackle and begin to solve the vital issues associated with long-term digital preservation, and in the ability of the Yale Library to be one of the players helping to find solutions. Particularly we thank Don Waters of the Foundation for his deep commitment to electronic archiving and preservation and for his help to us.</p>
<p>Our team counterparts at Elsevier Science, for proving to be true partners, giving unstintingly their commitment, time, and thoughtfulness to our joint effort. They have shared fully information, data, and technology expertise. We have learned that our two entities, working together, are much stronger than the sum of our parts.</p>
<p>Yale Information Technology Services, for donating far more of David Gewirtz's time than we had any right to expect and for offering their enthusiastic support and advice.</p>
<p>Other Mellon planning projects and their staffs, for giving us help and insights along the way.</p>
<p>Finally, I personally wish to thank each of our team members, because everyone, out of commitment to the long-term mission of libraries, excitement about digital information technologies and their potential, the thrill of learning, and genuine respect for each other's contributions, did more than their share and contributed to a strong planning phase.</p>
<p><hi rend="italics">Ann Okerson, Principal Investigator</hi></p>
</div2>

<div2 type="subsection" n="03"><head>Executive Summary</head>
<p>Networked information technology offers immense new possibilities in collecting, managing, and accessing unimaginable quantities of information. But the media in which such information lives are remarkably more ephemeral and fragile than even traditional print media. For such information to have a place in scientific and academic discourse, there must be assurance of long-term preservation of data in a form that can be accessed by users with the kind of assurance they now bring to print materials preserved in libraries. The Yale-Elsevier planning project undertook to study the challenges and opportunities for such preservation posed by a large collection of commercially published scientific journals.</p>
<p>Despite the natural interdependence between libraries and publishers, skepticism remains in both communities about the potential for successful library/publisher collaborations, especially in the electronic archiving arena. The e-archiving planning effort between the Yale University Library and Elsevier Science funded by the Andrew W. Mellon Foundation has resulted in substantial gains in bridging the traditional divide between these two groups and has paved the way for continuing collaboration. The goals of our effort were to understand better the scope and scale of digital journal preservation and to reach a position in which it was possible to identify practical next steps in some degree of detail and with a high level of confidence. We believe we have achieved these goals.</p>
<p>From the outset, the Yale-Elsevier team recognized and respected the important and fundamental differences in our respective missions. Any successful and robust e-archive must be built on an infrastructure created specifically to respond to preservation needs and that can only be done with a clear understanding of those missions. Managing library preservation responsibilities for electronic content while protecting a publisher's commercial interests is thus no small task. We have begun with a mutually-beneficial learning process. Work during the Mellon planning year gave us a better understanding of the commercial life cycle of electronic journals, of the ways in which journal production will impact the success of an e-archive, and of the motives that each party brings to the process and the benefits that each party expects.</p>
<p>From the start, the exploration was based on the premise of separating content from functionality. Embedded here is the belief that users of the e-archive are not bench scientists for whom ease of use of the most current scientific information is critical. We envision potential users of the e-archive to be focused primarily on the content. They must be confident that it remains true to what was published and is not influenced/affected by changes in technology that undoubtedly affect functionality. Minimally acceptable standards of access can be defined without mirroring all features of a publisher's evolving interface.</p>
<p>Our determinations include the following:</p>
<list>
<item>Migration of data offers a more realistic strategy than emulation of obsolete systems;</item>
<item>Preservation metadata differs from that required for production systems and adds real value to the content;</item>
<item>No preservation program is an island, hence success will depend on adherence to broadly accepted standards and best practices;</item>
<item>A reasonable preservation process is one that identifies clearly the "trigger events" that would require consultation of the archive and plans accordingly.</item>
</list>
<p>We have made effective use of the information learned by library peers in their efforts and in turn have shared the results of our work. Ultimately, the future of electronic archives depends fundamentally on a network of cooperating archives, built on well-conceived and broadly-adopted standards.</p>
<p>Nevertheless, the relationship between publisher and archiver is fundamental. We have begun work on a model license that draws on Yale's extensive experience in developing and modeling successful license agreements. Such an agreement will shape the publisher/archive relationship in ways that control costs, increase effectiveness, and give the archive a place in the economic and intellectual life cycle of the journals preserved.</p>
<p>The Yale-Elsevier team has demonstrated that working collaboratively, we can now begin to build a small prototype archive using emerging standards and available software. This prototype has the potential to become the cornerstone of an e-journal archive environment that provides full backup, preservation, refreshing, and migration functions. We have demonstrated that the prototype   --   offering content from many or all of the more than 1,200 Elsevier Science journals   --   can and will function reliably. We are guardedly optimistic about the economic prospects for such archives, but can only test that optimism against a large-scale prototype.</p>
<p>For this archive to become a reality, we must play a continuing lead role in the development and application of standards; help shape and support the notion of a network of cooperating archives; explore further the potential archival uses; and understand and model the economic and sustainability implications.</p>
<p>The following report provides in some detail the results of the Mellon planning year. We believe it demonstrates the deep commitment of the Yale University Library and Elsevier Science to the success of this kind of collaboration, the urgency with which such investigations must be pursued, and the value that can be found in thus assuring the responsible preservation of critical scientific discourse.</p>
</div2>

<div2 type="subsection" n="04"><head>Part  I: Background, Approaches, Assumptions</head>
<div3 type="part" n="01"><head>Challenges for Long-Term Electronic Archiving</head>
<div4 type="subpart" n="01"><head>The Big Issues</head>
<p>The tension that underlies digital preservation issues is the fundamental human tension between mutability and immortality. The ancient Platonic philosophers thought that divine nature was unchanging and immortal and human nature was changeable and mortal. They were right about the human nature at least.</p>
<p>Human products in the normal course of affairs share the fates of their makers. If they are not eradicated, they are changed in ways that run beyond the imagination of their makers. Stewart Brand's <hi rend="italics">How Buildings Learn</hi><note target="Yale01">[1]</note> has lessons for all those who imagine they are involved in the preservation of cultural artifacts, not just people concerned with buildings.</p>
<p>But a very limited class of things has managed a special kind of fate. The invention of writing and the development of cultural practices associated with it has created a unique kind of survival. It is rarely the case that the original artifact of writing itself survives any substantial length of time, and when it does, that artifact itself is rarely the object of much active reading. Most of us have read the "Declaration of Independence" but few do so while standing in front of the signed original in the National Archives.</p>
<p>Written texts have emerged as man-made artifacts with a peculiar kind of near-immortality. Copied and recopied, transforming physically from one generation to the next, they remain still somehow the same, functionally identical to what has gone before. A modern edition of Plato is utterly unlike in every physical dimension the thing that Plato wrote and yet functions for most readers as a sufficient surrogate for the original artifact. For more modern authors, where the distance between original artifact and present surrogate is shorter, the functional utility of the latter is even greater.</p>
<p>That extraordinary cultural fact creates extraordinary expectations. The idea that when we move to a next generation of technologies we will be able to carry forward the expectations and practices of the last generation blithely and effortlessly is probably widely shared   --   and deeply misleading. The shift from organic forms of information storage (from papyrus to animal skin to paper) back to inorganic ones (returning, in silicon, to the same material on which the ancients carved words meant to last forever and in fact, lasting mainly only a few decades or centuries) is part of a larger shift of cultural practices that puts the long-term survival of the text newly at risk.</p>
<p>Some of the principal factors that put our expectations in a
digital age at risk include:</p>
<list>
<item>The ephemeral nature of the specific digital materials we use  --  ephemeral both in that storage materials (e.g., disks, tapes) are fragile and of unknown but surely very limited lifespan, and in that storage technologies (e.g., computers, operating systems, software) change rapidly and thus create reading environments hostile to older materials.</item>
<item>The dependence of the reader on technologies in order to view content. It is impossible to use digital materials without hardware and software systems compatible with the task. All the software that a traditional book requires can be pre-loaded into a human brain (e.g., familiarity with format and structural conventions, knowledge of languages and scripts) and the brain and eyes have the ability to compensate routinely for errors in format and presentation (e.g., typographical errors).
The combined effect of those facts makes it impossible for digital materials to survive usefully without continuing human attention and modification. A digital text cannot be left unattended for a few hundred years, or even a few years, and still be readable.</item>
<item>The print medium is relatively standard among disciplines and even countries. A physicist in Finland and a poet in Portugal expect their cultural materials to be stored in media that are essentially interchangeable. A digital environment allows for multiple kinds of digital objects and encourages different groups to pursue different goals and standards, thus multiplying the kinds of objects (and kinds of hardware and software supporting different kinds of things) that various disciplines can produce and expect to be preserved.</item>
<item>Rapidity of change is a feature of digital information technology. That rapidity means that any steps contemplated to seek stability and permanence are themselves at risk of obsolescing before they can be properly adopted.</item>
<item>The intellectual property regimes under which we operate encourage privatization of various kinds, including restricted access to information as well as the creation of proprietary systems designed to encrypt and hide information from unauthorized users until that information no longer has commercial value, at which point the owner of the property may forget and neglect it.</item>
<item>The quantity of works created in digital form threatens to overwhelm our traditional practices for management.</item>
<item>The aggregation of factors so far outlined threatens to impose costs for management that at this moment we cannot estimate with even an order of magnitude accuracy. Thus we do not have a way of knowing just how much we <hi rend="italics">can</hi> hope to do to achieve our goals and where some tradeoffs may be required.</item>
<item>Finally, the ephemeral nature of the media of recording and transmission imposes a particular sense of urgency on our considerations. Time is not on our side.</item>
</list>
<p>Against all of these entropic tendencies lies the powerful force of expectation. Our deepest cultural practices and expectations have to such an extent naturalized ideas of preservation, permanence, and broad accessibility that even the most resistant software manufacturers and anxious owners of intellectual property will normally respond positively, at least in principle, to concerns of preservation. That is a great advantage and the foundation on which this project is built.</p>
</div4>

<div4 type="subpart" n="02"><head>Social and Organizational Challenges</head>
<p>The reader is the elusive center of our attention, but not many readers attend conferences on digital preservation. We find ourselves instead working among authors, publishers, and libraries, with occasional intervention from benevolent and interested foundations and other institutional agencies. The motives and goals of these different players are roughly aligned, but subtly different.</p>
<q>
<p><hi rend="bold">Authors:</hi>  Authors require in the first instance that their work be made widely known and, for scholarly and scientific information, made known in a form that carries with it the authorization of something like peer review. Raw mass dissemination is not sufficient. Authors require in the second instance that what they write be available to interested users for the useful life of the information. This period varies from discipline to discipline. Authors require in the third instance that their work be accessible for a very long time. This goal is the hardest to achieve and the least effectively pursued, but it nevertheless gives the author community a real interest in preservation. However, the first and second areas of concern are more vital and will lead authors to submit work for publication through channels that offer those services first. In practice, this means that the second motive   --   desire to see material remain in use for some substantial period of time   --   is the strongest authorial intent on which a project such as ours can draw. It will drive authors towards reputable and long-standing publishing operations and away from the local, the ephemeral, and the purely experimental.</p>
<p>It should be noted that at a recent digital preservation meeting,<note target="Yale02">>[2]</note> certain authors affirmed volubly their right to be forgotten, i.e., at the least to have their content not included in digital archives or to be able to remove it from those archives. Curiously, even as we worry about creating long-term, formal electronic archives that are guaranteed to last, we note that the electronic environment shows quite a multiplier effect: once a work is available on the Web, chances are it can be relatively easily copied or downloaded and shared with correspondents or lists (a matter that worries some rights owners immensely even though those re-sends are rarely of more than a single bibliographical object such as an article). This means that once an author has published something, the chances of his or her right to be forgotten are as slim as they were in days of modern printing  --  or even slimmer. Think, if you will, whether "special collections," as we have defined them in the print/fixed-format era, have a meaning in the digital environment and, if so, what might that meaning be? The focus may be not on the materials collected so much as on the expertise and commitment to collect and continue to collect materials at particular centers of excellence, especially where the ongoing task of collection is complex, exacting, difficult, and/or particularly unremunerative.</p>
<p><hi rend="bold">Publishers:</hi>  Publishers require in the first instance that they recruit and retain authors who will produce material of reliable and widely-recognized value. Hence, publishers and authors share a strong common interest in peer review and similar systems whose functioning is quite independent of any question of survival and preservation. Publishers are as well  --  perhaps even more  --  motivated by their paying customers, e.g., the libraries in this case, who can influence the strategic direction of the publisher no less directly. Consequently, publishers require in the second instance that the material they publish be of continuing value in a specific way. That is, publishers of the type we are concerned with here publish serials and depend for their revenue and the intellectual continuity of their operations on a continuous flow of material of comparable kind and quality. The demand for such material is itself conditioned on that continuity, and the availability of previous issues is itself a mark and instrument of that continuity. The publisher, therefore, understands that readers want the latest material but also material that is not only the latest; the scientific journal is thus crucially different from a newspaper. Publishers also have more insubstantial motivations about continuing reputation and may have themselves long histories of distinguished work. But as with authors, it is the second of the motives outlined here  --  where self-interest intersects the interest of others  --  that will most reliably encourage publishers to participate in preservation strategies.</p>
<p><hi rend="bold">Libraries:</hi>  Libraries require in the first instance that users find in their collections the materials most urgently needed for their professional and academic work. This need leads them to pay high prices for current information, even when they could get a better price by waiting (e.g., buying new hard cover books rather than waiting for soft cover or remainder prices, or continuing to purchase electronic newspaper subscriptions rather than depend on content aggregators such as Lexis-Nexis, which they may also be purchasing). They require in the second instance that they build collections that usefully reflect the state and quality of scientific, scholarly, and cultural discourse in their chosen areas of coverage.</p>
<p>Research library collections may be built largely independently of day-to-day use, but libraries expect certain kinds of use over a long period of time. Where information may be published to meet a particular information need, these libraries will retain that information in order to meet their other mission of collecting a cultural heritage for future generations. Yale has been pursuing that project for 300 years. With traditional media, libraries, museums, archives, and other cultural institutions have pursued that project in various independent and cooperative ways. It is reasonable to expect that such cooperation among traditional players and new players will only continue and grow more powerful when the objects of preservation are digital.</p>
</q>
<p>All of the above tantalizing complications of long-term electronic archiving drew us into this planning project and continued to be themes throughout the year-long planning process.</p>
</div4>
</div3>

<div3 type="part" n="02"><head>Background for the Planning Project</head>
<div4 type="subpart" n="01"><head>Yale Library as a Player</head>
<p>The Yale Library has, for close to three decades, been cognizant of and aggressive about providing access to the numerous emerging forms of scholarly and popular publications appearing in "new" electronic formats, in particular those delivered via the Internet and increasingly through a Web interface. Initially, indexing and abstracting services and other "reference" type works found their way into electronic formats and rapidly displaced their former print instantiations. By 1996, full-text content from serious and substantive players such as Academic Press (AP) and JSTOR were entering the marketplace, and libraries  --  and their readers  --  became quickly captivated by the utility, effectiveness, efficiency, and convenience of academic content freed from its traditional fixed formats. By the summer of 2000, Yale Library, like most of its peer institutions, was spending over $1 million annually on these new publication forms, offering several hundred reference databases and thousands of full-text electronic journals to its readers. Expenditures for electronic content and access paid to outside providers last academic year alone totaled nearly $1.8 million. In addition, we spend increasing sums both on the creation of digital content and on the tools to manage digital content internally  --  e.g., a growing digitized image collection, a fledgling collection of university electronic records, digital finding aids for analog materials in our collections, and our online library management system, which includes but is not limited to the public access catalog.</p>
<p>The electronic resources that Yale makes available to readers, both on its own and in conjunction with its partners in the NorthEast Research Libraries consortium (NERL), quickly become heavily used and wildly popular   --   and increasingly duplicative, in terms of effort and price, with a number of print reference works, journals, and books. The Yale Library, with its significant resources, 300 years of collections, and long-term commitment to acquiring and preserving collections not only for its own but also for a global body of readers, has acted cautiously and prudently in retaining print texts not only for immediate use but also for long-time ownership and access. It has treated its growing, largely licensed (and thus un-owned) electronic collections, moreover, as a boon for reader productivity enhancement and convenience, even to the point of acquiring materials that seem to duplicate content but offer different functionality.</p>
<p>Nonetheless, it is clear that the Library (and this is true of all libraries) cannot endlessly continue on such a dual pathway, for several compelling reasons: 1) the growing level of print and electronic duplication is very costly in staff resources and to collections budgets; 2) increasingly, readers, at least in certain fields such as sciences, technology, and medicine (STM), as well as certain social sciences, strongly prefer the electronic format and the use of print in those areas is rapidly diminishing; and 3) traditional library stacks are costly to build or renovate. All libraries face what NERL members have dubbed the "Carol Fleishauer"<note target="Yale03">[3]</note> problem: "We have to subscribe to the electronic resources for many good reasons, but we cannot drop print  --  where we might wish to  --  because we do not trust the permanence of electronic media." The challenge for us all, then, is how to solve the problem that Carol so pointedly articulated at a NERL meeting.</p>
</div4>

<div4 type="subpart" n="02"><head>An Opportunity to Learn and Plan</head>
<p>When the Andrew W. Mellon Foundation first began to signal its keen interest in long-term preservation of digital resources, the Yale Library had already acquired, loaded on site, and migrated certain selected databases and full-text files for its readers. The Library had also explored, between 1997 and 1999, the possibility of serving as a local repository site for either all of Elsevier Science's more than 1,100 full-text e-journal titles or at least for the 300 or so that had been identified by NERL members as the most important for their programs. Yale information technology (IT) staff experimented with a year's worth of Elsevier electronic journals, using the Science Server software for loading and providing functionality to those journals. In the end, the fuller functionality of Science Direct (Elsevier's commercial Web product) proved more attractive for immediate access, particularly as interlinking capabilities between publishers were developed and were more easily exploitable from the commercial site than through a local load. Nonetheless, Yale's positive experience in working with Elsevier content led our staff enthusiastically to consider Elsevier as a possible e-journal archive planning partner.</p>
<p>When we were invited to consider applying for a planning grant (summer 2000) we contacted Karen Hunter, Elsevier Science's Senior Vice President for Strategy, who signaled a keen personal and corporate interest in long-term electronic archiving solutions. Additional attractions for Yale in working with Elsevier related to the huge amount of important content, particularly in STM, that this publisher provides. It also seemed to us that the strong commercial motivation of a for-profit publisher made such a partnership more important and interesting, at least initially, than one with a not-for-profit publisher. That is, a for-profit entity might not feel so much of a long-term or eternal commitment to its content as would a learned society. We have learned in the course of this planning project that Elsevier has its own serious commitment in this area. With Ms. Hunter and other senior Elsevier staff, a self-identified Yale Library team began to formulate e-journal questions and opportunities, and Elsevier officers strongly supported our submission of the Fall 2000 application to Mellon.</p>
<p>Throughout the project, regular meetings between Yale and Elsevier team members have been held, and key topics have been identified and pursued therein, as well as by phone, e-mail, through the work of small sub-groups, through site visits by team members and visitors to our establishments. The principal lines of inquiry have been in the following areas: 1) "trigger" events; 2) a beginning exploration of the fascinating area of "archival uses," i.e., how real-life users might use the kind of archive we were proposing to develop; 3) contractual and licensing issues; 4) metadata identification and analysis, particularly through comparison and cross-mapping with datasets recommended by such players as the British Library and OCLC/RLG; and 5) technical issues, beginning with an examination of Elsevier's production and workflow processes, and with particular emphasis after summer of 2001 on building a small prototype archive based on the OAIS (Open Archival Information Systems) model,<note target="Yale04">[4]</note> focusing on the archival store component. Interlaced have been the economic and sustainability questions that are crucial to all electronic preservation projects.</p>
</div4>

<div4 type="subpart" n="03"><head>An Interesting Mid-Year Development: Acquisition of Academic Press (AP)</head>
<p>In July 2001, the acquisition by Elsevier Science of a number of Harcourt properties and their component journal imprints was announced. This real-life business event presented interesting and significant challenges, not only to Elsevier Science but also prospectively to the Yale Electronic Archive (YEA). At that time, Elsevier had not fully formulated its organizational or technical plans for the new imprints, which included not only AP (whose IDEAL service represented one of the earliest commercially-licensed groups of important scientific journals, introduced to the marketplace in 1995), but also Harcourt, Saunders, Mosby, and Churchill Livingstone, i.e., primarily medical titles which are to be integrated into a new Elsevier division called Health Science. Elsevier staff believe that the imprints of the acquired titles will survive; it is not clear whether the IDEAL electronic platform will continue or whether (more likely) it will be integrated into Science Direct production processes.</p>
<div5 type="division" n="01"><head>Sizing</head>
<p>As a result of this acquisition, Elsevier's total number of journal titles rose from around 1,100-1,200, to about 1,500-1,600, i.e., by nearly 50 percent. In 2002, the combined publications will add collectively 240,000 new articles to Elsevier's electronic offerings; the size of the Elsevier e-archive will become 1.7 million articles in number. Additionally, Elsevier, like many other scholarly and scientific publishers, is pursuing a program of retrospective digitization of its journals, back to Volume One, Number One. The backfiles up to and including the years 1800-1995 (estimated at four to six million entries) will require 4.5 terabytes of storage. The years up to and including 1995-2000 require .75 terabytes. Production output for 2001 is estimated to be at 150-200 gigabytes using the new ScienceDirect OnSite (SDOS) 3.0 format, SGML, and graphics. The addition of Harcourt titles adds another 1.25 terabytes of storage requirements, for a grand total of nearly 7 terabytes of storage being required for all Elsevier Science content back to Volume One, Number One.</p>
<p>Although our e-archiving project is not yet working with non-journal electronic formats, it is worth noting that just as with Elsevier Science's publishing output, the new AP acquisitions include serials such as the Mosby yearbooks, various <hi rend="italics">Advances in</hi> . . ., and certain major reference works. The Yale team believes that this non-journal output is worthy of attention and also poses significant challenges.</p>
<p>After the acquisition, Ken Metzner, AP's Director of Electronic Publishing, was invited to attend project meetings; scheduling permitted him to participate only to a limited extent. Because of the relative newness of this additional content, the YEA team participants were unable to determine the specific impacts of the acquisition for our electronic archiving pursuits. Details will become clearer during 2002. What is clear  --  and has been all along, though not so dramatically  --  is that content of publishers is fluid, at least around the edges. Titles come and go; rights are gained and lost, bought and sold. Any archive needs carefully to consider its desiderata with regard to such normally occurring business changes and how contractual obligations must be expressed to accommodate them.</p>
</div5>
</div4>
</div3>

<div3 type="part" n="03"><head>Approaches and Assumptions</head>
<p>In January 2001, the Mellon Foundation approved a one-year planning grant for the Yale Library in partnership with Elsevier Science. The two organizations issued a press release and named members to the planning team. The work proceeded according to certain assumptions, some of which were identified very early in the process and others that evolved as we began to pursue various lines of inquiry. While it is not always easy to distinguish, one year into the planning process, assumptions from findings, we have made an effort to do so and to detail our <hi rend="italics">a priori</hi> assumptions here:</p>
<list>
<item>The digital archive being planned will meet long-term needs. The team adopted a definition of "long" as one hundred or more years. One hundred years, while rather less than the life of well cared for library print collections, is significantly more than any period of time that digital media have so far lasted or needed to last. Users of an electronic archive must be secure in the knowledge that the content they find in that archive is the content the author created and the publisher published, the same kind of assurance they generally have with print collections.</item>
<item>Accordingly, and given the rapid changes in technologies of all sorts, the archive has the responsibility to migrate content through numerous generations of hardware and software. Content can be defined as the data and discourse about the data that authors submit to the publisher. Content includes, as well, other discourse-related values added by the publisher's editorial process, such as revisions prompted by peer review or copy editing or editorial content such as letters, reviews, journal information and the like. Specifically, content might comprise articles and their abstracts, footnotes, and references, as well as supplementary materials such as datasets, audio, visual and other enhancements. For practical purposes, of course, the content consists of the finished product made available to readers.</item>
<item>The archive will not compete with the publisher's presentation of or functionality for the same content nor with the publisher's revenue stream. Functionality is defined as a set of further value-adding activities that do not have a major impact on the reader's ability to read content but may help the reader to locate, interact with, and understand the content. The YEA project will not concern itself with reproducing or preserving the different instances of publisher's or provider's functionality, because this functionality is very mutable and appears differently based on who delivers the content (publisher, vendor, aggregator, and so on). That is, an increasing number of journals, books, and other databases are provided through more than one source and thus multiple interfaces are already available, in many instances, for the same works.</item>
<item>Should the archive be seen as potentially competitive, the publisher would certainly have no incentive (and the authors might not have any incentive either) to cooperate with the archive by contributing to it, particularly content formatted for easy ingestion into the archive.</item>
<item>That said, some immediate uses of the archive seem desirable. We imagined that if/when the archive  --  or some portion of its offerings, such as metadata  --  could be conceived of as having rather different and possibly more limited uses than the primary, extensive uses the publisher's commercial service provides, the archive could be deployed early in its existence for those uses.</item>
<item>Once each set of data is loaded at regular, frequent intervals, the archive remains an entity separate from and independent of the publisher's production system and store. The publisher's data and the archive's data become, as it were, "fraternal twins" going their separate behavioral ways.</item>
<item>Such environmental separation enables the archive's content to be managed and rendered separately and to be migrated separately  --  and flexibly  --  over long periods of time, unencumbered by the formatting and production processes that the publisher needs to deploy for its own print and electronic dissemination.</item>
<item>The archive, accordingly, commits to preserving the author's content and does not make an effort to reproduce or preserve the publisher's presentation of the content, providing, at this time, basic functionality and content with no visible loss.  The YEA is committed at this point in time only to a minimum "no frills" standard of presentation of content.</item>
<item>Where extensive functionality is required, the YEA project assumes that functionality will be created  --  perhaps by the archive or by a separate contractor  --  when the time comes, and that the functionality will be created in standards applicable to that (present or future) time.</item>
<item>The archive does not, in general, create electronic content that does not exist in the publisher's electronic offering of the same content, even though such content may exist in the printed version of the journals. The archive is not intended to mimic the printed version. (For example, if the print journal includes "letters to the editor" and the e-journal version does not include these, the e-archive will not create them.</item>
<item>The archive will likely need to create metadata or other elements to define or describe the publisher's electronic content if the publisher has not provided these data during its production processes. However, it is desirable for the archive to create as few of these electronic elements as possible. The most accurate and efficient (and cost-effective) archive will be created if the publisher creates those data. This in turn indicates strongly the need both for industry-wide electronic preservation standards and close partnerships between archives (such as libraries) and publishers.</item>
<item>The archive will work with the publisher to facilitate at-source creation of all electronic elements. The archive will work with other similar publishers and archives to develop, as quickly as possible, standards for such elements, in order to deliver consistent and complete archive ingestion packages.</item>
<item>The archive will develop a system to ingest content regularly and frequently. In this way, it will record information identical to that generated by the authors and publishers. Any adjustments to content after ingestion into the archive will be added and identified as such.</item>
<item>At Yale, the e-journals archival system and site will be part of a larger digital store and infrastructure comprising and integrating numerous other digital items, many of which are already on site, such as internally (to the University and Library) digitized content, images, University records, born-digital acquisitions that are purchased rather than leased, finding aids, preservation re-formatting, the online catalog, and others. In this way, efficiencies and synergies can be advanced and exploited.</item>
<item>The archive will regularly and frequently "test" content, preferably both with automated systems that verify accuracy and completeness and with real users seeking content from the archive.</item>
<item>YEA team members assume that the archive may be searched by outside intelligent agents or harvesters or "bots," and that it must be constructed in a way that both facilitates such searching and at the same time respects the rights agreements that have been made with the copyright owners.</item>
<item>"Triggers" for ingestion are frequent and immediate; "triggers" for use of the archive are a different matter and will comply with rules developed between the publisher and the archive. These triggers would be identified during the course of the planning project.</item>
<item>The archive will be constructed to comply with emerging standards such as the OAIS model, certain metadata recommendations if possible, XML, and the like. Standards that enable data portability are key to YEA development.</item>
<item>The archive will be developed using, wherever possible, software tools as well as concepts being created in other institutions<!-- omit: (see later our use of the Urbana software and the OAI for a rough search engine, though note that there is concern on the part of publishers about using the OAI for retrieval)-->.</item>
</list>

<div4 type="subpart" n="01"><head>Notes About Archival Approaches and the Absolute Necessity for Standards in E-Archival Development</head>
<p>The assumptions listed above speak to four major activities of the YEA, which are 1) preservation planning, 2) administration of the archive, 3) access to the archive, and 4) ingestion of content. Like other Mellon research projects, the YEA defines activities associated with these processes within the context of the OAIS reference model of a digital archive. <hi rend="italics">A fortiori</hi>, the model also states that implementations will vary depending upon the needs of an archival community.</p>
<p>Research conducted during the planning year has identified four different approaches to preservation: emulation, migration, hard copy, and computer museums. These different approaches should not, however, be viewed as mutually exclusive. They can be used in conjunction with each other. Additionally, as we are not pursuing the present study as simply an academic exercise but rather, as a very practical investigation of what it will take to build, operate, and maintain a fully functioning production-mode digital archive, we cannot possibly discount the financial implications of the different approaches and the impact of standards on a choice of approach.</p>
<p>In choosing our approach, we quickly discounted both hard copy and computer museums. Hard copy decays over time and multimedia objects cannot be printed. Computer museums were also discounted as impractical. To function as an archive, computer museum equipment would need to be operational, not simply a collection of static exhibits. In turn, operation would lead to inevitable wear and tear on the equipment, with the consequential need for maintenance and repair work. When considering the repair of "antique" computer equipment, one has to ask about the source of spare parts   --   do all of them have to be hand-made at enormous expense? Even if money were available for such expensive work, does the "antique" equipment come with adequate diagnostic and testing equipment, wiring diagrams, component specifications, and the like, which would make the "museum" choice technically feasible in the first place? Even if the antique equipment were to receive only the most minimal usage, the silicon chips would deteriorate over time. In such a museum environment, one would question whether we would be in danger of losing our focus, ending up as a living history-of-computers museum rather than an archive of digital materials.</p>
<p>Rejecting hardcopy and museum options left the team with two very different approaches to the storage of content in an OAIS archive. One approach to content preservation is to store objects based upon emerging standards such as XML and then migrate them to new formats as new paradigms emerge. The other approach, advanced by and associated with one of its chief proponents, Marc Rothenberg, is to preserve content through emulation. Both approaches have potential and value, but probably to different subcultures in the archival community. A goal of standards is to preserve the essential meaning or argument contained in the digital object. Archives that are charged with the responsibility of preserving text-based objects such as e-journals are likely to adopt a migratory approach. Archives that need to preserve an exact replication or clone of the digital objects may choose, in the future, to deploy emulation as an archival approach. Both approaches are rooted in the use of standards. Contrary to an argument advanced in a research paper by Rothenberg,<note target="Yale05">[5]</note> YEA team members maintain that standards, despite their flaws, represent an essential component of any coherent preservation strategy adopted.</p>
<p>That said, Rothenberg criticized the use of migration as an approach to digital longevity. Rothenberg does make an insightful and enterprising case for the practice of emulation as the "true" answer to the digital longevity problem. The "central idea of the approach, " he writes, "is to enable the emulation of obsolete systems on future, unknown systems, so that a digital document's original software can be run in the future despite being obsolete." Rothenberg avers that only by preservation of a digital object's context   --   or, simply stated, an object's original hardware and software environment   --   can the object's originality (look, feel, and meaning) be protected and preserved from technological decay and software dependency.</p>
<p>The foundation of this approach rests on hardware emulation, which is a common practice in the field of data processing. Rothenberg logically argues that once a hardware system is emulated, all else just naturally follows. The operating system designed to run on the hardware works and software application(s) that were written for the operating system also work. Consequently, the digital object behaves and interacts with the software as originally designed.</p>
<p>However, emulation cannot escape standards. Processors and peripherals are designed with the use of standards. If the manufacturer of a piece of hardware did not adhere 100 percent to the standard, then the emulation will reflect that imperfection or flaw. Consequently, there is never a true solution, as suggested by Rothenberg, that a generalized specification for an emulator of a hardware platform can be constructed. In the data processing trenches, system programmers are well acquainted with the imperfections and problems of emulation. For example, the IBM operating system MVS never ran without problems under IBM's VM operating system. It was a good emulation but it was not perfect. Another major problem with emulation in a practical sense is its financial implications. The specification, development, and testing of an emulator require large amounts of very sophisticated and expensive resources.</p>
<p>At this stage, the YEA team believes the most productive line of research is a migratory approach based upon standards. Standards development must, therefore, feature front and center in the next phase of e-journal archiving activities. If one listens closely to academic discourse, the most seductive adverb of all is one not found in a dictionary; it is spelled "just" and pronounced "jist" and is heard repeatedly in optimistic and transparent schemes for making the world a better place. If scientists would "jist" insist on contributing to publishing venues with the appropriate high-minded standards of broad access, we would all be better off. If users would "jist" insist on using open source operating systems like Linux, we would all be better off. If libraries would "jist" spend more money on acquisitions, we would all be better off.</p>
<p>Many of those propositions are undoubtedly true, but the adverb is their Achilles' heel. In each case the "jist" masks the crucial point of difficulty, the sticking point to movement. To identify those sticking points reliably is the first step to progress in any realistic plan for action. In some cases, the plan for action itself is arguably a good one, but building the consensus and the commonality is the difficulty; in other cases, the plan of action is fatally flawed because the "jist" masks not merely a difficulty but an impossibility.</p>
<p>It would be a comparatively easy thing to design, for any given journal and any given publisher, a reliable system of digital information architecture and a plan for preservation that would be absolutely bulletproof  --  as long as the other players in the system would "jist" accept the self-evident virtue of the system proposed. Unfortunately, the acceptance of self-evident virtue is a practice far less widely emulated than one could wish.</p>
<p>It is fundamental to the intention of a project such as the YEA that the product  --  the preserved artifact  --  be as independent of mischance and the need for special supervising providence as possible. That means that, like it or not, YEA and all other seriously aspiring archives must work in an environment of hardware, software, and information architecture that is as collaboratively developed and as broadly supported as possible, as open and inviting to other participants as possible, and as likely to have a clear migration forward into the future as possible.</p>
<p>The lesson is simple: standards mean durability. Adhering to commonly and widely recognized data standards will create records in a form that lends itself to adaptation as technologies change. Best of all is to identify standards that are in the course of emerging, i.e., that appear powerful at the present moment and are likely to have a strong future in front of them. Identifying those standards has an element of risk about it if we choose the version that has no future,  but at the moment some of the choices seem fairly clear.</p>
<p>Standards point not only to the future but also to the present in another way. The well-chosen standard positions itself at a crossroads, from which multiple paths of data transformation radiate. The right standards are the ones that allow transformation into as many forms as the present and foreseeable user could wish. Thus PDF is a less desirable, though widely used, standard because it does not convert into structured text. The XML suite of technology standards is most desirable because it is portable, extensible, and transformative: it can generate everything from ASCII to HTML to PDF and beyond.</p>
</div4>
</div3>
</div2>

<div2 type="subsection" n="05"><head>Part II: Lines of Inquiry</head>
<div3 type="part" n="01"><head>Trigger Events</head>
<p>Makers of an archive need to be very explicit about one question: what is the archive for? The correct answer to that question is not a large idealistic answer about assuring the future of science and culture but a practical one: when and how and for what purpose will this archive be put to use? Any ongoing daily source needs to be backed up reliably, somewhere away from the risks of the live server, and <hi rend="italics">that</hi> backup copy becomes the <hi rend="italics">de facto</hi> archive and the basis for serious preservation activities.</p>
<div4 type="subpart" n="01"><head>Types of Archives</head>
<p>The team discovered during the course of its explorations that there is no single type of archive. While it is true that all or most digital archives might share a common mission, i.e., the provision of permanent access to content, as we noted in our original proposal to the Mellon Foundation, "This simple truth grows immensely complicated when one acknowledges that such access is also the basis of the publishers' business and that, in the digital arena (unlike the print arena), the archival agent owns nothing that it may preserve and cannot control the terms on which access to preserved information is provided."</p>
<p>In beginning to think about triggers, business models, and sustainability, the project team modeled three kinds of archival agents. The first two types of archives include a <hi rend="italics">de facto</hi> archival agent, defined as a library or consortium having a current license to load all of a publisher's journals locally, or a self-designated archival agent. Both of these types are commercial transactions, even though they do not conduct their business in the same ways or necessarily to meet the same missions. The third type of archive is a publisher-archival agent partnership and the focus of our investigation. Whether this type can now be brought into existence turns on the business viability of an archive that is not heavily accessed. Project participants varied in their views about whether an archive with an as yet uncertain mission can be created and sustained over time and whether, if created, an individual library such as Yale or a wide-reaching library enterprise like OCLC would be the more likely archival partner.</p>
</div4>

<div4 type="subpart" n="02"><head>Accessing the Archive</head>
<p>So when does one access the archive? Or does one ever access it? If the archive is never to be accessed (until, say, material passes into the public domain, which currently in the United States is seventy years plus the lifetime of the author or rights holder), then the incentives for building it diminish greatly, or at least the cost per use becomes infinite. There is talk these days of "dark" archives, that is, collections of data intended for no use but only for preservation in the abstract. Such a "dark" archive concept is at the least risky and in the end possibly absurd.</p>
<p>Planning for access to the e-archive requires two elements. The less clearly defined at the present is the technical manner of opening and reading the archive, for this will depend on the state of technology at the point of need. The more clearly defined, however, will be what we have chosen to call "trigger" events. In developing an archival arrangement with a publisher or other rights holder, it will be necessary for the archive to specify the circumstances in which 1) the move to the archive will be authorized, which is much easier to agree to than the point at which 2) users may access the archive's content. The publisher or rights holder will naturally discourage too early or too easy authorization,  for then the archive would begin to attract traffic that should go by rights to the commercial source. Many rights holders will also naturally resist thinking about the eventuality in which they are involuntarily removed from the scene by corporate transformation or other misadventure,  but it is precisely such circumstances that need to be most carefully defined.</p>
<p>Project participants worked and thought hard to identify conditions that could prompt a transfer of access responsibilities from the publisher to the archival agent. These conditions would be the key factors on which a business plan for a digital archive would turn. The investigation began by trying to identify events that would trigger such a transfer, but it concluded that most such events led back to questions about the marketplace for and the life cycle of electronic information that were as yet impossible to answer. Team members agreed that too little is known about the relatively young business of electronic publishing to enable us now to identify definitively situations in which it would be reasonable for publishers to transfer access responsibility to an archival agent.</p>
</div4>

<div4 type="subpart" n="03"><head>Possible Trigger Events</head>
<p>That said, some of the possible trigger events identified during numerous discussions by the project team were:</p>
<p><hi rend="bold">Long-term physical damage to the primary source.</hi> Note that we have not imagined the e-journal archive to serve as a temporary emergency service. We expect formal publishers to make provision for such access. Nevertheless, in the case of cataclysmic event, the publisher could have an agreement with the archive that would allow the publisher to recopy material for ongoing use.</p>
<p><hi rend="bold">Loss of access or abdication of responsibility for access by the rights holder or his/her successor, or no successor for the rights holder is identified.</hi> In other words, the content of the archive could be made widely available by the archive if the content is no longer commercially available from the publisher or future owner of that content. We should note that at this point in time, we were not easily able to imagine a situation in which the owner or successor would not make provision precisely because in the event of a sale or bankruptcy, content is a primary transactional asset. But that is not to say that such situations will not occur or that the new owner might not choose to deal with the archive as, in some way, the distributor of the previous owner's content.</p>
<p><hi rend="bold">Lapse of a specified period of time.</hi> That is, it could be negotiated in advance that the archive would become the primary source after a negotiated period or "moving wall," of the sort that JSTOR has introduced into the e-journal world's common parlance. It may be that the "free science" movement embodied in PubMed Central or Public Library of Science might set new norms in which scientific content is made widely available from any and all sources after a period of time, to be chosen by the rights owner. This is a variant on the "moving wall" model.</p>
<p><hi rend="bold">On-site visitors</hi>. Elsevier, our partner in this planning venture, has agreed that at the least, its content could be made available to any onsite visitors at the archive site, and possibly to other institutions licensing the content from the publisher. Another possibility is provision of access to institutions that have previously licensed the content. This latter option goes directly to development of financial and sustainability models that will be key in Phase II.</p>
<p><hi rend="bold">Archival Uses</hi>. Elsevier is very interested in continuing to explore the notion of so-called "archival uses" which represent uses very different to uses made by current subscribers in support of today's active science. Elsevier has stated that if we can identify such "archival uses," it might be willing to consider opening the archive to those. Some such uses might be studies in the history, sociology, or culture of sciences, for example. This thread in our planning processes has motivated the YEA team to devote some time to early exploration of archival uses with a view to expanding and deepening such exploration in Phase II.</p>
<p><hi rend="bold">Metadata Uses</hi>. In the course of preservation activity it could be imagined that new metadata elements and structures would be created that would turn out to have use beyond the archive. Appropriate uses of such data would need to be negotiated with the original rights holder.</p>
</div4>
</div3>

<div3 type="part" n="02"><head>Some Economic Considerations</head>
<p>Economic considerations are key to developing systems of digital archives. Accordingly, in our proposal, the Yale Library expressed its intention better "to understand the ordinary commercial life cycle of scientific journal archives..." In that proposal, our list of additional important questions included concerns about costs of creating and sustaining the archive, as well as sources of ongoing revenues to support the archive. While the issues of sustainability lurked in our thinking throughout the project, we determined relatively early on that the time was not right substantively to address these matters because we had as yet insufficient data and skill to make any but the very broadest of generalizations. But, that lack of hard data did not stop the group from discussing and returning frequently to economic matters.</p>
<p>Neither were the views of various individuals and organizations of definitive help to us. For example, the best study about e-archiving known to us attempted to analyze costs, but the information is somewhat dated.<note target="Yale06">>[6]</note> A large school of thought affirms that e-archives and even e-journal archives will be immensely expensive to develop and maintain, perhaps impossibly so. Some of the arguments include:</p>
<p><hi rend="bold">Huge Costs.</hi> Formal publishers' e-journal titles, i.e., those presented in fairly "standard" formats, will be very costly to archive because even those publishers do not provide clean, consistent, fully tagged data. Accordingly, the e-archive will have to perform significant repair and enhancement, particularly in the ingestion process; e.g., the creation of the Submission Information Package (SIP) will be particularly expensive. Furthermore, this reasoning goes, as the size, variety, and complexity of the content increases, associated costs will rise, as they will whenever formats need to be migrated and as storage size increases.</p>
<p>The universe of e-journals  --  which includes a great volume as well as diversity of subjects and formats, including Web sites, newsletters, dynamic publications, e-zines, and scholarly journals, and includes a huge variety of possible technical formats  --  will surely be difficult and costly to archive when one considers that universe as a whole.</p>
<p><hi rend="bold">Information Will Be Free</hi>. On the other hand, a great deal of today's "popular" scientific literature, promulgated by working scientists themselves, argues that electronic archiving is very cheap indeed. Proponents of this optimistic line of argument reason that colleges, universities, research laboratories, and the like already support the most costly piece of the action: that electronic infrastructure comprises computers, internal networks, and fast links to the external world, and institutions are obligated in any case aggressively to maintain their investments and frequently to update them. That being the case, the reasoning is that willing authors can put high quality material "out there," leaving it for search engines and harvesters to find. In such arguments, the value-adding services heretofore provided by editors, reviewers, publishers, and libraries are doomed to obsolescence and are withering away even as this report is being written.</p>
<p>Our guess is that the "truth" will be found to lie in between those two polarities, but of course that guess is a little glib and perhaps even more unfounded than the above arguments.</p>
<p>Even though during the planning year we were unable to make economic issues a topic of focused inquiry, we have begun to develop specific and detailed costs for building the YEA for e-journals in preparation for the next granting phase, and those calculations are starting to provide us with a sense of scale for such an operation. In addition, throughout the year, team members articulated certain general views about the economics of e-journal archives, which we share here below.</p>
<div4 type="subpart" n="01"><head>Five Cost Life-Cycle Stages of an e-Journal Archive</head>
<p>The task of archiving electronic journals may be divided into five parts: the difficult part (infrastructure development and startup), the easier part (maintenance), the sometimes tricky part (collaborations and standards), the messy part (comprehensiveness), and the part where it becomes difficult again (new technologies, migration).</p>
<list>
<item><hi rend="bold">The difficult part (development and startup).</hi> Initial electronic archiving efforts involve such activities as establishing the data architecture, verifying a prototype, validating the assumptions, and testing the adequacy of the degree of detail of realization. The magnitude and complexity of the issues and the detail involved in e-journal archiving are considerable. That said, it does not lie beyond the scope of human imagination, and the big lesson we have learned in this planning year is that it is indeed possible to get one's arms around the problem,  and that several different projects have discovered more or less the same thing in the same time period. In fact, Yale Library is already involved in other types of archiving projects related to several other digital initiatives. The greatest difficulties do not lie in having to invent a new technology, nor do they lie in coping with immense magnitudes. Rather, they reside in resolving a large, but not unimaginably large, set of problems in an adequate degree of detail to cope with a broad range of possibilities.</item>
<item><hi rend="bold">The easier part (ongoing maintenance and problem resolution).</hi> Where we are encouraged is in believing that once the first structure-building steps have been taken, the active operationalization and maintenance of an e-journal archiving project, in partnership with one or more well-resourced and cooperative publishers, can become relatively straightforward, particularly as standards develop to which all parties can adhere. There will be costs, but after start-up many of these will be increasingly marginal costs to the act of publishing the electronic journal in the first place. For new data being created going forward, attaching appropriate metadata and conforming to agreed standards will require up-front investment of time and attention, especially retrofitting the first years of journals to standards newly enacted, but once that is done, the ongoing tasks will become more transparent. In theory, the hosting of the archive could be part and parcel of the operational side of the publishing, and the servers and staff involved in that case would most likely be the same people involved in the actual publication. Alternately, as we imagine it, the long-term archiving piece of business will be taken aboard by existing centers distributed among hosting universities with similar synergies of costs.</item>
<item><hi rend="bold">The tricky part (collaboration and standards).</hi> Because different people and organizations in different settings have been working on electronic preservation issues for the last few years, there may already be appreciable numbers of similar but nonidentical sets of solutions coming to life. Working around the world to build sufficient communities of interest and standards to allow genuinely interoperable archives and real standards will take a great deal of "social work." Every archive will continue to devote some percentage of its operation to external collaborations driven by the desire to optimize functional interoperability.</item>
<item><hi rend="bold">The messy part (comprehensiveness)</hi>. There will be a fair number of journals that either choose not to cooperate or are financially or organizationally ill-equipped to cooperate in a venture of the scope imagined. It will be in the interest of the library and user communities generally to identify those under-resourced or recalcitrant organizations and find the means   --   financial, organizational, political  --  to bring as many of them aboard as possible. It may prove to be the case that 90 percent of formal publishers' journals can be brought aboard for a modest price, and the other 10 percent may require as much money or more to come in line with the broader community.</item>
<item><hi rend="bold">The part where it becomes difficult  --  and probably very expensive  --  again (migration).</hi> The solutions we now envision will sustain themselves only as long as the current technical framework holds. When the next technological or conceptual revolution gives people powers of presentation they now lack and that do not allow themselves to be represented by the technical solutions we now envision, then we will require the next revolution in archiving. The good news at that point is that some well-made and well-observed standards and practices today should be able to be carried forward as a subset of whatever superset of practices need to be devised in the future. Elsevier Science has a foretaste of this in its current, very costly migration to XML.</item>
</list>
<p>Needless to say, the above overview is somewhat simplified. For example, in our planning year, we were surprised to find just how few of the 1,100+ Elsevier e-journal titles carried complex information objects, compared to what we expected to find. Complex media, data sets, and other electronic-only features exist that have yet to find their place as regular or dominant players in e-journals, and creating ways to deal with these types of digital information  --  let alone standard ways  --  will be costly, as are all initial structural activities (see #1 above).</p>
</div4>

<div4 type="subpart" n="02"><head>Cost-Effective Collaboration and Organization for e-Archiving</head>
<p>That said, it appears that willing collaborators have yet a little time both to address and to solve the hefty problems of presenting and archiving complex digital information objects. To archive a single e-journal or small set of journals is to do relatively little. But to develop standards that will serve e-preservation well   --   let alone to facilitate access to the most simple of e-archives that begin to bloom like a hundred flowers   --   all the players will need to work together. We imagine an aggregation of archiving efforts, whether in physical co-location or at least virtual association and coordination.</p>
<p>But how might such archival universes be organized?</p>
<list>
<item> Archives could be subject-based, arranged by discipline and subdiscipline. Such an arrangement would allow some specialization of features, easier cross-journal searching, and creation of a community of stakeholders.</item>
<item>Archives could be format-based. This arrangement would probably overlap with subject-based arrangement in many fields, would be easier to operate and manage, but would sacrifice at least some functionality for users   --   an important consideration, given that archival retrieval is likely to occur in ways that put at least some demand on users to navigate unfamiliar interfaces.</item>
<item>Archives could be publisher-based. Such an arrangement would offer real conveniences at the very outset, but would need close examination to assure that standards and interoperability are maintained against the natural interest of a given rights holder to cling to prerogatives and privileges.</item>
<item>Archives could be nationally-based. Australia, Japan, Canada, Sweden, and other nations could reasonably feel that they have a mission to preserve their own scientific and cultural products and not to depend on others.</item>
<item>Archives could be organized entrepreneurially by hosts. This is probably the weakest model, inasmuch as it would create the least coherence for users and searching.</item>
</list>
<p>Each of these alternate universes has its own gravitational force and all will probably come into existence in one form or another. Such multiplicity creates potentially severe problems of scalability and cost. One remedy could be for official archives to operate as service providers feeding other archives. Hence, a publisher's agreed archive could feed some of its journals to one subject-based archive and others to national archives.</p>
<p>One way to begin to anticipate and plan for this likely multiplicity would be to create a consortium now of interested parties to address the difficult issues such as redundancy, certification, economic models, collection of fees, standards, and so on. No one organization can solve these problems alone, but coordination among problem-solvers now and soon will be very cost-effective in the long run. In OCLC's proposal to create a digital preservation cooperative,<note target="Yale07">[7]</note> and, on a larger scale in the Library of Congress's recent National Digital Information Infrastructure Preservation Program,<note target="Yale08">[8]</note> we may be seeing the emergence of such movements. It may be possible to turn the Mellon planning projects into such an overarching group of groups.</p>
</div4>

<div4 type="subpart" n="03"><head>Who Will Pay and How Will They Pay?</head>
<p>No preservation ambitions will be realized without a sustainable economic model. As we have noted above, the costs of archiving are much in dispute and our study will examine those costs in great detail in the next phase. For now, it would appear that the initial costs are high, although manageable, and the ongoing costs, at least for standard publisher's journals, could be relatively predictable and eventually stable over time.</p>
<p>If that is true, then various models for paying for the archiving process suggest themselves. This is an area about which there has been much soft discourse but in which there has been little experience, save perhaps for JSTOR whose staff have given the topic a great deal of thought.</p>
<p><hi rend="bold">Up-front payment</hi>. The most dramatic and simple way to finance the e-journal archives would be the "lifetime annuity model": that is, users (presumably institutional entities, such as libraries, professional societies, governments, or cultural institutions, but some speak of enhanced "page charges" from authors or other variants on current practices) pay for a defined quantum of storage and with that one-time payment comes an eternity of preservation. The up front payment would be invested partly in ongoing archival development and partly in an "endowment" or rainy day fund. The risk in this case is that inadequate funding may lead to future difficulties of operation.</p>
<p><hi rend="bold">Ongoing archival fees</hi>. An "insurance premium" on the other hand could give an ongoing supply of money, adjustable as costs change, and modest at all stages. This reduces the risk to the provider but increases the uncertainty for the beneficiary. The ongoing fee could be a visible part of a subscription fee or a fee for services charged by the archive.</p>
<p><hi rend="bold">The traditional library model</hi>. The library (or museum or archive) picks up the tab and is funded by third-party sources.</p>
<p><hi rend="bold">Fee for services operation</hi>. The archive provides certain services (special metadata, support for specialized archives) in return for payments.</p>
<p><hi rend="bold">Hybrid</hi>. If no single arrangement seems sufficient   --   as it likely will not   --   then a hybrid system likely will emerge, perhaps with one set of stakeholders sharing the up-front costs while another enters into agreement to provide ongoing funding for maintenance and potential access.</p>
<p>Much more could be said on the topic of who pays but at the moment most of it would be speculation. The choice of models will influence development of methods for paying fees and the agents who will collect those fees. Before making specific recommendations it will be important for our project to develop a much more specific sense of real costs of the e-archive. We imagine that we might want to develop both cost and charging models in conjunction with other libraries, i.e., prospective users of the archive. In Yale's case the collaborative effort might happen with our local electronic resource licensing consortium NERL.</p>
</div4>
</div3>

<div3 type="part" n="03"><head>Contract Between the Publisher and the Archive</head>
<p>Publishers and librarians have reluctantly grown accustomed to having licenses that articulate the terms and conditions under which digital publications may be used. These licenses are necessary because in their absence the uses to which digital files could be put would be limited by restrictions (and ambiguities) on reproduction and related uses that are intrinsic within copyright law. Licenses clarify ambiguities and often remove, or at least significantly reduce, limitations while also acknowledging certain restrictions on unlimited access or use.</p>
<p>A licensing agreement between a digital information provider and an archival repository presents several unique challenges not generally faced in the standard licensing agreement context between an information provider and an end-user. Discussed below are several of the issues that must be addressed in any final agreement:</p>
<div4 type="subpart" n="01"><head>Issues</head>
<list>
<item>Term and termination. The perpetual nature of the intended agreement, even if "forever," is in fact, a relative rather than an absolute term. One has to think in funereal terms of "perpetual care" and of the minimum length of time required to make an archiving agreement reasonable as to expectations and investments. Some issues that need to be addressed are appropriate length of any such agreement, as well as provisions for termination of the agreement and/or "handing off" the archive to a third party. Underlying concerns of term and termination is the need to ensure that the parties' investments in the archive are sufficiently protected as well as that the materials are sufficiently maintained and supported.</item>
<item>Sharing responsibility between the archive and the digital information provider. There are elements of a service level agreement that must be incorporated into the license because the rights and responsibilities are different in an archival agreement than in a normal license. That is, an archive is not the same as a traditional end-user; in many ways the archive is stepping into the shoes of the digital information provider in order (eventually) to provide access to end-users. The rights and responsibilities of the archive will no doubt vary depending on when the material will become accessible and on whether there are any differentiations between the level and timing of access by end-users. This issue will have an impact on the level of technical and informational support each party is required to provide to end-users and to each other, as well responsibility for content  --  including the right to withdraw or change information in the archive  --  and responsibilities concerning protecting against the unauthorized use of the material.</item>
<item>Level and timing of access. While all licenses describe who are the authorized users, the parties to an archival agreement must try to anticipate and articulate the circumstances (i.e., "trigger events") under which the contents of the archive can be made available to readers, possibly without restriction. When the information will be transmitted to the archive and, more importantly, how that information is made available to end-users are also critical questions. Several models have been discussed and this may be an issue best addressed in detailed appendices reflecting particular concerns related to individual publications.</item>
<item>Costs and fees. The financial terms of the agreement are much different from those of a conventional publisher-user license. Though it is difficult to conceive of one standard or agreed financial model, it is clear that an archival agreement will have a different set of financial considerations from a "normal" license. Arrangements must be made for the recovery of costs for services to end-users, as well as any sharing of costs between the archive and the digital information provider. These costs may include transmission costs, the development of archive and end-user access software, and hardware and other costs involved in preserving and maintaining the data.</item>
<item>Submission of the materials to the archive. The issues of format of the deposited work ("submission") take on new considerations as there is a need for more information than typically comes with an online or even locally-held database. Describing the means for initial and subsequent transfers of digital information to the archive requires a balance between providing sufficient detail to ensure all technical requirements for receiving and understanding the material are met, while at the same time providing sufficient flexibility for differing technologies used in storing and accessing the materials throughout the life of the contract. One means of dealing with the submission issues is to provide in the agreement general language concerning the transmission of the materials, with reference to appendices that can contain precise protocols for different materials in different time periods. If detailed appendices are the preferred method for dealing with submission matters, mechanisms must be developed for modifying the specifics during the life of the agreement without triggering a formal renegotiation of the entire contract.</item>
<item>Integrity of the archive. The integrity and comprehensiveness of the archive must be considered. The contract must address the question: "If the publisher 'withdraws' a publication, is it also withdrawn from the archive?"</item>
</list>
</div4>

<div4 type="subpart" n="02"><head>Progress Made</head>
<p>YEA and Elsevier Science have come to basic agreement on what they would be comfortable with as a model license. In some areas alternatives are clearly available and other archival agencies working with other publishers will choose different alternatives. Reaching a general agreement was, however, surprisingly easy as the agreement flowed naturally out of the year-long discussions on what we were trying to accomplish. The current draft license is not supplied in this document because it has a number of "unpolished" areas and some unresolved details, but it could be submitted and discussed upon request.</p>
<p>The team made certain choices with regard to the contractual issues noted above:</p>
<list>
<item>Term. The team opted for an initial ten-year term with subsequent ten-year renewals This provides the library with sufficient assurance that its investments will be protected and assures the publisher that there is a long-term commitment. The team also recognized that circumstances can change and has attempted to provide for what we hope will be an orderly transfer to another archival repository.</item>
<item>Rights and responsibilities. The agreement includes statements of rights and responsibilities that are quite different from a traditional digital license. The publisher agrees, among other things, to conform to submission standards. The library agrees, among other things, to receive, maintain, and migrate the files over time.</item>
<item>Trigger events. Discussions of "trigger events" provided some of the most interesting, if also frustrating, aspects of the year. In the end, the only trigger event that all completely agreed upon was that condition under which the digital materials being archived were no longer commercially available either from the original publisher or someone who had acquired them as assets for further utilization. Given that it is quite hard to imagine a circumstance in which journal files of this magnitude would be judged to have no commercial value and would not be commercially offered, does it makes sense to maintain such an archive at all? Will money be invested year after year as a precaution or protection against an event that will never occur? Though the team agreed it is necessary to proceed with long-term electronic archival agreements, clearly serious issues are at stake.<lb/><lb/>
The team also identified a second side to the trigger question: if the archive were not going to be exposed to wide use by readers, how could the archival agent "exercise" it in order to assure its technical viability? This topic is discussed more fully in the "Trigger Events" section of the report. Briefly here, the team was concerned that a totally dark archive might become technically unusable over time and wanted to provide agreed upon applications that would make the archive at least "dim" and subject to some level of use, e.g., available to local authorized users. The second, perhaps more important, notion was that there would be archival uses that could be distinguishable from normal journal use. The team tried to identify such uses but so far have not received the feedback from the history of science community (for example) that we would have wished. Therefore, "archival uses" remain more theory than reality, but at the same time they represent a topic we are committed to exploring in the next phase of work. An alternative would be to have the archive serve as a service provider to former subscribers, but this changes the nature of the archive to being a "normal" host which could be a questionable consideration. These issues are not currently reflected in the draft license.</item>
<item>Financial terms were viewed as neutral at this time, i.e., no money would change hands. In our current thinking, the publisher provides the files without charge and the archival agency accepts the perpetual archiving responsibility without financing from the publisher. Obviously, one could argue that the publisher should be financing some part of this activity. However, in the longer term it is probably more realistic to develop alternative financing arrangements that are independent of the publisher.</item>
<item>Technical provisions. Early on, the team agreed on the OAIS model for submission and subsequent activities. The license reflects this in terms of the need to define metadata provided by the publisher. The specific metadata elements have not yet been finalized, however. This is also relevant in defining what use can be made by the archive of the metadata. Publishers such as Elsevier that have secondary publishing businesses want to be sure that those businesses are not compromised by an archive distributing abstracts for free, for example. The model license does not yet reflect this point but it is recognized as an issue.</item>
<item>Withdrawal of content. The current draft license provides for appropriate notices when an item is withdrawn by the publisher. The team has discussed and will likely incorporate into the license the notion that the archive will "sequester" rather than remove a withdrawn item.</item>
</list>
<p>The model license is still evolving and not yet ready for signature. However, there are no identified points of contention  --  only points for further reflection and agreement on wording. All the participants were very much pleased with the team's ability to come to early understandings of licensing issues and to resolve some of these at the planning stage. This success arises out of close working relationships and communications over about a year-and-a-half of cooperative effort.</p>
</div4>
</div3>

<div3 type="part" n="04"><head>Archival Uses of Electronic Scientific Journals</head>
<p>As part of its work, the Yale-Elsevier team began to investigate whether and how the uses of an archive of electronic journals would differ significantly from those of the active product distributed by the publisher. This investigation was launched to help determine what needed to be preserved and maintained in the archive; to inform the design of a discovery, navigation, and presentation mechanism for materials in the archive; and to determine the circumstances under which materials in the archive could be made available for research use without compromising the publisher's commercial interests.</p>
<p>The group reviewed traditional archival theory and practice and began preliminary consultations with historians of science and scholarly communication to understand past and contemporary uses of scientific journal literature. A number of issues became particularly significant in the group's discussions: the selection of documentation of long-term significance, the importance of topological and structural relationships within the content, and the importance of the archive as a guarantor of authenticity.</p>
<div4 type="part" n="01"><head>Selection and Appraisal</head>
<p>The first area in which there might be useful approaches is that of archival appraisal, i.e., the selection of those materials worth the resources needed for their long-term preservation and ongoing access. Archival appraisal considers the continuing need of the creating entity for documentation in order to carry out its mission and functions and to maintain its legal and administrative accountability, as well as other potential uses for the materials. These other uses generally fall into the category of support for historical research, although there may be others such as establishing and proving the existence of personal rights which may also be secondary to the original purpose of the documentation in question.</p>
<p>Archivists also consider the context of the documentation as well as its content in determining long-term significance. In some cases, the significance of the documentation lies in the particular content that is recorded; the presentation of that content is not critical to its usefulness or interpretation. The content of the documentation can be extracted, put into other applications, and made to serve useful purposes even as it is divorced from its original recording technology and form. In other cases, however, the role of documentation as evidence requires that the original form of the document and information about the circumstances under which it was created and used also be preserved in order to establish and maintain its authenticity and usefulness.</p>
<p>With these selection approaches in mind, a number of issues arose in the e-journal archiving context and in the work of the team. The first question was whether it was sufficient for the archive to preserve and provide access to "just" the content of the published material  --  primarily text and figures  --  in a standard format, which might or might not be the format in which the publisher distributed the content. Preserving only the content, insofar as that is possible, foregoes the preservation of any functionality that controlled and facilitated the discovery, navigation, and presentation of the materials on the assumption that functionality was of little or no long-term research interest. The decision to preserve content only would eliminate the need to deal with changing display formats, search mechanisms and indices, and linking capabilities.</p>
<p>While the group has adopted this narrow definition of the scope of the archive as a working assumption, such a narrow approach does preclude the study of the diplomatics of these documents  --   "digital paleography," as one of our advisors termed it. How essential to future researchers' interpretations of the use of these documents is it for them to know what tools contemporary users had available to them, e.g., indices that did not address particular components of the document, thus making them unfindable through the publisher's interface? At the conclusion of the planning period the team had not changed the main focus of its attention on content, but it was sufficiently intrigued by the issues of digital paleography that it will propose that this assumption be investigated more thoroughly in its implementation proposal.</p>
<p>The long-held approach in the archival profession governing how archives are organized, described, and provided to users once they become part of the repository's holdings is deeply informed by the principle of provenance and the rules that flow from it: <hi rend="italics">respect des fonds</hi> (records of a creator should remain together) and original order (which has significance for the interpretation of records and should be preserved whenever possible). These principles reflect the nature of archival records. They are by-products created by an organizational entity in the course of carrying out its functions. The primary significance of the records is as evidence of those functions and activities. These principles reflect the needs of research for bodies of materials that are as strongly evidential as possible and reflect minimal interaction by custodial agencies other than the creator. The assumption is that solid historical research and interpretation require knowledge of the circumstances under which the materials were created and maintained and not just access to the raw content.</p>
<p>Access to archival materials is often characterized by two factors that take advantage of the provenance approach. Searches are often conducted to document a particular event or issue rather than for a known item; they may also be based on characteristics of the creators rather than on characteristics of the records themselves. Comprehensive and accurate recording of the circumstances of creation, including characteristics of records creators and the relationships among them, are central parts of archival description. The implications for developing an approach to downstream uses of e-journal literature include the potential need of contextual metadata regarding the authors and other circumstances affecting the publication of a given article/issue that are not found in a structured way in the published materials. Information regarding the context in which the article was submitted, reviewed, and edited for publication is important in studies of scholarly communication, especially as to questions of how institutional affiliations might be important in certain lines of inquiry and who had the power to accept or reject submissions.</p>
<p>Some of this information is explicitly disseminated in online products, e.g., in the form of members of an editorial board or descriptions of the purpose and audience of the journal, but it may be presented separately from any particular volume, issue, or article; may reflect only current (and not historic) information; and is rarely structured or encoded in such a way as to facilitate its direct use in scholarly studies. Other information about the context of creation and use that historians of science might find useful is not published; rather, it is found in the publisher's records of the review process and circulation figures. Capturing and linking of title-level publication information are additional areas of investigation that the team intends to pursue in its implementation proposal.</p>
</div4>

<div4 type="subpart" n="02"><head>Preservation of Structural Information</head>
<p>The mass of archival records that repositories select for long-range retention and are responsible for, and the imperative of the principle of provenance to maintain and document the recordkeeping system in which the records were created and lived, combine to foster the archival practice of top-down, hierarchical, and collective description. This type of descriptive practice provides both a way of reflecting the arrangement of the original recordkeeping system and of allowing the archival agency to select for each body of records the level beyond which the costs of description outweigh the benefits of access, and completing its descriptive work just before that point is achieved.</p>
<p>This principle and practice highlight for scientific journals the importance of preserving the relationship among the materials that the publisher was distributing, especially the need to link articles that the publisher presented as a "volume," "special issue," or some other sort of chronological or topical grouping. These relationships represent another form of contextual information important to the study of scholarly communications, in terms of which articles were released simultaneously or in some other relationship to each other. While the team recognized the need to be aware of new forms of publishing that would not necessarily follow the traditional patterns adopted by the hard-copy print world, it asserted that those structures do need to be saved as long as they are used.</p>
<p>With respect to other methods of navigating among digitally presented articles, such as linking to articles cited, the team found that many of these capabilities existed not as part of the content, but as added functionality that might be managed by processes external to the content or to the publisher's product (e.g. CrossRef). The team felt that these capabilities should be preserved as part of the archive, necessitating the need to maintain an enduring naming scheme for unambiguous identification of particular pieces. The plan for the implementation project will include a closer look at the requirements for supporting important navigational capabilities.</p>
</div4>

<div4 type="subpart" n="03"><head>Guaranteeing Authenticity</head>
<p>Finally, the authenticity of any document that purports to be evidence rests in some part on a chain of custody that ensures that the document was created as described and that it has not been altered from its original form or content. Once an archival agency takes charge of documentation it is obligated to keep explicit records documenting the circumstances of its transfer or acquisition and any subsequent uses of it. Records are rarely removed, either for use or retrospective retention by an office, but when this is necessary the circumstances of that action need to be documented and available. This assumption, along with the unique nature and intrinsic value of the materials, leads to the circumstance of secure reading rooms for archival materials and all of the security paraphernalia associated with them, as well as to detailed recordkeeping of use and work performed on the records.</p>
<p>The assumption that the archival agency is responsible for preserving the "authentic" version of documentation suggests that transfer of content to the official archival agency should take place as soon as the publisher disseminates such content, and that once placed into the archive content will not be modified in any way. This includes instances of typographical errors, the release of inaccurate (and potentially dangerous) information, or the publication of materials not meeting professional standards for review, citation, and similar issues. Instead, the archive should maintain a system of errata and appropriate flagging and sequestering of such materials that were released and later corrected or withdrawn, ensuring that the record of what was distributed to the scholarly community, however flawed, would be preserved.</p>
<p>Issues related to authenticity also suggest that one circumstance under which transferred content could be released, even while the publisher retains a business interest in it, is when questions are raised as to the authenticity of content still available under normal business arrangements. Longer-term safeguards will need to be in place within the archival repository to ensure the authenticity of the content.</p>
<p>Other issues relating to the nature and mission of an archival repository appear elsewhere in this report, especially in the discussion of trigger events. The issues discussed in this section, however, are especially germane to the question of how anticipated use of preserved electronic journals should inform the selection of materials. The Yale-Elsevier team has found many archival use topics central to the definition and purpose of an archive for electronic journals and plans to pursue them more completely in the implementation project.</p>
</div4>
</div3>

<div3 type="part" n="05"><head>The Metadata Inquiry</head>
<div4 type="subpart" n="01"><head>The Role of Metadata in an e-Archive</head>
<p>It is impossible to create a system designed to authenticate, preserve, and make available electronic journals for an extended period of time without addressing the topic of metadata. "Metadata" is a term that has been used so often in different contexts that it has become somewhat imprecise in meaning. Therefore, it is probably wise to begin a discussion of metadata for an archival system by narrowing the array of possible connotations. In the context of this investigation, metadata makes possible certain key functions:</p>
<list>
<item>Metadata permits search and extraction of content from an archival entity in unique ways (descriptive metadata). Metadata does this by describing the materials (in our case journals and articles) in full bibliographic detail.</item>
<item>Metadata also permits the management of the content for the archive (administrative metadata) by describing in detail the technical aspects of the ingested content (format, relevant transformations, etc.), the way content was ingested into the archive, and activities that have since taken place within the archive, thereby affecting the ingested item.</item>
</list>
<p>Taken together, both types of metadata facilitate the preservation of the content for the future (preservation metadata). Preservation ensures the retrievability of protected materials, their authentication, and their content.</p>
<p>Using metadata to describe the characteristics of an archived item is important for a number of reasons. With care, metadata can highlight the sensitivity to technological obsolescence of content under the care of an archival agency (i.e., items of a complex technical nature that are more susceptible to small changes in formats or browsers.) Metadata can also prevent contractual conflicts by pinpointing issues related to an archived item's governance while under the care of an archive; e.g., "the archive has permission to copy this item for a subscriber but not for a nonsubscriber." Finally, metadata can permit the archival agency to examine the requirements of the item during its life cycle within the archive; e.g., "this object has been migrated four times since it was deposited and it is now difficult to find a browser for its current format."<note target="Yale09">[9]</note></p>
<p>The Open Archival Information System (OAIS) model to which the YEA project has chosen to conform refers to metadata as preservation description information (PDI). There are four types of PDI within OAIS: 1) reference information, 2) context information, 3) provenance information, and 4) fixity information. Not all of these forms of PDI need be present in the Submission Information Package (SIP) ingested by the archive, but they all must be a part of the Archival Information Package (AIP) stored in the archive. This implies that some of these PDI elements are created during ingestion or input by the archive.</p>
<p>Reference Information refers to standards used to define identifiers of the content. While YEA uses reference information and supplies this context in appendices to our metadata element set, we do not refer to it as metadata. Context Information documents the relationships of the content to its environment. For YEA, this is part of the descriptive metadata. Provenance Information documents the history of the content including its storage, handling, and migration. Fixity Information documents the authentication mechanisms and provides authentication keys to ensure that the content object has not been altered in an undocumented manner. Both Provenance and Fixity are part of administrative metadata for YEA.</p>
<p>Given the focus YEA has chosen to place on a preservation model that serves as an archive as well as a guarantor for the content placed in its care, authenticity was an issue of importance for the group to explore. In its early investigations, the team was much struck by the detailed analysis of the InterPARES project on the subject of authenticity. While some of the InterPARES work is highly specific to records and manuscripts  --  and thus irrelevant to the journal archiving on which YEA is focusing  --  some general principles remain the same. It is important to record as much detail as possible about the original object brought under the care of the archive in order both to prove that a migrated or "refreshed" item is still the derivative of the original and to permit an analysis to be conducted in the future about when and how specific types of recorded information have changed or are being reinvented, or where totally new forms are emerging.<note target="Yale10">[10]</note></p>
<p>Finally, as YEA has examined the issue of metadata for a system designed to authenticate, preserve, and make available electronic journals for an extended length of time, we have tried to keep in mind that metadata will not just be static; rather, metadata will be interacted with, often by individuals who are seeking knowledge. To this end, we acknowledge the four issues identified by the International Federation of Library Associations and Institutions (IFLA) in the report on functional requirements for bibliographic records: metadata exist because individuals want to find, identify, select, or obtain informational materials.<note target="Yale11">[11]</note></p>
</div4>

<div4 type="subpart" n="02"><head>The Metadata Analysis</head>
<p>YEA began its analysis of needed metadata for a preservation archive of electronic journals by conducting a review of extant literature and projects. In this process the team discovered and closely explored a number of models and schemes. The first document  --  and the one we returned to most strongly in the end  --  described the OAIS model, although OAIS provides only a general framework and leaves the details to be defined by implementers.<note target="Yale12">[12]</note> We also examined the Making of America's testbed project white paper<note target="Yale13">[13]</note> and determined it was compatible with OAIS. Next, we examined the 15 January 2001 RLG/OCLC Preservation Metadata Review document<note target="Yale14">[14]</note> and determined that while all of the major projects described (CEDARS, NEDLIB, PANDORA) were compliant with the OAIS structure, none of them had the level of detail, particularly in contextual information, that we believed necessary for a long-term electronic journal archive. We also explored the InterPARES project (mentioned above) and found there a level of detail in contextual information that we had not seen delineated in the RLG/OCLC review of the other projects.</p>
<p>At the same time, the library and publisher participants in the project were exploring the extant metadata sets used by Elsevier Science to transport descriptions of their journal materials for their own document handling systems and customer interfaces. In addition to their EFFECT standard (see section describing Elsevier Science's Technical Systems and Processes), we also examined portions of the more detailed Elsevier Science "Full Length Article DTD 4.2.0."<note target="Yale15">[15]</note> Due to the solid pre-existing work by Elsevier Science in this area and the thorough documentation of the metadata elements that Elsevier Science is already using, we were able to proceed directly to an analysis of the extant Elsevier metadata to determine what additional information might need to be created or recorded during production for and by YEA.</p>
<p>About halfway through the project year, the team made connections with British Library staff who were themselves just completing a metadata element set definition project and who generously shared with the team their draft version. While the British Library draft document was more expansive in scope than the needs of the YEA project (i.e., the British Library document covers manuscripts, films, and many other items beyond the scope of any e-journal focus), the metadata elements defined therein and the level of detail in each area of coverage were almost precisely on target for what the e-archiving team sought to create. Thus, with the kind consent of contacts at the British Library, the team began working with the draft, stripping away unneeded elements, and inserting some missing items.</p>
<p>In the fall of 2001, the YEA team committed to creating a working prototype or proof-of-concept which demonstrated it would indeed be possible to ingest data supplied by Elsevier Science into a minimalistic environment conducive to archival maintenance. The prototype-building activity briefly diverted the metadata focus from assembling a full set of needed elements for the archival system to defining a very minimal set of elements for use in the prototype. The technical explorations of the prototype eventually led us to simply use the metadata supplied by Elsevier and the prototype metadata element set was never used. The one remaining activity associated with metadata performed for the prototype was to map the Elsevier EFFECT metadata to Dublin Core so that it could be exposed for harvesting.</p>
<p>Once the prototype subset element set was identified, YEA returned to the question of a complete metadata element set for a working archive. As the British Library draft document was examined, reviewed, and assessed, many decisions were made to include or exclude elements, particularly descriptive metadata elements. These decisions were informed in part by the recurring theme of whether the presence of such an item of information would assist individuals performing inquiries of the archive. The questions related to uses of scholarly journal materials for archival explorations are dealt with more fully elsewhere in this report.</p>
<p>The full metadata element set was completed by YEA as a recommended set of metadata to be used in a future full archive construction. It is important to reiterate that our approach to producing this set of metadata was inclusive. In creating an archival architecture it is not enough to delineate the descriptive metadata that must be acquired from the publisher or created by the archive while leaving out the administrative metadata elements that permit the archive to function in its preserving role. Neither is it sufficient to focus on the administrative metadata aspects that are unique to an archive while setting aside the descriptive metadata elements, i.e., assuming they are sufficiently defined by other standards. Preservation metadata are the conflation of the two types of metadata and, in fact, both types of metadata work jointly to ensure the preservation of and continuing access to the materials under the care of the archive.</p>
<p>One other fact may be of interest to those reviewing the description of metadata elements for the YEA: where possible, we used external standards and lists as materials upon which the archive would depend. For example, we refer to the DCMI-Type Vocabulary<note target="Yale16">[16]</note> as the reference list of the element called "resource type."</p>
<p>We certainly do not expect that the element set created by YEA will proceed into implementation in a future full archive construction without any further changes. It will undoubtedly be influenced by work done by other groups such as the <hi rend="italics">E-Journal Archive DTD Feasibility Study</hi><note target="Yale17">[17]</note> prepared for the Harvard University Library e-journal archiving project. However, we now have a reference by which to assess whether proposed inclusions, exclusions, or modifications fit the structure we imagine an archive will need properly to preserve electronic journals.</p>
</div4>

<div4 type="subpart" n="03"><head>Metadata in Phase II</head>
<p>In the next phase of the e-archiving project, the YEA desires further to define and refine metadata needed for a system designed to authenticate, preserve, and make available electronic journals for an extended period of time. We will need to connect with others working informally or formally to create a standard or standards for preservation metadata. As noted above, further investigations may influence a revision to the initial metadata set defined during the planning phase. Additionally, we intend to rework the element set into an XML schema for Open Archives Initiative (OAI) manifestation and harvesting. With our small prototype, we have demonstrated that OAI harvesting can occur from the simple Dublin Core metadata set to which we mapped the Elsevier EFFECT elements. However, OAI interaction can occur much more richly if a fuller dataset is in use, and we intend to accomplish this schema transformation to enable fuller interaction with the archive as it develops.<note target="Yale18">[18]</note></p>
<p>As the next phase moves forward, another avenue of exploration will be to assess and examine our metadata element choices in a live environment. We are most particularly interested in testing those elements included or excluded on the basis of assumptions made regarding the likelihood of archival inquiries targeting specific elements for exploration. Such choices can only be validated over time and with the interaction of individuals conducting authentic research into the history of their fields. Finally, we look forward to testing our element choices for administrative metadata under the stress of daily archive administration and maintenance. Only in such a live environment can an archive be truly confirmed as a functioning entity for preserving the materials under its care.</p>
</div4>
</div3>

<div3 type="part" n="06"><head>Elsevier Science's Technical Systems and Processes</head>
<div4 type="subpart" n="01"><head>Introduction</head>
<p>Elsevier Science is a major producer of scholarly communication and scientific journals that are distributed globally. The headquarters for production, along with the electronic warehouse, is located in Amsterdam, Netherlands. There the company maintains two office buildings and deploys several hundred staff to organize, produce, and distribute its content. The production of electronic scholarly information is a highly complex process that occurs in a distributed geographical environment involving many businesses beyond Elsevier Science. Changes to the manufacturing process can take years to percolate through the entire chain of assembly and are considered significant business risks. Consequently, Elsevier is moved to make changes to production only when compelling market demands exist. For example, the Computer Aided Production (CAP) workflow is now under modification because Science Direct, an internal customer of Elsevier Science, is experiencing market pressure to bring published items to its customers in a shorter time than ever before.</p>
</div4>

<div4 type="subpart" n="02"><head>The History</head>
<p>Prior to the creation of the Electronic Warehouse (EW) in 1995, Elsevier Science had no standard processes to create and distribute journals or content. The production of journals was based upon a loose confederation of many smaller publishing houses owned by Elsevier Science. Content was produced using methods that were extant when Elsevier acquired a given publisher. Consequently, prior to the creation of the EW there was no uniformity in the structure or style of content marketed under the name of Elsevier Science. Each publishing house set its own standards for creation and distribution. The lack of a central infrastructure for creating and distributing content also served as an impediment to the rapid distribution of scholarly communication to the market.</p>
<p>With the creation of networks in the early 1990s the perception of time delay amplified. Scientists began to use the network themselves to share communications with one another instantly. The scholarly community would no longer accept long delays between the submission of manuscripts to a publisher and their appearance in paper journals. Scientists and publishers realized that reporting research in electronic format could significantly close the time gap between publication and distribution of content to the scholarly community. The origin of Elsevier Science's Electronic Warehouse is rooted in this realization. Elsevier Science's early solution to the problem was to support a research project known as The University Licensing Program commonly referred to as TULIP.<note target="Yale19">[19]</note></p>
<p>The TULIP Project (1992-1996) grew out of a series of Coalition for Networked Information (CNI) meetings in which Elsevier Science, a CNI member, invited academic libraries to partner with it to consider how best to develop online delivery capabilities for scientific journals. The purpose of the project was to discuss the need to build large-scale systems and infrastructures to support the production and rapid delivery of such journals over a network to the scholarly community. Given a critical mass of interest from the university communities, Elsevier Science justified a large investment that would create a manufacturing function for converting paper journals into an electronic format for network distribution. This process became known as the PRECAP method for the creation of an electronic version of a journal. The creation of this conversion function served as the foundation for the present day EW. Near the end of the TULIP project plans for an EW were adopted by Elsevier Science in 1995 and built by the end of 1996. By 1997 the EW could produce over one thousand journals using a standard means of production.</p>
<p>The creation and success of the EW in producing and distributing journals was a very significant accomplishment for Elsevier Science because 1) many individual publishers had to be converted one by one, 2) standards for production were evolving from 1994 through 2000, and 3) suppliers who created content for the producers needed to be continuously trained and retooled to adhere to the evolving standards. At the same time, these suppliers met their obligation to produce content, on time, for Elsevier Science.</p>
</div4>

<div4 type="subpart" n="03"><head>Current Workflow</head>
<p>Elsevier Science maintains four production sites based in the United Kingdom (Oxford and Exeter), Ireland (Shannon), the United States (New York), and the Netherlands (Amsterdam). Each site provides content to the EW where this content is stored as an S300 dataset. The contents of each dataset represent an entire issue of a particular journal. The storage system at the EW originally used vanilla IBM technology, i.e., ADSTAR Distributed Storage Manager (ADSM), to create tape backup datasets of content stored on magnetic and optical storage. Access to the data was based only upon the file name of the S300 dataset. As of Summer 2001, the old hierarchical storage system was replaced by an all-magnetic disk-based system providing more flexibility and enabling faster throughput and production times.</p>
</div4>

<div4 type="subpart" n="04"><head>The CAP Workflow</head>
<p>The following is a concise description and discussion of the Computer Aided Production (CAP) workflow. An item is accepted for publication by means of a peer review process. After peer review the item enters the CAP workflow via the Login Function in which a publication item identifier (PII) is assigned to the content. This is a tag that the EW uses to track the item through the production process, and it also serves as a piece of metadata used for the long-term storage of the item. Since this identifier is unique it could also be used as a digital object identifier for an information package in an OAIS archive. In addition to assigning the PII, the login process also obtains other metadata about the author and item such as the first author's name, address, e-mail address, and number of pages, tables, and figures in the item. This and other similar metadata are entered into a Production Tracking System (PTS) that is maintained by the Production Control system.</p>
<p>The item is then sent electronically to a supplier (Elsevier has sixteen suppliers, distributed on a worldwide basis). There the item undergoes media conversion, file structuring, copy editing, and typesetting. The output of this processing is a first generation (no corrections) SGML markup of the item, a PDF file, and artwork for the item. These units of work are then sent to the author for corrections. The author makes the necessary corrections, then sends the item to Production Control where information in the PTS system is updated. Thereafter, Production Control sends the item to an Issues Manager. Any problems found in the content are worked out between the author and the Issues Manager. If there are no problems, the supplier sends the content directly to Production Control.</p>
<p>The Issues Manager then passes the corrections on to the supplier and begins to compile the issue. This involves making decisions about proofs, cover pages, advertising, and building of indexes. On average, an Issues Manager is responsible for five to ten journals or about fifteen thousand pages a year. Once content is received, the supplier then creates a second-generation SGML and PDF file and new artwork, if necessary. This cycle is repeated until the complete issue is assembled. Once the issue is fully assembled the Issues Manager directs the supplier to create a distribution dataset called S300 which contains the entire issue. The supplier sends this file to the EW where the file serves as input for the creation of distribution datasets for customers such as Science Direct. At EW this dataset is added to an ADSM-based storage system that serves as a depository  --  not an archive  --  for all electronic data produced for the EW. The S300 dataset is also sent to a printer where a paper version of the issue is created and then distributed to customers. The paper version of the journal is also stored in a warehouse. Most printing occurs in the Netherlands and the United Kingdom.</p>
<p>The current issue-based workflow has two serious problems. The first is that production does not produce content for distribution in a timely fashion for customers like Science Direct, and the second is that issue-based processing generates high and low periods of work for suppliers. A steady stream of work passing through the manufacturing process would be more efficient for the suppliers and would result in a more timely delivery of content to Elsevier's customers such as Science Direct. The driving force behind a need for change, as mentioned above, is not EW but rather, Science Direct as an internal customer of the EW. The resolution to these workflow problems is to change the fundamental unit of work for production from an issue to an article, something Elsevier recognizes and is currently working toward.</p>
<p>The new article-based e-workflow being developed by Science Direct will streamline interactions between authors, producers, and suppliers. At a management level automation of key functions will yield the following efficiencies: 1) in the e-workflow model, Web sites will be created to automate the electronic submission of articles to an editorial office and to establish an electronic peer review system, and 2) the peer review system will interface with a more automated login and tracking system maintained by the EW.</p>
<p>The new Production Tracking System can then be used by the EW, suppliers, and customers to manage the production and distribution processes more efficiently. Functionally, the EW would also produce two additional intermediary datasets called S100 and S200. These datasets could be sent to the EW for distribution to customers at the time of creation by the supplier and before an S300 dataset was sent to the EW. For example, the physics community, which uses letter journals, would directly benefit by this change in production. Under the e-workflow model, the supplier could immediately upon creation send an S100 dataset that contained a first generation version of the letter or item (i.e., no author corrections) directly to the EW for distribution to a Science Direct Web site. In addition, Science Direct would also be able to distribute content at the article level in the form of an S200 dataset that contained second generation or correct SGML and PDF data. This content would be sent to a Web site before an S300 dataset, representing the entire issue that was sent to the EW by the supplier. It is interesting to note that the EW does not save intermediary datasets once an S300 dataset is created. Pilot projects have been launched to test the e-workflow model.</p>
<p>Finally, it should be noted that as the use of the EW developed and evolved over time, it became apparent  --  for operational and customer support reasons  --  that some additional support systems would be needed. For example, one of these systems facilitates Elsevier's ability to support customers in auditing the completeness of their collections. Another tracks the history of publications that Elsevier distributes.</p>
</div4>

<div4 type="subpart" n="05"><head>The Standards</head>
<p>In the early 1990s Elsevier Science recognized that production and delivery of electronic content could best be facilitated by conversion of documents to an SGML format. SGML is a tool that enables the rendering of a document to be separated from the content structure of a document. This division is achieved through the use of a document type definition (DTD) and a style sheet. The DTD is a tool by which the structure of a document can be defined through the use of mark-up tags. In addition, the DTD defines a grammar or set of rules that constrain how these tags can be used to mark up a document. A style sheet defines how the content should be rendered, i.e., character sets, fonts, and type styles. Together, these two tools make documents portable across different computer systems and more easily manipulated by database applications. In addition, the separation of content from rendering is also critical to the long-term preservation of electronic scholarly information. That said, the evolution of production and distribution of content by Elsevier Science or the EW has been tightly coupled to 1) the development of a universal DTD for their publications, 2) the successful adoption of a DTD by EW suppliers, and 3) the emergence of the Portable Document Format known as PDF. On average it took two years for all suppliers (at one time greater than two hundred) to integrate a new DTD into production. As inferred from Table I below, by the time one DTD was fully implemented by all suppliers another version of the DTD was being released.</p>

<p><table>
<row><cell rows="3">Table I   --   DTD Chronology of Development</cell></row>
<row><cell rows="3"></cell></row>
<row><cell role="label">DTD Version</cell><cell role="label">Date</cell><cell role="label">Note</cell></row>
<row><cell>FLA 1.1.0</cell><cell>April 1994</cell><cell></cell></row>
<row><cell>FLA 2.1.1</cell><cell>May 1995</cell><cell></cell></row>
<row><cell>FLA 3.0.0</cell><cell>November 1995</cell><cell>No production</cell></row>
<row><cell>FLA 4.0.0</cell><cell></cell><cell>No production</cell></row>
<row><cell>Index DTD 1.0.0</cell><cell></cell><cell>No production</cell></row>
<row><cell>Glossary DTD 1.0.0</cell><cell></cell><cell>No production</cell></row>
<row><cell>FLA 4.1.0</cell><cell>November 1997</cell><cell>Full SGML</cell></row>
<row><cell>FLA 4.2.0</cell><cell>February 2000</cell><cell>Full SGML Perfected</cell></row>
<row><cell>FLA 4.3.0</cell><cell>July 2001</cell><cell></cell></row>
<row><cell>FLA 5.0</cell><cell>To be announced</cell><cell>XML and MathML</cell></row>
</table></p>


<p>Two types of standards control production exist at the EW, one for the production of content and the other for the distribution of content to customers. On the production side, the standards used are known as PRECAP, CAP, and DTD. For distribution to customers such as Science Direct, the standards are known as Exchange Format for Electronic Components and Text (EFFECT), Electronic Subscriptions Service (EES), and Science Direct On Site (SDOS).</p>
<p>PRECAP, born in 1995, is an acronym for PRE-Computer Aided Production; CAP, born in 1997, is an acronym for Computer Aided Production. The principal differences between the two modes of production are that 1) PRECAP is paper-based and CAP is electronically based, and 2) CAP production produces higher quality content then PRECAP production. In the PRECAP method electronic journals are created from disassembled paper journals that are scanned and processed.</p>
<p>The PRECAP standard was developed for the TULIP project and is still used to produce content today. At first, PRECAP content was distributed for the Elsevier Science EES (1995-1997) using the EFFECT dataset format, a standard that also grew out of the TULIP project. In fact, the standard was first known as the TULIP Technical Specification Version 2.2. Like its predecessor, EFFECT provided a means by which output from PRECAP and CAP processing could be bundled and delivered to customers. The specification defined a map or standard by which component data (e.g., TIFF, ASCII, and PDF) generated by these processes could be accessed by an application or loaded into a database for end-user use. Since its introduction in 1995, the EFFECT standard has gone through several revisions to meet the changing needs of EW customers.<note target="Yale20">[20]</note></p>
<p>The data components for PRECAP production can consist of page image files, raw ASCII files, SGML files for bibliographic information, and postscript files encapsulated PDF format. Data components for CAP production are only different in that CAP contains no TIFF page images and CAP can produce full SGML instances of an editorial item such as a full-length article. Paper pages are scanned at 300 dots per inch (dpi) to produce TIFF 5.0 (Tag Image File Format) images. The page image has a white background and black characters. Pages are also compressed using the Fax Group 4 standard that can reduce the size of a page image by about 8 percent. The raw text files are generated via Optical Character Recognition (OCR) from the TIFF files. No editing is performed on these files and only characters in the ASCII range 32-126 are present in the content. These raw files are used to create indexes for applications, not for end-user purposes. SGML citation files are created using the full-length article DTD version 3.0 that took nearly three years to develop. DTD version 1.1.0 created in 1994 and version 2.1.1 created in 1995 were considered experimental and were not used to produce content with PRECAP production. Sometime in 1996 or early 1997, PDF files replaced TIFF image files.</p>
<p>The development of the PRECAP standard and its evolution to CAP can be traced in datasets the EW distributed to its customers either as EES or later as SDOS. Between 1995 and 1997, the EW distributed three different versions of datasets to the Elsevier Electronic Subscription Service. These versions are known as EES 1.0, EES 1.1, and EES 1.2. In EES 1.0, datasets contained only TIFF, ASCII, and SGML files. In EES 1.1, PDF files replaced TIFF images. However, in EES 1.2 datasets (around 1997) a new type of PDF file was introduced. This PDF file is called a "true PDF" and is created not from paper but rather from output from electronic type setting. This change marked the birth of the CAP production method. It is important to note that both CAP and PRECAP data can be contained in an EES 1.2 distribution dataset and SDOS datasets. In December of 1998 EES was officially renamed SDOS. From about 1997 to the present, three versions of SDOS datasets (SDOS 2.0, SDOS 2.1, and SDOS 3.0) have been marketed. Like EES, SDOS datasets contain the same component data. Differences in the versions consist of the type of SGML content packaged in the dataset. All versions contain SGML bibliographic data but in version 2.1 tail or article reference data is being delivered in SGML format. It also is important to note that by 1997, using DTD 4.1, EW suppliers produced full-length article SGML. However, this content was not offered to the EW customers from 1997 through 2000. In February of 2000, DTD 4.2 became the production DTD. However, it was only recently, in spring of 2001, that SDOS 3.0 datasets contained full-length article SGML, including artwork files in Web-enabled graphic format. Version DTD 5.0 is now under development but unlike all other DTD versions, 5.0 will be XML-based and MathML-enabled.</p>
</div4>

<div4 type="subpart" n="06"><head>Conclusions</head>
<p>This section describes the production processes that take place at Elsevier Science. A later section dealing with prototype development will describe what is necessary to move Elsevier data from the end point of the publisher's production systems (i.e., the CDs containing metadata and other content) into the prototype archive. It rapidly became clear that the bridge between the two worlds  --  that of the publisher and that of the archivist  --  is a very shaky one. While recognizing that much work has been done with such emerging standards as METS,<note target="Yale21">[21]</note> OAI, OAIS, etc., no archiving standards have yet been universally adopted jointly by major publishers and the academic community. The adoption of such standards is critical to the success of long-term electronic archives, but such standards urgently need further development and testing in a collaborative approach between the academic and publishing communities before they are likely to become an integral part of publishers' workflows.</p>
<p>As the study progressed, it became clear that the lack of accepted standards and protocols to govern such facets of metadata as transmission, data elements, format, etc., would be a major impediment in the future, not only to expanding the prototype but also to realizing the full potential of digital archives.</p>
<p>Major areas of concern regarding the present situation include generic problems associated with introducing "bridgeware" for any given publisher, as well as the unnecessary, if not prohibitive, costs and operational problems associated with developing, maintaining, and operating multiple different sets of bridgeware to accommodate different publishers having different metadata content and formats. This chaotic scenario has the potential to consume inordinate amounts of time and resources to produce, operate, and maintain such multiple instances of bridgeware.</p>
<p>Relating this chaotic environment to our experience in developing the prototype, the team observed that the lack of a commonly agreed upon set of metadata content necessitated the development of data replication and transformation software to convert the data received from the publisher (in Elsevier's case, in EFFECT format) into the format used in the archive itself (in our prototype, OAI and Dublin Core). At Yale, this transformation was made possible by using Extensible Style Language Transformation (XSLT) technology. However, our prototype development represents a far-from-optimal scenario. While it works in the case of Elsevier because the Dublin Core metadata can be generated from the information in the EFFECT datasets, there is no guarantee this would be true for every publisher.</p>
<p>A further danger is that this situation tends to lead to a fragmented approach in which archive information that is additional to what is needed for a publisher's current content operation will be added either as an afterthought at the publisher's end or as a pre-ingestion stand-alone process at the archive's end. However, based on Elsevier's past experiences in TULIP and in the early days of EES, the team observed that the necessary or additional metadata cannot be effectively and satisfactorily produced either as an afterthought post-production process on the publisher's side or as a pre-ingestion conversion activity at the archive's end. Approaching e-archiving in this fashion leads to distribution delays and a more complex production and distribution scenario, with all the accompanying potential to introduce production delays and errors.</p>
<p>The approach to adopt in creating electronic archives should be to recognize at the outset the needs of the archivist, i.e., to collect information to meet these needs as an integral part of the publishing and production process. Archival information will then be subject to the same level of production tracking and quality control as the information gathered in order to provide current-content service.</p>
</div4>
</div3>

<div3 type="part" n="07"><head>Creation of a Prototype Digital Archive</head>
<div4 type="subpart" n="01"><head>Introduction</head>
<p>In their seminal report of 1996, Waters and Garrett<note target="Yale22">[22]</note> lucidly defined the long-term challenges of preserving digital content. Ironically, the questions and issues that swirl about this new and perplexing activity can be relatively simply characterized as a problem of integrity of the artifact. Unlike paper artifacts such as printed scholarly journals which are inherently immutable, digital objects such as electronic journals are not only mutable but can also be modified or transformed without generating any evidence of change. It is the mutable nature of digital information objects that represents one of the principal obstacles to the creation of archives for their long-term storage and preservation. In the CPA/RLG report, Waters and Garrett identified five attributes that define integrity for a digital object: 1) content, 2) fixity, 3) reference, 4) provenance, and 5) context. At a different level, these attributes also represent various impediments or problems to the creation of digital archives. For example, the attribute called context involves, among other issues, the technological environment used to store, search, and render digital objects. Solutions to technological obsolescence such as refreshment, emulation, or migration, are imperfect and can leave digital objects inaccessible  --  or even worse, in an irrevocably corrupted state  --  if they are not implemented correctly.</p>
<p>Unfortunately, there now exist numerous examples of data that are no longer available to scholars because there is no means to access information stored on obsolete computer hardware and software. In short, technological obsolescence is a vector that can, in a blink of the eye, undermine the integrity of all digital objects in an archive. The YEA was designed to learn how current models, standards, and formats could effectively address the principal problems of integrity and technological obsolescence that threaten the ontology of digital objects. What follows is a narrative that discusses the creation of the YEA, and the findings and lessons learned from our experiment.</p>
</div4>

<div4 type="subpart" n="02"><head>Site visits to explore ongoing archival projects</head>
<p>Our first step in creating the YEA prototype was to learn about the publisher's technical systems and processes used to create electronic content. Knowledge of the publisher's workflows was important because this knowledge was needed to build an understanding, as defined by the attributes noted above, of digital objects produced by Elsevier Science's EW. At a minimum, the team needed to understand the structure and format of Elsevier Science content and the context or the technical environment needed to read and render the data. In addition, team members needed an understanding of the possible preservation metadata incorporated into Elsevier's data in order to address other issues such as the provenance and fixity of the digital objects that were to be stored in the YEA archive.</p>
<p>Next, team members conducted a review of research projects involved with electronic archives. The findings of this review showed that internationally the Open Archival Information System (OAIS) has been fast-tracked as a model that can be used to describe and create an infrastructure to support the activities of a digital archive. The OAIS reference model specifies and defines 1) an information object taxonomy and 2) a functional model for defining the processes of a digital archival system.<note target="Yale23">[23]</note> The team's other important finding was that the Open Archives Initiative (OAI),<note target="Yale24">[24]</note> an open source model for Web publishing, could be used as a means to access digital objects from the archive.</p>
<p>Archival projects that have adopted the OAIS model include the British Library in London, England; the National Library of the Netherlands, Koninkliijke Bibliotheek (KB) in Amsterdam, the Netherlands; and Harvard University in Cambridge, Massachusetts. In addition, WGBH, a non-profit media organization based in Boston, Massachusetts, plans to build its digital archive based on the OAIS model. The project's technical team decided to make site visits to the European projects and based upon the recommendation of Elsevier Science, to WGBH. Elsevier's technical staff also chose to visit the European sites, both because of Elsevier's relationship with these institutions and because the libraries are exploring the archiving of Elsevier Science content. In addition, both national libraries had already made significant contributions to the study of digital archives. The KB is known for its work on the NEDLIB project<note target="Yale25">[25]</note> and the British Library for its work on preservation description metadata. The site visits proved important and valuable because they provided Elsevier with an opportunity to validate Yale's recommendation that the YEA prototype should be an implementation of the OAIS model. In addition, the team used these visits as a means to explore lessons learned from ongoing digital archive projects. The team wanted to take advantage of project successes and to avoid pitfalls that electronic archiving projects might have encountered. The elements that can contribute to the success or failure of electronic archiving are summarized as follows.</p>
<p>The archival projects at the British Library and the KB represent a continuum of results. The KB has been, by its definition, successful with its project while the British Library has experienced some significant problems with its plans to build a digital archive. Two factors account for the different outcomes. First, the British Library attempted to specify and develop production systems without the benefit of prototype models. In contrast, the KB is developing their archive from a series of research projects that have focused upon building prototypes of future production systems. The other success factor was related to the technical partnership between the library and the vendor chosen to develop the archival systems. In contrast to the British Library, which depended on the vendor to specify application requirements, the KB was able to specify application requirements to the vendor who in turn was able to develop system software. For example, the KB and IBM have successfully begun to modify IBM's Content Manager to integrate into the OAIS model. The KB and IBM have also successfully implemented a data management process and storage management system for digital objects. In addition, the KB and IBM have created beta code for an OAIS ingestion system. Because the KB possessed a deep intellectual understanding of the OAIS model and its requirements, staff were able successfully to exploit IBM's technical know-how. The other valuable lesson came from our site visit to Boston-based WGBH which has successfully partnered with Sun Microsystems to build a digital archive. Through this mutually beneficial partnership, Sun developed a new type of file system for large multimedia objects based upon content owned by WGBH. In return, WGBH was given hardware to support their digital archive. This experience reinforces the value of relevant partnerships that can, among other things, contain development costs.</p>
<p>These site visits also served to validate for YEA that the OAIS and OAI models could serve as foundations for a prototype archive. Consequently, the next objective for the study team was to build small but meaningful components of an OAIS archive. The team speculated, based upon knowledge of Elsevier Science content and Elsevier's EFFECT distribution standard, that rudimentary ingestion, data management, and archival storage processes could be created. Once built, these processes could be engaged to transform a primitive submission information package (SIP) into a primitive archival information package (AIP), which in turn could be searched and rendered via an OAI interface. The prototype-building work began in August 2001 and was successfully completed four months later in December 2001.</p>
<p>In May 2001, sandwiched between the site visit to WGBH and the ground-breaking for the YEA prototype, the team hosted a presentation on digital archiving from the J. P. Morgan Chase I-Solutions group. Chase's I-Solutions potentially offers a means to reduce the total cost of ownership of an archive for a library. That is, Chase's I-Solutions provides archival storage services to commercial businesses that are required to store business transaction data, such as checks and loan agreements, for a minimum period of seven years. Potentially, scholarly archives could outsource the storage management function of their archives to large commercial institutions such as Chase. The Yale team speculated that perhaps, by taking advantage of the scale offered by the Chase archival infrastructure, it might be possible to reduce the total unit cost of storage for a digital object. However, it is difficult to tell at this time whether the cost-saving could be passed on to the customer. While the economics of this concept deserve additional research, other issues make Chase's I-Solutions less useful at this point in time. These issues revolve around trust and major differences between the nature of commercial and scholarly archives. Would the academic community trust a very large commercial institution to archive their content when this community has reservations about relying upon publishers to archive their content? In addition, the I-Solutions archive is currently not designed to capture preservation metadata with stored digital objects. Equally important, the commercial archive is designed to store content for a short period, not the one hundred plus years that academic archives require. Access to the stored objects also poses a problem. Once archived with Chase, an object or its metadata cannot not be altered. Accordingly, at this stage the team believed it was premature to establish a collaborative relationship with Chase.</p>
</div4>

<div4 type="subpart" n="03"><head>The Concept of the YEA prototype Archive</head>
<p>The Yale/Elsevier technical team perceived that the EFFECT standard and the OAI protocol could be fashioned to build two components of the OAIS model. That is, data in Elsevier's EFFECT format could be transformed into a Submission Information Package (SIP) and the data provider component of the OAI model could be used as an OAIS data management process. Archival storage for the digital objects could be created with a standard UNIX (Solaris) file system. However, the design of the prototype hinged upon the team's ability to convert the EFFECT metadata found in the publisher's SDOS distribution datasets into an XML format. Once converted to XML, the metadata could be transformed into the Dublin Core format that is a requirement for the OAI data provider protocol. Thereafter, the converted metadata could be harvested and exposed by an OAI compliant service provider.</p>
</div4>

<div4 type="subpart" n="04"><head>The Hardware and Software Infrastructure</head>
<p>The YEA prototype is split across two different hardware and software platforms. This is idiosyncratic and was done for the sake of expediency. The OAI components are deployed on an IBM Thinkpad model T20 that runs Windows Professional 2000. The Thinkpad has one Intel x86 based, 700 Mhz processor and about 400 Mbytes of memory. The PC's internal disk storage drive has a capacity of 11 Gbytes. The OAIS archival storage component is hosted on a Sun Enterprise 450 workgroup server that run Solaris version 2.8. The system has two (Sun Ultra Sparc-II) 450 Mhz processors and 2 Gbytes of memory. An external Sun A1000 disk array, which provides about 436 Gbytes of storage, is attached to the server.</p>
<p>The OAI data provider software was developed at the University of Illinois at Urbana-Champaign as part of another Mellon foundation project. To run the application the following software is required:</p>

<list>
<item>Microsoft 2000 Professional</item>
<item>Microsoft Internet Information Server version 4.0 or higher</item>
<item>Microsoft XML Parser (MSXML) version 4.0</item>
<item>Microsoft Access</item>
</list>

<p>The OAI data store from the University of Illinois-UC conforms to version 1.1 of the OAI protocol. The data service has a simple but powerful design that separates XML metadata files from OAI protocol administrative information about each object. Individual XML files are stored in a Windows file system, and the OAI administrative data are stored in four simple RDBMS (MS Access) tables. In the YEA implementation, the XML files are stored in a MS Windows file system, and the administrative data is stored in an MS Access database. Data in these tables contain the substance of the protocol, without which the data server could not respond to an OAI command or request for information. For example, the metadata table contains all the XML information necessary to describe a metadata object. This information includes the XML namespace, schema, and style sheet information that is needed to transform tagged data in the XML files to Dublin Core. The purpose of the Object table in the database is to maintain a set of pointers to these files. The Repository table provides descriptive information about the repository and the Set table defines collects that are within the repository.</p>
<p>The OAI service provider software is not part of the local environment but was developed at Old Dominion University. The search service called "Arc" is an experimental research service of the Digital Library Research group at Old Dominion University. Arc is used to harvest OAI-compliant repositories, making them accessible through a unified search interface over the network.</p>
</div4>

<div4 type="subpart" n="05"><head>Programmatic Process</head>
<p>Elsevier Science distributes electronic content in a proprietary format that has the fundamental components or structures of a SIP. The standard includes a data object and representation information to provide meaning to the bits that compose the object. As noted above, Elsevier's SDOS datasets are distributed in EFFECT format and contain data objects that are composed of text, image, and PDF files. The encoding standards for each object type are identified and partially defined in the EFFECT dataset. In addition to containing these objects, the EFFECT standard also contains some preservation description information metadata that are needed to maintain the long-term integrity of an archived information object. Finally, the EFFECT standard contains packaging information that 1) uniquely identifies the dataset that contains the information objects so that they can be located through a search process, and 2) provides identification and descriptive information about the delivery vehicle, i.e., the CD-ROM or FTP protocol used to transport the content to a customer or archive. Other representation information in the standard defines the directory structure of the distribution dataset and a logical mapping of how data objects can be assembled to display the digital object through rendering software.</p>
<p>As delivered to Yale, the usefulness of the SDOS data for archival purposes was diminished because these data are not in a normative format such as XML. To transform these data into an XML format, the researchers adopted a piece of software from Endeavor Information Systems (EIS), another company owned by Elsevier Science. EIS was able to process an EFFECT dataset and convert the metadata into XML. Thereafter, the metadata had to be converted to the Dublin Core standard so it would comply with the OAI protocol. Using the expertise of a librarian, the team mapped the EFFECT metadata tags to qualified Dublin Core tags. Once these tags were mapped, an XSLT style sheet was created to dynamically transform EFFECT tags to Dublin Core in response to an OAI request. Approximately fifty items from an SDOS dataset were converted and loaded into the OAI database.</p>
<p>Once data were loaded, the implementation was validated with a tool provided by the Digital Library Research group at Old Dominion University. The tool is called the Open Archives Initiative Repository Explorer.<note target="Yale26">[26]</note> Once the contents are validated, the repository is certified to understand any verb or command in the OAI protocol. The YEA prototype passed this implementation test. After making small modifications to the main application module for the data provider service, the team could experiment with initiating OAI commands to the YEA database. However, the search interface to these data was limited and lacked a feature for retrieving and displaying the digital objects that reside in archival storage.</p>
<p>To provide a unified search interface to YEA, Elsevier Science gave the planning team permission to register the archive with the Arc service provider. Shortly thereafter, Arc's Web harvesting daemon extracted metadata from YEA and, in addition to other repositories, the YEA officially became a repository that could be searched through the Arc interface. Now, not only could YEA metadata be exposed in Dublin Core format, but also links to digital objects in archival storage became active. A reader would not only see metadata about Elsevier Science but could also extract and view the actual content in PDF format through a simple Web browser.</p>
</div4>

<div4 type="subpart" n="06"><head>Lessons Learned and Next Steps</head>
<p>The ability to preserve digital information for long periods of time is dependent upon the effectiveness of the models, standards, formats, and protocols that can be applied to overcome problems associated with technological obsolescence and the maintenance of the integrity of digital objects. The YEA prototype provided some evidence that the OAIS and OAI models can be used to create such an archive. The OAIS model specifies metadata that is needed to preserve the integrity of digital information for long periods of time.</p>
<p>The e-archiving planning team also learned that some of this metadata, e.g., the Preservation Description Information, is already incorporated into distribution datasets disseminated by at least one major publisher, Elsevier Science. However, SIP elements included in Elsevier's EFFECT standard need formally to be developed to include all metadata concerning the fixity, reference, provenance, and context of a digital object. The team recognizes that to obtain these data, production processes used to create Elsevier's content will have to be modified. To be helpful to the archival community, Elsevier needs to assure that its metadata conforms to emerging standards for SIPs.</p>
<p>Recently, Harvard University released a specification for a SIP expressed in XML format.<note target="Yale27">[27]</note> The effectiveness and usefulness of this model can only be determined through robust testing from real applications. Elsevier Science has plans to change its workflows so that content and distribution standards are XML-based. Such a change could provide an opportunity for the planning team, in Phase Two, to work to develop an advanced prototype SIP that conforms to the Harvard specification.</p>
<p>The team's experience with OAI data provider software showed promise for rapid deployment. The economic advantage of using open source software to sustain archives is self-evident. The OAI protocol also showed promise for interoperating with the OAIS model. One shortcoming of a standard OAI implementation is that the Dublin Core standard does not allow all of the rich metadata found in an Information Package to become manifest. Dublin Core was developed as a low-barrier means of searching for data; consequently, it has a limited tag vocabulary. However, the OAI standard does allow for multiple manifestations of an object's metadata. In Phase Two, the Yale-Elsevier team will consider how best to develop an XML schema that can permit the exposure of all metadata found in a formal AIP.</p>
<p>The simplicity of the OAI data store that was implemented suggests that the data management architecture is also scalable and portable. The project team has experiential evidence suggesting that applications that store data objects external to a RDBMS are more flexible, easier to maintain, and more portable across operating systems. These features can potentially make migrations less problematic and more economical when they need to occur.</p>
<p>As alluded to elsewhere in this report, advances in the creation of digital archives are dependent upon systems that can interoperate, and on data and content that are portable. The suite of XML technologies that includes XML, XSL, XPATH, and XSLT provides some hope and high expectations that electronic archives can be successfully architected and implemented. The fact that the project team was able quickly to create an XSLT script with the use of a XML tool demonstrates the promise of already-available technologies. In addition, there is substantial evidence that text data in tagged format such as SGML or XML is very portable across different platforms. The challenge to e-archives is how to make other data formats such as audio and video equally portable across systems. This challenge will be particularly important for specification of standards for Dissemination Information Packages (DIPs).</p>
<p>Finally, the continued success of this impressive beginning between the Yale Library and Elsevier Science to explore digital archives hinges upon a few critical success factors. First is Elsevier Science's continued and unflagging support of Yale Library as a strategic planning partner. The professional relationships and confidence that each institution now has in the other is invaluable. Together, the two institutions are poised to become leaders in the electronic archiving field. Second, Yale and Elsevier need to gain experience with other publishers' formats. In this, Elsevier Science can be helpful, because many of its rendering applications load data from other publishers. Finally, Elsevier Science is interested in exploring the concept of an archival standard that can apply across publishers. Their support and resources could contribute significantly to the development of these systems and standards.</p>
</div4>
</div3>

<div3 type="part" n="08"><head>Digital Library Infrastructure at Yale</head>
<div4 type="subpart" n="01"><head>Existing Infrastructure</head>
<p>At present, the Yale University Library has several successful components of a Digital Library Infrastructure (DLI) in production use and is actively pursuing additional key initiatives. The Luna Insight image delivery system, for example, elegantly supports faculty and student use of digital images for teaching and study, but it does not yet address the long-term preservation of those images. Over the next three years, we have committed to a substantial expansion of the Luna imaging initiative supported by grant funding from the Getty Foundation, digital collection development in the Beinecke Library, and increased dedication of internal Library resources to the project. Our Finding Aids database provides access to archival finding aids encoded in formats that will endure over time, but, like many of our current stand-alone systems, this resource is not yet tightly integrated into an overall architecture. The participants in the Finding Aids project (including the Beinecke Library, the Divinity Library, the Music Library, and Manuscripts and Archives) continue to add new material to this database and to enhance the public interface.</p>
<p>The Orbis online catalog is perhaps the best example of a system designed, operated, maintained, and migrated with a focus on long-term permanence. The Yale Library staff are currently engaged in the process of migrating from the NOTIS library management system to the Endeavor Voyager system, with production implementation scheduled for July 2002. We are confident that the bulk of our retrospective card catalog conversion effort will also be finished by that date. The meticulous examination of hardware options for the LMS installation has resulted in a high level of expertise among Yale systems staff in the technical requirements for robust, large-scale processing and storage of critical data. The completion of these two fundamental and resource-intensive projects will position the Library well for a substantial investment of energy in innovative digital library initiatives.</p>
<p>In order to enhance reader navigation of digital resources, for instance, we have purchased SFX and MetaLib from Ex Libris. SFX context-sensitive reference linking went into production use at Yale in January 2002 for four information providers: Web of Science, EbscoHost, OCLC FirstSearch, and the OVID databases. Immediately following the Voyager implementation next summer, library staff expect to implement the MetaLib universal gateway in order to deliver unified access, federated searching, and personalized services across a wide range of local and remote resources.</p>
<p>Integration of Library applications with the wider University technical environment is another key principle guiding our work. The Library, for instance, is well advanced in utilizing the campus-wide authentication infrastructure based upon a Central Authentication Service and a universal "NETID." Other areas for collaborative activity include the University Portal project (now in preliminary planning stages), the Alliance for Lifelong Learning,<note target="Yale28">[28]</note> and the Center for Media Initiatives (faculty technology support).<note target="Yale29">[29]</note></p>
</div4>

<div4 type="subpart" n="02"><head>Current Commitments</head>
<div5 type="division" n="01"><head>University Electronic Records Management Service</head>
<p>The Library's University Archives program provides records management services for University records of enduring value. Yale e-records comprise those digital objects (such as e-mail, administrative databases, Web sites, and workstation products) that are created primarily to administer and sustain the business of the University. The University is committed to preservation and access for its record in perpetuity through the services of the Library's Manuscripts and Archives Department. As part of its tercentennial initiatives, Yale augmented significantly the Library's records management capabilities. Recently received permanent funding for a comprehensive University Archives Program will help to ensure that preservation of University records in digital formats is properly addressed. New attention to the management of the University's electronic records is a necessary and natural extension of the responsibilities now fulfilled for paper records. The service (ERMS) will develop the capacity to ensure the long-term preservation of and access to vital University records, while ensuring their intellectual integrity and guaranteeing their authenticity. The service will harvest and augment the metadata of the records to enhance access and support data management, migration, and long-term preservation. The ERMS will also provide consultation and guidance to University departments implementing electronic document management systems, to ensure that such systems meet the needs of the University for long-term preservation of and access to their content.</p>
</div5>

<div5 type="division" n="02"><head>Beinecke Rare Book and Manuscript Library Digital Collections Project</head>
<p>The Beinecke Library is now (January 2002) embarking on a major multi-year digitization project which will generate approximately two thousand images per month from book and manuscript material in the Beinecke collections. Luna Imaging, Inc., is acting as consultant for the newly-created scanning facility, and Beinecke staff are committed to high standards for image quality, metadata creation, and long-term archiving. Discussion has already begun among Beinecke staff, the Library Systems Office, and ITS staff about the appropriate mechanisms for ingestion of this material into the Yale Electronic Archive.</p>
</div5>
</div4>

<div4 type="subpart" n="03"><head>Next Steps for Establishing the YEA</head>
<p>In December 2001, the Collection Management Goal Group (CMGG), one of six strategic planning groups created by the new University Librarian, strongly recommended that the University "establish a Digital Library Infrastructure (DLI) in the Yale University Library worthy of an institution with a 300-year history of acquiring, preserving, and providing access to scholarly research material." There was a powerful conviction in this goal group, and among those consulted by the goal group, that digital preservation is the highest-priority unmet need in the Library's nascent digital infrastructure. The CMGG summarized the first-year objectives as follows:</p>

<list>
<item>Establish the scope of need for a local digital archive (the metaphor used is that of a "Digital Library Shelving Facility," based on the Library's high-density shelving service near the campus).</item>
<item>Establish an appropriate infrastructure for a digital archive with a focus on the Mellon-funded project to preserve scholarly electronic journals.</item>
<item>Important potential candidates for preservation include:
<list>
<item>Unique digital material acquired by Yale (e.g., literary archives in the Beinecke Library)</item>
<item>Born-digital material acquired/selected by Yale, not adequately preserved elsewhere (e.g., selected government documents, works published online, Web sites)</item>
<item>Formal partnerships with providers (e.g., Elsevier e-journals)</item>
<item>Surrogates (preservation) created/acquired (e.g., digital reformatting of brittle books)</item>
<item>Surrogates (public access collections) created/acquired (e.g., teaching images collected or created by the Visual Resources Collection and the Beinecke Rare Books Library)</item>
</list></item>
<item>Establish metadata requirements for materials destined to reside in the Archive.</item>
</list>

<p>Senior Library managers are committed to the aggressive pursuit of funding for the creation of this essential digital infrastructure.</p>
</div4>
</div3>
</div2>

<div2 type="subsection" n="06"><head>Endnotes</head>
<note id="Yale01">[1] Stewart Brand, <hi rend="italics">How Buildings Learn: What Happens After They're Built</hi> (NY: Viking, 1994).</note>
<note id="Yale02">[2] Under the auspices of the International Union of Pure and Applied Physics (IUPAP) (<xref doc="iupap">http://iupap.org</xref>), a workshop on the Long-Term Archiving of Digital Documents in Physics was held in Lyon, France, 5-6 November 2001. As the digitization of physics literature has become increasingly widespread, concern about the long-term preservation of this literature has risen. The workshop brought together society and commercial publishers, librarians, and scientists to discuss issues related to the long-term archiving of electronic publications. See <xref doc="publishapsIUPAP">http://publish.aps.org/IUPAP/</xref>.</note>
<note id="Yale03">[3] Carol Fleishauer is Associate Director for Collection Services of the MIT Libraries and a founding member of the NERL consortium.</note>
<note id="Yale04">[4] Consultative Committee for Space Data Systems,  <hi rend="italics">Reference Model for an Open Archival Information System (OAIS)</hi>, CCSDS-650.0-B-1 Blue Book (Washington, DC: National Aeronautics and Space Administration, January 2002).  Online at <xref doc="wwwclassicccsdsdocumentsCCSDS6500B1">http://wwwclassic.ccsds.org/documents/pdf/CCSDS-650.0-B-1.pdf</xref>.</note>
<note id="Yale05">[5] <hi rend="italics">Avoiding Technological Quicksand: Finding a Viable Technical Foundation for Digital Preservation</hi>, Publication 77 (Washington, DC: Council on Library and Information Resources, January 1999), online at <xref doc="clirpubsreportsrothenbergcontents">http://www.clir.org/pubs/reports/rothenberg/contents.html</xref>.</note>
<note id="Yale06">[6] Donald Waters and John Garrett, co-chairs, <hi rend="italics">Preserving Digital Information: Report of the Task Force on Archiving of Digital Information</hi>. Commission on Preservation and Access and the Research Libraries Group (1 May 1996). Online at <xref doc="ftprlgpubarchtffinalreport">ftp://ftp.rlg.org/pub/archtf/final-report.pdf</xref>.</note>
<note id="Yale07">[7] For additional information about OCLC's programs in the digital preservation arena, see: <xref doc="oclcdigitalpreservation">http://www.oclc.org/digitalpreservation/</xref>.</note>
<note id="Yale08">[8] For a brief overview of the NDIIPP, see Deanna Marcum, "A National Plan for Digital Preservation: What Does it Mean for the Library Community," CLIR Issues 25 (January/February 2002): 1, 4. Online at <xref doc="clirpubsissues25plan">http://www.clir.org/pubs/issues/issues25.html#plan</xref>.</note>
<note id="Yale09">[9] John C. Bennett, "A Framework of Data Types and Formats, and Issues Affecting the Long Term Preservation of Digital Material," British Library Research and Innovation Report 50, Version 1.1, JISC/NPO Studies on the Preservation of Electronic Materials (London: British Library Research and Innovation Centre, 23 June 1999). Online at <xref doc="ukolnserviceselibpaperssupportingrept011">http://www.ukoln.ac.uk/services/elib/papers/supporting/pdf/rept011.pdf</xref>.</note>
<note id="Yale10">[10] Anne J. Gilliland-Swetland and Philip B. Eppard, "Preserving the Authenticity of Contingent Digital Objects: the InterPARES Project." <hi rend="italics">D-Lib Magazine</hi> 6.7/8 (July/August 2000). Online at <xref doc="dlibjuly00eppard07eppard">http://www.dlib.org/dlib/july00/eppard/07eppard.html</xref>.</note>
<note id="Yale11">[11] Marie-France Plassard, ed., IFLA Study Group on the Functional Requirements for Bibliographic Records, <hi rend="italics">Functional Requirements for Bibliographic Records: Final Report</hi>, UBCIM Publications - New Series Vol 19 (M&#x00FC;nchen: K. G. Saur, 1998). Online at <xref doc="iflaVIIs13frbr">http://www.ifla.org/VII/s13/frbr/frbr.htm</xref>.</note>
<note id="Yale12">[12] Cited above at note 4.</note>
<note id="Yale13">[13] "The Making of America II Testbed Project White Paper," Version 2.0 (15 September 1998). Online at: <xref doc="sunsiteberkeleymoa2wpv2">http://sunsite.berkeley.edu/moa2/wp-v2.pdf</xref>.</note>
<note id="Yale14">[14] OCLC/RLG Working Group on Preservation Metadata, "Preservation Metadata for Digital Objects: a Review of the State of the Art" (15 January 2001). Online at <xref doc="oclcresearchprojectspmwgpresmetawp">http://www.oclc.org/research/projects/pmwg/presmeta_wp.pdf</xref>.</note>
<note id="Yale15">[15] The complete archive of Elsevier Science SGML/XML DTDs is available online at <xref doc="supportsciencedirecttectextsgml">http://support.sciencedirect.com/tectext_sgml.shtml</xref>.</note>
<note id="Yale16">[16] This list can be found at <xref doc="dublincoredocuments20000711dcmitypevocabulary">http://dublincore.org/documents/2000/07/11/dcmi-type-vocabulary/</xref>.</note>
<note id="Yale17">[17] Inera, Inc., <hi rend="italics">E-Journal Archive DTD Feasibility Study</hi> (5 December 2001). Online at <xref doc="diglibpreservehadtdfs">http://www.diglib.org/preserve/hadtdfs.pdf</xref>.</note>
<note id="Yale18">[18] For information on OAI, see <xref doc="openarchives">http://www.openarchives.org/</xref>.</note>
<note id="Yale19">[19] See Marthyn Borghuis, <hi rend="italics">et al</hi>, <hi rend="italics">Tulip: Final Report</hi> (New York: Elsevier Science, 1996). Online at <xref doc="elsevierhomepageaboutresprojtrmenu">http://www.elsevier.nl/homepage/about/resproj/trmenu.htm</xref>.</note>
<note id="Yale20">[20] To learn more about EFFECT,  see <xref doc="supportsciencedirecttecindex">http://support.sciencedirect.com/tecindex.htm</xref>.</note>
<note id="Yale21">[21] The Metadata Encoding &amp; Transmission Standard (<xref doc="locstandardsmets">http://www.loc.gov/standards/mets</xref>).</note>
<note id="Yale22">[22] Previously cited at note 7 above.</note>
<note id="Yale23">[23] Previously cited at note 4 above.</note>
<note id="Yale24">[24] Previously cited at note 19 above.</note>
<note id="Yale25">[25] NEDLIB is a collaborative project of European national libraries. It aims to construct the basic infrastructure upon which a networked European deposit library can be built. The objectives of NEDLIB concur with the mission of national deposit libraries to ensure that electronic publications of the present can be used now and in the future. See extensive documentation at <xref doc="kbcoopnedlibhomeflash">http://www.kb.nl/coop/nedlib/homeflash.html</xref>.</note>
<note id="Yale26">[26] This site presents an interface to interactively test archives for compliance with the OAI Protocol for
Metadata Harvesting. See <xref doc="oaidlibvtExploreroai11testoai">http://oai.dlib.vt.edu/cgi-bin/Explorer/oai1.1/testoai</xref>.</note>
<note id="Yale27">[27] Harvard University Library, <hi rend="italics">Submission Information Package (SIP) Specification</hi>, Version 1.0 DRAFT (19 December 2001). Online at <xref doc="diglibpreserveharvardsip10">http://www.diglib.org/preserve/harvardsip10.pdf</xref>.</note>
<note id="Yale28">[28] The Alliance for Lifelong Learning is a joint venture between Oxford, Stanford, and Yale Universities.
See <xref doc="allianceforlifelonglearning">http://www.allianceforlifelonglearning.org/</xref>.</note>
<note id="Yale29">[29] For additional information, see <xref doc="cmiyale">http://cmi.yale.edu/</xref>.</note>
</div2>

<div2 type="subsection" n="07"><head>Part III: Appendices</head>
<div3 type="part" n="01"><head>Appendix A. Three Models of Archival Agents</head>

<p><table>
<row><cell role="label"></cell><cell role="label"><hi rend="bold">Scope of archival commitment</hi></cell><cell role="label"><hi rend="bold">Users</hi></cell><cell role="label"><hi rend="bold">Possession of content</hi></cell><cell role="label"><hi rend="bold">Technical environment</hi></cell><cell role="label"><hi rend="bold">Access</hi></cell><cell role="label"><hi rend="bold">Interlibrary loan</hi></cell><cell role="label"><hi rend="bold">Distribution of costs</hi></cell><cell role="label"><hi rend="bold">Financial support</hi></cell></row>
<row><cell><hi rend="bold">1 - De facto archival agent (e.g., OhioLink, CSIRO)</hi></cell><cell>Made to the readers using the archive or to consortium members</cell><cell>Users are primarily bench scientists with information needs similar to those of other users of the publisher's online content</cell><cell>Perpetual license is the functional equivalent of subscriber ownership of content, but possession is governed by contact law (i.e., the license) rather than copyright law</cell><cell>Local load of content; rendering software identical to that ordinarily provided by the publisher</cell><cell>License imposes few restrictions for authorized users; no online access allowed to others unless a separate archival agreement is reached (at which time the de facto archival agent may become a self-designated archival agent)</cell><cell>As a ScienceDirectOnSite licensee, may provide interlibrary loan services by creating paper output from online content</cell><cell>Costs borne by licensing library or distributed among consortium members</cell><cell>Costs may be supported, in part or whole, by state or other government funds</cell></row>
<row><cell><hi rend="bold">2 - Self-designated archival agent (e.g., National Library of the Netherlands)</hi></cell><cell>Made to readers or to libraries, generally within a given geo-political unit</cell><cell>Same as above, except that national libraries would likely have relatively few bench scientists working onsite</cell><cell>Same as above</cell><cell>Same as above</cell><cell>License imposes few restrictions as regards readers physically present at the archival agent's service sites; no online access allowed to libraries beyond the archival agent except, temporarily, in the case of service disasters the publisher is otherwise unable to handle</cell><cell>Same as above</cell><cell>Borne solely by the archival agent, which may be a government agency; copyright deposit laws may be relevant</cell><cell>Provided by archival agent as a matter of mission</cell></row>
<row><cell><hi rend="bold">3 - Publisher-archival agent partnership (e.g., Yale/Elsevier partnership)</hi></cell><cell>Made to the publishers and, through the publisher, to readers and libraries that do not benefit from the commitments made by other archival agents</cell><cell>Users are primarily not bench scientists but those pursuing the historical inquiries typically supported by archival services; ordinary users of the publisher's content that is no longer commercially viable are also supported by the archive</cell><cell>Same as above</cell><cell>Local load of content; metadata, storage technology, and rendering software may differ from that ordinarily provided by the publisher, given the different audience of users</cell><cell>License sets terms similar to those for self-designated archival agents for the commercially viable part of the publisher's content; few restrictions on access to the content that it not commercially viable; protection against service disasters is a possible, but secondary, mission</cell><cell>Interlibrary loan for commercially viable content is not part of the agent's mission; few restrictions on access to the content that is no longer commercially viable</cell><cell>Borne by the archival agent; publisher may wish to subsidize archival activity</cell><cell>Archival agent, acting independently or with the publisher partner, may seek subscribers to its services; given the focus on content that is not commercially viable, subscriptions would be non-for-profit in nature</cell></row>
</table></p>

<div4 type="subpart" n="01"><head>NOTES</head>
<p><hi rend="bold">NOTE 1:</hi> A library willing to negotiate a national site license could function for an entire nation in the manner of a consortial archival agent.</p>
<p><hi rend="bold">NOTE 2:</hi> The access column defines the scope of library operational security provided by each archival agency. For instance, the consortial archival agent ensures permanent online access to all of the publisher's content but only to consortial members, while the publisher-archival agent partnership ensures largely unrestricted permanent online access only to commercially non-viable content.</p>
<p><hi rend="bold">NOTE 3:</hi> The defining concern of the publisher-archival agent partnership, as distinguished from the two other kinds of archival agent, is to identify content that is not commercially viable. Such an agent seeks in this way to minimize conflicts between the commercial mission of the publisher and the preservation/access mission of the archival agent. No boundary between commercially viable and non-viable content has yet been identified. Such boundaries may in time be established by a "rule of thumb" (as has been done with JSTOR or proposed in the case of PubMed Central), or by invoking some set of yet-to-be-specified "trigger events."</p>
<p><hi rend="bold">NOTE 4:</hi> Self-identified archival agents and publisher-archival agent partnerships might provide access to commercially viable content to libraries that once had licenses for that content and/or to libraries in developing countries to which publishers wish, as a matter of good public policy, to provide content for free or at steeply discounted prices.</p>
<p><hi rend="bold">NOTE 5:</hi> Should boundaries between commercially viable and non-viable content be established, consortial and self-identified archival agents may wish to reshape their services with regard to those boundaries, to provide some online access to readers beyond the boundaries of the consortium or physical site. If enough archival agents did this, it is not clear that the publisher-archival agent partnership would have a distinctive function.</p>
<p><hi rend="bold">NOTE 6:</hi> One reason for the maintenance of paper publications is our present inability to identify a boundary between commercially viable and non-viable content. The costs associated with these subscriptions therefore represent, in part, the preservation costs libraries bear. Put differently, the cost burdens of paper publication result, in part, from libraries' unwillingness to put their preservation mission at risk and from publishers' unwillingness to put their commercial mission at risk. This impasse exists because, for online information resources, libraries do not own any information carrier that can be preserved.</p>
</div4>
</div3>

<div3 type="part" n="02"><head>Appendix F. List of Site Visits During Planning Year</head>

<p><table>
<row><cell role="label">Date</cell><cell role="label">Organization</cell><cell role="label">Location</cell><cell role="label">Purpose</cell></row>
<row><cell>26-30 March 2001</cell><cell>Elsevier Science <lb/><lb/>National Library of <lb/>the Netherlands</cell><cell>Amsterdam <lb/><lb/>Den Haag</cell><cell>Fact-finding trip to learn about the production of electronic journals by ES and to learn about the digital archive work being done at the National Library of the Netherlands.</cell></row>
<row><cell>6-11 September 2001</cell><cell>British Library <lb/><lb/>National Library of <lb/>the Netherlands</cell><cell>London <lb/><lb/>Den Haag</cell><cell>Validation of OAIS and OAI models to build prototype archives; learn about best practices from sites that have ongoing archival programs.</cell></row>
<row><cell>7 May 2001</cell><cell>J.P. Morgan Chase</cell><cell>Yale University <lb/>New Haven, CT</cell><cell>Fact-finding visit to learn about potential economic benefits of outsourcing the storage component of an archive.</cell></row>
<row><cell>11-12 October 2001</cell><cell>Elsevier Science</cell><cell>Amsterdam</cell><cell>Fact-finding trip to learn more about potential content beyond traditional journals, the production process, and metadata population.</cell></row>
</table></p>
</div3>

<div3 type="part" n="03"><head>Appendix G. Possible Structure for the Yale Digital Library</head>
<p>Desirable Characteristics of a Digital Library Infrastructure:</p>

<list>
<item>Integration of system components</item>
<item>Consolidation or aggregation of proliferating stand-alone databases</item>
<item>Integration of a wide variety of digital objects and metadata schemas</item>
<item>Integration of search interfaces and delivery mechanisms</item>
<item>Flexible output: general, specialized, and personalized interfaces</item>
<item>Interoperability with external systems and institutions</item>
<item>Scalability</item>
<item>Versatility</item>
<item>Sophisticated management tools</item>
<item>Direct focus on teaching and research needs</item>
</list>

<p><figure entity="yaleimage001"><head></head><figDesc>Yale Digital Library</figDesc></figure></p>

<p>This diagram illustrates selected existing systems in the Yale Library and explores several future directions, with a focus on digital preservation. At the heart of the diagram is a new preservation archive for digital objects and associated metadata based on the Open Archival Information System model. The public interfaces on the right interact directly with this preservation archive. Those on the left rely upon completely independent systems where metadata and digital objects are stored separately from the archive. Content sources in the second column feed these systems in various ways:</p>
<p>Journal Publisher (Elsevier)</p>

<list>
<item>Public access through full-featured online system maintained by vendor</item>
<item>Formal partnership between Yale and vendor for archiving journal content</item>
<item>Limited access to archive through OAI interface (Open Archives Initiative)</item>
</list>

<p>Digitized Content (Visual Resources, Beinecke, Digital Conversion Facility, Divinity, etc.)</p>

<list>
<item>Public interface supplies sophisticated visual environment for teaching and study</item>
<item>Insight system houses derived images (JPEGs and SIDs) and public metadata</item>
<item>Archive houses original TIFF images and enhanced metadata</item>
<item>Archive used only for image recovery or migration to new delivery platform</item>
</list>

<p>Electronic Yale University Records</p>

<list>
<item>University records preserved for legal and historical purposes, low-use material</item>
<item>Content sent directly to archive; no duplication of data in separate system</item>
<item>Public interface retrieves digital objects directly from archive</item>
</list>

<p>Born-Digital Acquisitions</p>

<list>
<item>Content is imported or directly input into new public repository</item>
<item>Potential home for digital scholarship resulting from collaborative research projects</item>
<item>Archival copies are transmitted from there to the archive</item>
</list>

<p>Finding Aids</p>

<list>
<item>Finding aids distributed both to public service system and to archive</item>
</list>

<p>Preservation Reformatting (Digital Conversion)</p>

<list>
<item>Digitized content sent directly to archive</item>
<item>Hard-copy may be produced from digital version for public use</item>
<item>Access to digital copy through custom application fed from archive</item>
<item>Digital copy and original artifact may appear in national registry</item>
</list>

<p>Online Catalog</p>

<list>
<item>Cataloging data resides only in LMS (NOTIS or Endeavor Voyager)</item>
<item>Integration achieved through MetaLib portal and lateral SFX links</item>
</list>

</div3>
</div2>
</div1>

</body>
<back>

<div1 type="section" n="09"><head>Minimum Criteria for an Archival Repository of Digital Scholarly Journals</head>
<p>Version 1.2 <lb/>May 15, 2000</p>

<div2 type="subsection" n="01"><head>Introduction</head>
<p>This document sets out the minimum criteria of a digital archival repository that acts to preserve digital scholarly publications. It is based closely on the Reference Model for an Open Archival Information System and modified to reflect the specific needs of library, publishing, and academic communities. It also indicates some of the key research issues that are likely to emerge for those who establish digital archival repositories that meet these criteria. The research issues are divided into three categories: those associated with the deposit of data, those associated with preservation, and those associated with access.</p>
<p>At the outset, Dan Greenstein and Deanna Marcum extracted the relevant sections of the OAIS Reference Model and presented criteria to a group of fifteen librarians for review and comment. The librarians suggested a number of changes, and the document was modified to reflect their views <xref doc="archreq">(Version 1.1)</xref>. On May 1, a group of commercial and non-profit scholarly journal publishers met to review the minimum criteria. They propose the adaptations found in this version of the criteria (Version 1.2)</p>
</div2>

<div2 type="subsection" n="02"><head><hi rend="bold">Criterion 1. A digital archival repository that acts to preserve digital scholarly publications will be a trusted party that conforms to minimum requirements agreed to by both scholarly publishers and libraries.</hi></head>
<p>Agreed minimum criteria are essential. Libraries need them to assure themselves and their patrons that digital content is being maintained. Publishers need them so they may demonstrate to libraries, but also to their authors, that they are taking all reasonable measures to ensure persistence of their publications. Finally, emerging repositories need them as a blueprint for services, but also as a benchmark against which service can be measured, validated, and above all, trusted by the libraries and publishers that rely upon them.</p>
<p>Trusted parties may include libraries, publishers, or third parties providing archival services.</p>
<p>The key research question entails the definition of those criteria. Initial meetings with librarians and publishers are an essential first step in developing these definitions. Their refinement is expected to be an iterative process, one that takes account of experience in building, maintaining, and using digital archival repositories.</p>
</div2>

<div2 type="subsection" n="03"><head><hi rend="bold">Criterion 2. A repository will define its mission with regard to the needs of scholarly publishers and research libraries. It will also be explicit about which scholarly publications it is willing to archive and for whom they are being archived.</hi></head>
<p>This definition will help to focus the repository on the nature and extent of digital information it will acquire and on the requirements of the research library as the primary recipient of any data disseminated by the repository.</p>

<list>
<head><hi rend="bold">Research issues:</hi></head>
<item>Mission statements that document the scope and nature of materials a repository aims to collect, the strategy and methods it adopts for developing its collections (attracting deposits), and the community of libraries (and other users) it seeks to serve. The statement of scope should use a common syntax that is universally accepted.</item>
<item>The development of registries that document what scholarly publications are archived where (and implicitly those not archived at all) is a further research issue.</item>
</list>
</div2>

<div2 type="subsection" n="04"><head><hi rend="bold">Criterion 3. A repository will negotiate and accept appropriate deposits from scholarly publishers.</hi></head>
<p>A repository will develop criteria to guide consideration of what publications it is willing to accept. Criteria may include subject matter, information source, degree of uniqueness or originality, and the techniques used to represent the information.</p>
<p>Individual negotiations with publishers may result in deposit agreements between the repository and the data producer. Deposit agreements may identify the detailed characteristics of the data and accompanying metadata that are deposited, the procedures for the deposit, the respective roles, responsibilities, and rights of the repository and the data procedure with regard to those data, references to the procedures and protocols by which a repository will verify the arrival and completeness of the data, etc. The deposit will come with a schedule in which that publisher states what is being deposited, and the repository will verify the deposit.</p>

<list>
<head><hi rend="bold">Research issues: <lb/><hi rend="italics">Deposit</hi></hi></head>
<item>Selection criteria used by the repository to review potential accessions.</item>
<item>Guidelines for depositors that identify preferred or required data and metadata formats, transmission methods and media, etc.</item>
<item>Procedures for verifying the arrival and completeness of deposited data and metadata.</item>
<item>Adherence by several archives to some common range of data and/or metadata formats.</item>
</list>
</div2>

<div2 type="subsection" n="05"><head><hi rend="bold">Criterion 4. A repository will obtain sufficient control of deposited information to ensure its long-term preservation.</hi></head>
<p>In this respect, a repository will at a minimum require licenses that allow it sufficient control to accession, describe, manage, even transform deposited data (and accompanying metatdata) for the sake of their preservation. Publishers may want to negotiate re-depositing when migration occurs. In any event, publishers must have the right to audit the contents of their deposited data. Where repositories act in association with one another (e.g. to ensure sufficient redundancy in the preservation process), they may also require rights allowing them to mirror or deposit data with other associated archives.</p> <p>Further, repositories will need to pay attention to whether and how their rights and responsibilities with regard to any particular deposit may change through time. For example, where a depositor ceases to supply its materials to the scholarly community, the repository must be positioned to supply those materials to existing licensees (perhaps at a fee). Similarly there must be a statement about the rights of the publisher if a repository goes out of business.</p>

<list>
<head><hi rend="bold">Research issues: <lb/><hi rend="italics">Deposit</hi></hi></head>
<item>Fuller understanding of how a respository's rights and responsibilities change over time.</item>
</list>

<list>
<head><hi rend="bold"><hi rend="italics">Access</hi></hi></head>
<item>Acceptable licenses and licensing principles.</item>
</list>
</div2>

<div2 type="subsection" n="06"><head><hi rend="bold">Criterion 5. A repository will follow documented policies and procedures which ensure that information is preserved against all reasonable contingencies.</hi></head>
<p>Preservation strategies and practices are not right or wrong, but more or less fit for their intended purposes. No general theory of digital preservation or data migration is likely to become available soon. Thus, data in different formats may require different strategies and these may need to be worked out with the data producer (depositor). Documenting how and where different preservation strategies and practices prove cost effective and fit for their intended purposes will be a primary interest of any coordinated approach to developing preservation capacity appropriate to scholarly publishing, research library, and academic communities. Because preservation practices are likely to vary across repositories, and because we have an interest in encouraging the development of different practices, we may wish simply to request that participants in any such coordinated effort agree to document the practices they adopt and disclose them to some community review and evaluation.</p>

<list>
<head><hi rend="bold">Research Issues: <lb/><hi rend="italics">Deposit:</hi></hi></head>
<item>Preservation metadata</item>
</list>

<list>
<head><hi rend="bold"><hi rend="italics">Preservation:</hi></hi></head>
<item>Migration strategies (and their application with specific data formats)</item>
<item>Data validation</item>
<item>Scaleable infrastructure</item>
</list>
</div2>

<div2 type="subsection" n="07"><head><hi rend="bold">Criterion 6: A repository will make preserved information available to libraries, under conditions negotiated with the publisher.</hi></head>
<p>Although repositories will need to support access at some level, those services should not replace the normal operating services through which digital scholarly publications are typically made accessible to end users. The access rights must be made explicit and must be mutually agreed upon by the publisher and the repository.</p>

<list>
<head><hi rend="bold">Research issues: <lb/><hi rend="italics">Access</hi></hi></head>
<item>Resource discovery mechanisms</item>
<item>Access (data dissemination) strategies supported by archives</item>
<item>User licenses and how enforced</item>
<item>Template licensing arrangements</item>
</list>
</div2>

<div2 type="subsection" n="08"><head><hi rend="bold">Criterion 7. Repositories will work as part of a network.</hi></head>
<p>At a minimum, respositories will need to operate as part of a network to achieve a satisfactory degree of redundancy for their holdings. Although an appropriate level of redundancy is difficult to quantify (let alone mandate), it will ideally extend for any single data to three archival sites, at least one of which is located off shore.</p>
<p>A network of repositories offers additional advantages to libraries and scholarly publishers. Libraries may benefit from common finding aids, access mechanisms, and registry services that are supported by a network and allow libraries more uniformly to identify and gain in trusted repositories. Publishers may benefit from having access to a single repository or group of repositories that specialize in publications of a particular type and for the cost efficiencies that emerge from within a network.</p>

<list>
<head><hi rend="bold">Research issues: <lb/><hi rend="italics">Deposit:</hi></hi></head>
<item>Perceived value of:
<list>
<item>Standard methods for data deposit</item>
<item>Standard deposit licenses and/or user agreements</item>
</list></item>
</list>

<list>
<head><hi rend="bold"><hi rend="italics">Preservation:</hi></hi></head>
<item>Perceived value of:
<list>
<item>Standard preservation and other metadata</item>
<item>Standard migration strategies and implementation procedures</item>
<item>Standard specifications for physical media</item>
<item>Standard accreditation of requirement conformant archives</item>
</list></item>
</list>

<list>
<head><hi rend="bold"><hi rend="italics">Access:</hi></hi></head>
<item>Perceived value of:
<list>
<item>Standard interfaces among repositories</item>
<item>Standard methods for data dissemination</item>
<item>Standard resource discovery practices.</item>
</list></item>
</list>

<p>For further information, please consult the following pages:</p>

<list>
<item><xref doc="archreq">Minimum criteria for an archival repository of digital scholarly journals, <hi rend="bold">Version 1.1</hi></xref></item>
<item><xref doc="presjour">Preservation of digital scholarly journals</xref></item>
<item><xref doc="pracshare">Framework for sharing archival practices</xref></item>
</list>
</div2>
</div1>

<div1 type="section" n="10"><head>Appendix II: E-Journal Archive DTD Feasibility Study: a report commissioned by Harvard University from Inera, Inc. on the feasibility of developing a common archival article DTD.</head>
<p><xref doc="diglibpreservehadtdfs">http://www.diglib.org/preserve/hadtdfs.pdf</xref></p>
</div1>

<div1 type="section" n="11"><head>Background Documents</head>
<div2 type="subsection" n="01"><head>Preface</head>
<p>In early 2000, the DLF, CLIR, and CNI began to address these questions with a view to facilitating some practical experimentation in digital archiving. In a series of three meetings -- one each for librarians, publishers, and licensing specialists, respectively -- the groups managed to reach consensus on the <xref doc="criteria">minimum requirements</xref> for e-journal archival repositories.</p>
<p>Building on that consensus, <xref doc="mellon">The Andrew W. Mellon Foundation</xref> solicited proposals from selected research libraries to plan the development of e-journal repositories meeting those requirements. Seven major libraries received grants from the Andrew W. Mellon Foundation, including the New York Public Library and the university libraries of Cornell, Harvard, MIT, Pennsylvania, Stanford, and Yale.</p>
<p>Yale, Harvard, and Pennsylvania worked with individual publishers on archiving the range of their electronic journals. Cornell and the New York Public Library worked on archiving journals in specific disciplines. MIT's project involved archiving "dynamic" e-journals that change frequently, and Stanford's involved the development of specific archiving software tools.</p>
</div2>

<div2 type="subsection" n="02"><head>Summary of the Projects and their Progress</head>
<div3 type="part" n="01"><head> Cornell University Library: Project Harvest</head>
<div4 type="subpart" n="01"><head>The Project as Planned</head>
<p>Can a major research library effectively become an archive for numerous electronic journals, published by different publishers, in one field? Because Cornell is a land-grant university, its library has spearheaded national initiatives to ensure the preservation of agricultural literature. It also has developed expertise in creating and preserving digital library material. Now it will try to organize, design, and implement a digital archive for agricultural e-journals.</p>
<p>Project Harvest plans to invite as many as a dozen publishers of core journals in agricultural science to work with Cornell staff on a model agreement for archival deposit. The agreement will define responsibilities of both the archival repository and those who deposit journals in it, specify access policies including copyright clearance conditions, and resolve numerous other pertinent issues.</p>
<p>Simultaneously, the project staff will devise a model architecture for the e-journal repository, providing for data ingestion, storage, management, migration, and access. Among other things, the project will investigate contractual, economic, and technical implications of whether the repository should be "dark" (the content preserved on some stable format with minimal functionality, essentially for emergency use) or "living" (the content no longer maintained by the publisher but regularly accessible from the archive).</p>
<p>Also the project will deal with questions of how to ensure scholarly acceptance (trust and use), how to develop the repository organizationally, how to manage its growth, and ultimately, how to finance it. Not least of all, the staff is working on digital-repository certification standards, which Cornell would plan to meet, and which, along with the prospective model agreement and architecture, eventually could help others.</p>
</div4>

<div4 type="subpart" n="02"><head>Project Developments as of 5 May 2001</head>
<p>Project Harvest has hired the publisher-relations specialist called for in its plan and has worked its way through early housekeeping requirements. Additionally, it has established criteria for selecting partners, identified agricultural journals with which it wishes to work at the outset, and started contacting publishers to arrange meetings. Moreover, Project Coordinator Peter Hirtle and his colleagues have begun consideration of attributes for an ideal system. They expect to make more information on their work available soon on a Web site they are drafting.</p>
</div4>
</div3>

<div3 type="part" n="02"><head>Harvard University Library: A Study of Electronic Journal Archiving</head>
<div4 type="subpart" n="01"><head>The Project as Planned</head>
<p>Can a major research library arrange with multiple publishers to archive many of the varied journals and databases that it provides in its electronic gateway? The Harvard University Library's list of such resources exceeds 2,000. Harvard gets paper copies also, primarily for preservation, but the Library does not regard this costly duplication as sustainable. Now it will plan an archive to preserve journals electronically, based on infrastructure for the creation, storage, and delivery of digital library collections in which it has invested heavily in the past two years.</p>
<p>In its planning, Harvard will analyze a two-part question: Which journals-and which components of them-will it archive? Answering will involve arranging with at least one journal publisher to provide a significant volume of material to test the scaling of the archive, working with that publisher (and possibly also with an actively publishing scholarly society) to develop a model for an archiving relationship, and selecting titles to archive from the list of journals that Harvard now acquires only in digital copies.</p>
<p>Harvard's plan includes drafting a policy on the components part of the question-will the archive contain only article texts from journals or also their covers, ads, letters-to-the-editor, book reviews, and digital links? The project also will investigate technical requirements for accession automation, archival formatting, on-going validation, bibliographic control, naming systems, access management, storage strategy, and output facilities.</p>
<p>The project will not now negotiate archiving licenses, but will explore what publishers are willing to provide and under what arrangements. A major concern is cost-designing the archiving process to minimize marginal costs, developing a model for cost distribution, and exploring long-term options for financial support.</p>
</div4>

<div4 type="subpart" n="02"><head>Project Developments as of 5 December 2001</head>
<p><hi rend="italics">Marilyn Geller, project manager of the Harvard project, provides the following report</hi>: Since the last update this summer, Harvard has completed a first round of business meetings and technical meetings with our publisher-partners, Blackwell, John Wiley, and University of Chicago Press. We have also received a <xref doc="diglibpreservehadtdfs">report</xref> from Inera, Inc.on the feasibility of developing a common archival article DTD [document type description].</p>
<p>Our business meetings have helped us refine the mission of the archive as a set of services and a logical organization for the preservation of significant intellectual content of the journal independent of the form in which that content was originally delivered. Substantive discussions have also taken place around the issue of the archive's stakeholders including researchers, authors, societies, publishers, and subscribers as represented by libraries. This stakeholder community, however it is organized, would have the opportunity to review and comment on policies and procedures for the development, administration, ongoing maintenance, and financing of the archive. Policies regarding access and financing of the archive continue to evolve.</p>
<p>The project's technical team has met with each of the publishers regarding the principles of technical development and the specifications for ingesting content. The most significant technical development in the last few months has been the delivery of the Inera study on the feasibility of creating a common archival DTD that would allow the archive to received material from all publishing partners tagged in the same manner. Ten publishers participated in this study by contributing their DTDs, documentation, and samples for review. The significant conclusions drawn from this study are that it is possible to create a common archival article DTD that would represent the intersection and the union of several existing publisher DTDs and that thorough documentation and quality assurance tools would be essential to insure that conversion is successful. Because this study has so much potential for resolving ingest, storage and delivery issues, it is being made available to the entire scholarly communications community. We are optimistic that this will encourage discussion and progress in the technical aspects of e-journal preservation.</p>
<p>In the coming months, we hope to finalize the conceptual agreement with our publishing partners, document technical development, operations, and staffing of the archive, and refine the business model that will sustain this archive over time.</p>
</div4>

<div4 type="subpart" n="03"><head>Project Developments as of 31 August 2001</head>
<p>In the past few months, both the Steering Committee and the Technical Team of the Harvard E-Journal Archiving Project have made significant progress in refining their broad understanding of the research topic and exploring the detailed implications of this understanding. As a whole, Project Manager Marilyn Geller reports, the project has selected and begun to discuss the business and technical models with three publishers as partners in this project: Blackwell, University of Chicago Press, and Wiley.</p>
<p>Discussions of the business model have been centering around the nature of access to the archive; specifically, the project and the publisher partners are exploring who should have access to the archives, when, under what circumstances, and how. Initially, the project proposed three access "trigger" events: (1) when the content is no longer available on-line, (2) when the title ceases to be published, and (3) after a defined amount of time has passed; and it is the third type of trigger event that is generating comment and being refined.</p>
<p>The project also has delved into the issue of costs to understand what elements of the process of building and maintaining the archive are sensitive to size or quantity and how this might influence a model for sustainable financing of the archive. Project staff envision that both the number and kind of digital objects to be deposited will increase over time and may be difficult to estimate. To a lesser extent, the size of the archived content will have an effect on storage costs. Additionally, the cost of migrating formats will be dependent on the number of digital objects to be migrated, the frequency of migration, and the technology available to accomplish the migration.</p>
<p>Harvard is basing its archive on the architectural framework provided by the Open Archival Information System (OAIS) Reference Model. Under the OAIS model, material from a content producer is transmitted to the archive in a form called a Submission Information Package, or SIP. We have put together a <xref doc="harvardsip10">tentative draft proposal</xref> for the technical specifications of the SIP that defines acceptable data formats, file naming conventions, bibliographic and technical metadata, and so forth. We are scheduling a round of meetings with technical representatives of our publishing partners to discuss and refine this proposal.</p>
<p>One of the key ideas we are exploring on the technical side is whether it is practical to design a common XML DTD that will reasonably represent the intellectual content of archival e-journal articles. Such a common DTD would simplify the work of gathering content from a variety of publishers using different DTDs. In this study, we have contracted with Inera because of their substantial background in this area and will look at the article DTDs being used by our publishing partners as well as a sampling of other DTDs representing large volumes of content and interesting elements. After determining the common elements of these DTDs, we hope to analyze the usefulness of this approach paying attention to what information is common to all DTDs and what information may be lost by using this common DTD.</p>
</div4>
</div3>

<div3 type="part" n="03"><head>MIT Libraries: Planning for an Archive of Dynamic E-Journals</head>
<div4 type="subpart" n="01"><head>The Project as Planned</head>
<p>Can a major research library capture and archive new scholarly "publications" called "dynamic e-journals"? These are Web sites where scholars share their findings unbound by conventions for articles published in periodic issues of print journals. Such "publications" provide dynamically updated, centralized access points for a wide-ranging variety of research information, scholarly interaction, and teaching resources in particular fields of study.</p>
<p>Convinced that "the dynamic e-journals currently published represent the leading edge of a broad range of dynamic content that we must learn to capture for future scholars," the MIT Libraries are taking on the challenge.</p>
<p>The challenge is great because Web-site publications change content flexibly; some parts of the content are more valuable to preserve than others; different kinds of content may require different archival treatment; and "look and feel" is less fixed for replication. But to the preservation task, MIT brings both experience with the digital repository infrastructure it already is building and the close relationship it has with the MIT Press, which last year launched CogNet," a central repository for resources for cognitive and brain sciences. The project would seek relationships with other publishers of "dynamic e-journals" as well.</p>
<p>In the planning year, the project may experiment with prototypes of the archiving process, but it will focus on the partnerships, strategies, and plans needed for the project's development. This work will include negotiations with publishing partners, detailed analysis of technical and legal challenges, identification of key technical and legal hurdles that must be addressed, and the development of technical specifications. Thus the project hopes to begin resolving archival issues for these new dynamic publications while they are still evolving.</p>
</div4>

<div4 type="subpart" n="02"><head>Project Developments as of 19 November 2001</head>
<p>The Dynamic E-Journal Archive (DEJA) Project has determined to interface, as anticipated, with MIT's DSpace project, a digital repository for MIT's own digital, intellectual output. DEJA will rely on DSpace's repository for long-term storage and preservation. DEJA, the archive's engine, if you will, will handle all data coming from publishers, verify the data's integrity and completeness, track changes, add metadata, and generally ready SIPs (submission information packages) for DSpace to ingest them. DEJA will similarly call files back from DSpace and create DIPs (dissemination information packages) for the dissemination of information upon users' requests.</p>
<p>In recent weeks, we have concentrated on the interfaces between DEJA-Depot and DSpace. We have also continued our research into the description (using METS and Xlink) of the "spaghettiness" of web journals (the complexity of their inter-connection).</p>
</div4>

<div4 type="subpart" n="03"><head>Project Developments as of 16 August 2001</head>
<p>The project hired Patsy Baudoin as project planner; she reports the following:</p>
<p>Since May, the MIT-Dynamic E-Journal Archive (MIT-DEJA) project has focused on born-digital journals. We have spent time defining "dynamic," identifying what characteristics make e-journals dynamic, including the full range of elements that make up the "webness" of these sites (multimedia, links, navigation systems, data-retrieval algorithms). We have traveled several paths trying to decide what to focus on and how best to capture such characteristics.</p>
<p>Two of the main issues we expect to tackle for the long run are:</p>

<list>
<item>Describing electronic journal sites? - what metadata will the archive need to describe a site and the inter-relationship of its parts to each other and to the whole?</item>
<item>Understanding the quandaries of archiving versions of journal-sites.</item>
</list>

<p>Preliminary discussions with MIT Press and Columbia University's EPIC are underway. No partnership has been shaped yet.</p>
</div4>
</div3>

<div3 type="part" n="04"><head>New York Public Library: Archiving Performing Arts Electronic Journals</head>
<div4 type="subpart" n="01"><head>The Project as Planned</head>
<p>Can a premier public library with vast research collections extend its services in a particular field by establishing secure repositories of archived electronic journals in that field? The New York Public Library (NYPL) will develop a plan to do so for e-journals in the performing arts and such related areas as media studies.</p>
<p>The project builds on several strengths of the NYPL: its long experience in library preservation, its current development of a digital library program, and its performing arts collections, which are among the most extensive in the world. One of four centers in The Research Libraries of the NYPL is its Library for the Performing Arts, at Lincoln Center.</p>
<p>Project staff will identify and select relevant journals, including those created digitally, those published in both print and electronic forms, and those published as an online supplement to print titles. Staff will then work with willing e-journal publishers to develop agreements on archival rights and responsibilities. Staff also will work on a technical implementation plan for the archive, an acquisitions and growth plan, an organizational model, staffing requirements, access policies, and long-term funding options. Special attention will be given to the development of methodologies that the archive would use to validate the archival processes and assure the user communities that the journals for which the archives is responsible will be accessible and readable into the future.</p>
<p>The project faces special challenges in dealing with performing arts e-journals because their publishers are often small rather than major commercial operations, and they make great use of embedded multimedia functions (such as digital sound and video) and hypertextuality (such as links to other Web presences). Questions will include how much commitment can be made to original presentation style.</p>
</div4>

<div4 type="subpart" n="02"><head>Project Developments as of 29 August 2001</head>
<p>Jennifer Krueger, deputy to the director of NYPL's research libraries, is project officer. She reports that the project has identified a core group of electronic journals in the performing arts from which to derive a final list that will give the project a range of partners. The project plans to include journals published by a university press, by a commercial press, and by small, independent publishers whose publications are important in the performing arts but who are not part of an organization that could be expected to take care of them. Also, the journals selected will be in one or more languages besides English. Work is under way to engage such e-journals as participants in exploring the numerous issues involved in archiving, including means of handling a variety of ingest formats, the legal responsibilities of both parties, user needs and approaches to the archive and its data, decisions about advertisements and different media types contained in the original issues, and basic technological issues about where and how to store.</p>
</div4>
</div3>

<div3 type="part" n="05"><head>University of Pennsylvania Library: Archiving and Preserving E-Journals</head>
<div4 type="subpart" n="01"><head>The Project as Planned</head>
<p>Can a major research library take full advantage of electronic journals by partnering with academic publishers to ensure long-term access through creation of an e-journal archive? The University of Pennsylvania Library will try to do so by building on a successful relationship it already has with a major scholarly publisher.</p>
<p>For more than a year, the library has been working with the Oxford University Press to make its current book releases in history available to the library's local community. This has given the library experience in receiving a publisher's digital content, converting it to a form suitable for on-line use, maintaining it, and making it available under terms beneficial both to the publisher and to the library's scholarly community. Also of use in the e-journal archiving project will be hardware already in place at the library and a database of information about e-journals to which the library subscribes.</p>
<p>In the planning year, the project staff expects to select a set of e-journals, arrange with their publishers to archive them, and negotiate agreements for doing so that identify rights and responsibilities. Also the project will determine and arrange to support the metadata and workflow needed to receive, validate, archive, and provide access to e-journals; design and begin installing an information base for storing and accessing archived journal content and related metadata; begin to install documentation and support for the data formats and protocols used by the archive, and start acquiring and archiving journals, indexing them, providing metadata, and providing content to authorized parties on an experimental basis.</p>
<p>The planning year will conclude with dissemination of results and development of a plan for continuing and growing the archive on a permanent basis.</p>
</div4>

<div4 type="subpart" n="02"><head>Project Developments as of 1 May 2001</head>
<p>Oxford University Press has agreed in principle to work with the University of Pennsylvania Library in the e-journal preservation project, and the project staff, lead by John Mark Ockerbloom, is working on a draft agreement specifying rights and responsibilities for both parties. At the same time, the project is progressing in its work on metadata descriptions.</p>
</div4>
</div3>

<div3 type="part" n="06"><head>Stanford Libraries: LOCKSS, A Distributed Digital Preservation System</head>
<div4 type="subpart" n="01"><head>The Project as Planned</head>
<p>Can an automated, decentralized preservation system protect libraries against loss of access to digital materials such as electronic journals to which they have subscribed? Fear of the demise of journals or problems with their publishers has inhibited library investment in electronic resources. Staff members of the Stanford University Libraries, a major research library system experimenting with automation, believe they have found one solution in a system called LOCKSS.</p>
<p>LOCKSS, which stands for "Lots Of Copies Keep Stuff Safe," provides a bootable floppy disk that converts a generic PC into a preservation appliance. The PC runs an enhanced Web cache that collects new issues of the e-journal and continually but slowly compares its contents with other caches. If damage or corruption is detected, it can be repaired from the publisher or from other caches. The intent is to make it feasible and affordable even for smaller libraries to preserve access to the e-journals to which they subscribe.</p>
<p>With support from NSF and Sun Microsystems, Stanford developed an alpha version of the system and ran a 10-month test with a single journal, six libraries, and 15 caches. With the Mellon funding and continued support from Sun, a more complete beta implementation has been developed. The beta version is being distributed to more than 40 libraries worldwide. They will run approximately 60 caches. Four "shadow" publisher machines at Stanford will mirror approximately 15 GB of content from real journals, and will simulate brief failures and permanent outages. Failures of the caches and corruption of their contents will also be simulated, as will attacks by simulated "bad guys."</p>
<p>The beta software will be released as open source. With experience from the beta tests and further funding, Stanford hopes to produce a production version in 2002.</p>
</div4>

<div4 type="subpart" n="02"><head>Project Developments as of 20 July 2001</head>
<p>The project has begun its worldwide beta phase, which will test LOCKSS security, usability, and software performance, including impact on network traffic. More than 40 libraries with 60 widely distributed and varyingly configured caches have signed onto the project, and 35 publishers are endorsing the beta test. Beta test sites include major libraries, such as the Library of Congress, and smaller ones, such as the University of Otago in New Zealand. The publishers' Web sites are simulated on shadow servers to isolate LOCKSS data streams, measure network traffic, and test whether LOCKSS works when the publisher "goes away." Once the beta software is stable, representative government documents and other non-HighWire publisher content will be added to the test.</p>
<p>In mid-July, Project Manager Victoria Reich reported that the project had passed an important milestone. Of participating library sites, 35, almost all, have installed and are running version 06122001 of the beta software. 45 machines are simultaneously participating in the beta test. By comparison, the alpha test had a maximum of 18 simultaneously participating machines.</p>
<p>The Stanford team has improved the security of the user interface and tweaked the system to respond to various worldwide network configurations. Additionally, the LOCKSS protocol (LCAP) is working well. This larger international beta test bed is so far using one journal (the BMJ). It has identified and repaired content damage in some local library LOCKSS caches.</p>
<p>The next steps are to bring the few remaining beta sites online and to slowly add more journal content to the system.</p> <p>See <xref doc="lockssStanford">lockss.Stanford.edu</xref> for more information and status updates.</p>
</div4>
</div3>

<div3 type="part" n="07"><head>Yale Library and Elsevier Science: A Digital Preservation Collaboration</head>
<div4 type="subpart" n="01"><head>The Project as Planned</head>
<p>Can a major research library and a major publisher of electronic journals on multiple subjects develop mutually satisfactory agreements and technologies for ensuring long-term access to those journals? The Yale University Library, which has staff expertise in digital-information preservation and licensing, and Elsevier Science, which publishes numerous electronic journals varied in size and content, have agreed to explore that question together.</p>
<p>Elsevier will continue to provide ordinary business access to e-journals, which Yale will archive when they no longer are commercially viable, and will make accessible for future inquiries that could range far beyond contemporary use. For this archive, Elsevier intends to provide coded content and metadata; Yale intends to provide rendering software and a computer environment for use.</p>
<p>Technology to be developed will include content storage with database-management functionality, process-management software, and a user interface (a Web server-browser for requesting, rendering, and displaying data). Central to this will be a technical means for separating e-journal content from original functionality to allow "historical" researchers to use the material in ways more congenial to them while remaining assured of the authority and authenticity of the content.</p>
<p>In addition to developing the technology, the project will try to identify the circumstances in which the library would become the access provider, work out an agreement on intellectual property rights in those circumstances, and answer many questions about good design and management of a digital archive. Because of the variety in Elsevier's publications, the resulting design may be scaleable for adaptation by other libraries and publishers.</p>
</div4>

<div4 type="subpart" n="02"><head>Project Development as of July 2001</head>
<p>The following is a mid-year status report on the Yale University Library/Elsevier Science Digital Archives Planning Project, generously supported by the Andrew W. Mellon Foundation. This report focuses on three lines of inquiry pursued since January 2001, involving technical questions, preservation metadata, and the service mission of a digital archive.</p>
<p>The principal investigators have been Scott Bennett and Ann Okerson of Yale University. Paul Conway, David Gewirtz, and Kimberly Parker are other Yale library staff who have participated deeply and consistently throughout the project. Karen Hunter, Geoffrey Adams, and Emeka Akaezuwa have led the participation of Elsevier Science in the project. The partnership built for this project between the Yale library and Elsevier Science has been cordial, candid, and highly productive. Both organizations are committed to understanding good archival practice for electronic publications, and both strongly wish to help create a functioning digital archive.</p>
<p>David Gewirtz visited the Electronic Warehouse maintained for its publications in Amsterdam by Elsevier Science. He also visited the National Library of the Netherlands. Titia van der Werf, NEDLIB Project Administrator at the National Library, visited for a day in New Haven. Both Yale and Elsevier Science staff met separately with William Telkowski and his colleagues at JP Morgan-Chase to discuss that firm's digital archives service. Karen Hunter had conversations about our project with staff at OCLC, the British Library, the National Library of the Netherlands, the University of Toronto, Australian academic libraries, and some libraries in Japan. Yale staff had conversations relating to our project with Sun Micro Systems staff in California.</p>
<p>TECHNICAL INQUIRIES. Early in the project, David Gewirtz purchased and commissioned a Sun server and complementary disk and tape subsystems. Elsevier Science sent us 18 tapes containing, in about 500-700 gigabytes of data, all of the e-journals it published between 1995 and November 1999. Elsevier Science also arranged for the project to use the ScienceServer software. With these and OpenText software in place, David and other project participants have pursued two inquiries.</p>

<list>
<item>We have documented the technical characteristics of Elsevier Science's e-journals. We have identified the various Document Type Definitions used by Elsevier Science and the technical standards that have controlled the production and distribution of its content since 1992. We have also documented the current workflow used in the production of Elsevier Science content. See Document 5 (in the Appendix listing project documents) and Document 10.</item>
<item>We have begun to investigate the technical configuration that the data store for a digital archive might take. See Document 13. David Gewirtz and Geoffrey Adams are consulting closely on this matter.</item>
</list>

<p>METADATA. Paul Conway has led a consideration of preservation metadata. He started with a review of the literature (Document 3) and with analyses of metadata issues (Document 4) and of preservation metadata in the OAIS model (Document 7). With this background, Paul and others studied the metadata provided for and actually created in the Elsevier Science EFFECT production standard. They also compared these findings with the standards for preservation metadata advanced by the British Library and by the NEDLIB project at the National Library of the Netherlands and with the MARC standards for cataloging serials. These findings are reported in Document 12.</p>
<p>Project participants will next model the preservation metadata that might be used in an archive of Elsevier Science e-journals. We will do this by selecting a limited body of content types (journal articles, editorials, and letters, for instance); identifying the metadata standards relevant to these types of information; agreeing on which metadata elements are essential to an effective archive; determining how much of this metadata is already being created by Elsevier Science and by serials catalogers; and assessing the effort required to create any essential metadata that are not now being created.</p>
<p>MISSION OF A DIGITAL ARCHIVE. In one sense, there is no question about the mission of an archive of digital content. It must provide permanent access to its content. This simple truth grows immensely complicated when one acknowledges that such access is also the basis of the publisher's business and that, in the digital arena (unlike the print arena), the archival agent owns nothing that it may preserve and cannot control the terms on which access to preserved information is provided.</p>
<p>Project participants have seen the question of archival mission as turning on our ability to identify conditions that would prompt a transfer of access responsibilities from the publisher to the archival agent. These conditions would be the key factors on which a business plan for a digital archive would turn. We started by trying to identify events that would trigger such a transfer (Document 2), but concluded that all such events led back to questions about the marketplace for and the life-cycle of electronic information that we could not answer. Project team members-from the Yale library and Elsevier Science alike-agreed that too little is known about the relatively young business of electronic publishing to enable us now to identify situations in which it would be reasonable for publishers to transfer access responsibility to an archival agent (Document 11).</p>
<p>In the process of coming to this conclusion, we modeled three kinds of archival agents-a de facto archival agent, defined as a library or consortium having a current license to load all of a publisher's journals locally; a self-designated archival agent; and a publisher-archival agent partnership (see Document 14). The first of these exists (e.g., CSIRO, OhioLink), and Elsevier Science is actively discussing the second type with a number of (mostly national) libraries. Whether the third type of archive, the focus of our investigation, can now be brought into existence turns on the business viability of an archive that is essentially "dark"-an archive, that is, for which no access responsibilities can now realistically be predicted. Project participants vary about whether an archive with so uncertain a mission can be created and sustained over time and whether, if created, an individual library such as Yale or a wide-reaching library enterprise like OCLC would be the more likely archival partner.</p>
<p>It is possible to imagine a digital archive that, while being "dark" for most purposes, might be "bright" for some highly selective purposes. Two such purposes have so far been named. One is providing access for libraries that have not renewed their licenses, but whose former licenses provided for perpetual access to the content covered by those licenses. A second is free or very low cost access to content provided to third-world libraries through some agency such as the World Health Organization. It might be that one or both of these purposes could provide enough of an enterprise base to make a publisher-archival agent partnership viable.</p>
<p><hi rend="bold">Appendix: List of planning documents</hi></p>
<p>Listed here are various documents created during the first half of the Yale University Library/Elsevier Science Digital Archives Planning Project. Some of these documents contain more or less proprietary business information; many were written as part of an investigatory process and are not fully intelligible when dissociated from that ongoing process.</p>
<p>The status report to which this list is an appendix is meant to be understood without referring to any other document. Readers wishing to consult any of the documents listed below should address their request to Ann Okerson, the project's Principal Investigator (ann.okerson@yale.edu).</p>

<list>
<item>2000
<list>
<item>1. October: Scott Bennett. "Proposal for a Digital Preservation Collaboration between the Yale University Library and Elsevier Science."</item>
</list></item>
<item>2001
<list>
<item>2. February: Scott Bennett. "'Triggering Events' &amp; Related Issues for a Digital Archive."</item>
<item>3. March: Paul Conway. "Preservation Metadata. An Annotated Bibliography."</item>
<item>4. March: Paul Conway. "Yale/Elsevier E-Journal Project. Metadata Issues."</item>
<item>5. March: David Gewirtz. "Site Visit Report to Elsevier Science. Amsterdam, Netherlands, March 26-30 2001."</item>
<item>6. March: David Gewirtz. "Yale/Elsevier E-Journal Project. Koninklijke Bibliotheek - The National Library of the Netherlands."</item>
<item>7. April: Paul Conway. "Yale/Elsevier E-Journal Project. OAIS Preservation Metadata."</item>
<item>8. April: Scott Bennett. "Characteristics of Two Types of Archival Arrangements."</item>
<item>9. May: JP Morgan Chase I-Solutions. "Building a Large Digital Archive Network."</item>
<item>10. May: Chris Shillum, Science Direct. "Publication Item Types in ScienceDirect."</item>
<item>11. May: Scott Bennett, "Purpose of the Digital Archive."</item>
<item>12. June: Paul Conway. "Metadata [Standards] Review."</item>
<item>13. June: David Gewirtz. "Mellon Foundation Planning Grant: Toward a Parallel Line of Inquiry."</item>
<item>14. June: Scott Bennett. "Three Models of Archival Agents."</item>
</list></item>
</list>
</div4>
</div3>
</div2>
</div1>

<div1 type="section" n="11"><head><hi rend="italics">Archiving Electronic Journals</hi></head>
<p rend="center"><hi rend="bold">A Research Program Funded by the Andrew W. Mellon Foundation <lb/>Papers presented to an initial meeting of the program participants, 6 February 2001.</hi></p>
<p>The meeting was convened by The Andrew W. Mellon Foundation at the New York Public Library. The Foundation will convene a further final meeting toward the end of this one-year planning process. At the request of project participants, CLIR and the DLF will host additional meetings and workshops to facilitate joint exploration of common themes and challenges.</p>
<div2 type="subsection" n="01"><head>Digital archiving in an international context: A UK/JISC perspective (Neil Beagrie, Assistant Director (DNER) Preservation, JISC Digital Preservation Focus)</head>
<p><xref doc="diglibpreservejisc0206">http://www.diglib.org/preserve/jisc0206.htm</xref></p>
</div2>

<div2 type="subsection" n="02"><head>Harvard University Library E-journal archiving project (Dale Flecker)</head>
<p><xref doc="diglibpreserveharvard0206">http://www.diglib.org/preserve/harvard0206.htm</xref></p>
</div2>

<div2 type="subsection" n="02"><head>Lots of Copies Keep Stuff Safe. LOCKSS (Vicky Reich, Stanford University)</head>
<p><xref doc="diglibpreservestanford0206">http://www.diglib.org/preserve/stanford0206.htm</xref></p>
</div2>

<div2 type="subsection" n="02"><head>New York Public Library. Preserving Performing Arts Journals</head>
<p>In response to the Call for Proposals on the archiving of electronic journals issued last year by The Mellon Foundation, The New York Public Library (NYPL) has identified the domain of the Performing Arts and related academic disciplines such as media studies, literary criticism, and historical and social studies as a significant area of exporation. Before I say why that is let me just briefly describe, for those who do not know of it, the importance of Performing Arts materials within our collections. This will better hep to set the context of the proposal.</p>
<p>The Library for The Performing Arts, or LPA, is one of four major centers within the NYPL "family" of research libraries. It assumed its individual identify in 1965, when the Lincoln Center for the Performing Arts was opened here in Manhattan and since that time it has steadily continued a tradition of adding current materials in published form as well as major collections of personal papers and archives. It has also pursued a vigorous program of documenting live performances in sound and vision. Its collections now include more than 8 million items, covering nearly every aspect of the performing arts, from Greek tragedy, to Renaissance dance, to contemporary pop music in a diverse range of media. It is now possibly the largest and most significant collection of its kind in North America.</p>
<p>Mellon's Call for Proposals spoke of the need to address "the issues relating to electronic scholarly journals" but also of "the likely loss to future generations of scholars of material published uniquely in the electronic medium." This statement certainly sounded a chord with LPA colleagues who already struggle with the challenge of format diversity in written, printed and recorded materials, but it also caused us at NYPL to think about a particular responsibility to future researchers which we would have in this area of our collections; and it made us put a particular spin on the definition of electronic scholarly journals. To be frank, even with the confines of the printed form, Performing Arts Studies offer a relatively small range of scholarly journals, if by that definition one means refereed journals, issued by learned societies or through established publishers so prevalent in the world of STM for example. What is very prevalent however is a large range of material ranging from very well-produced but highly specialized magazines to trash fanzines all full of commentary and review of artists and their performances; all of which is of tremendous importance to scholars and researchers in assessing the impact of artists and their often ephemeral performances on the wider society. Not surprisingly, LPA has collected, and continues to collect, very extensively in this sort of material - and not surprisingly also the multimedia opportunities afforded by the world wide web have proved very attractive to publishers of this kind of content, both because it appeals to their sense of creativity and helps enhance and emphasize many of the points to which they wish to draw attention in the Performing Arts.</p>
<p>So using our existing knowledge of this material and undertaking some further research we established a preliminary list of ninety titles of web publications with value for Performing Arts studies. The list includes peer-reviewed journals and magazines from more popular sources. It contains those born digital, those published in both print and electronic forms, and those published as an online supplement to print titles.</p>
<p>The following are some of the challenges associated with the preservation of journal material in the performing arts.</p>

<list>
<item>The publishers are very often small entities, even individuals, rather than well-established</item>
<item>The material is delivered to users in a variety of electronic formats and often makes great use of embedded multimedia functions (such as digital sound and video) as exemplars</item>
<item>Extensive use is made of hypertextuality, in particular links to other pages and presences elsewhere on the World Wide Web; and</item>
<item>The instant nature of much of the activity in the performing arts places a much higher premium, for future research purposes, on what might be described as ephemera, and a number of titles in the list fall into that category.</item>
</list>

<p>We believe that the attempt to establish workable processes for harvesting and archiving material of this nature for the development of usable collections for future generations of researchers presents three highly significant challenges:</p>

<list>
<item>The organizational and legal challenges of dealing with a number of smaller entities and individuals, many of whom are outside the mainstream publishing world</item>
<item>The technological challenge of handing embedded multimedia, prefiguring an outcome which is not yet fully developed amongst more traditional publications in electronic form</item>
<item>The hypertextual challenge of examining the feasibility of, and solutions to, the maintenance of persistent links to other web presences within an archive environment.</item>
</list>

<p>I would like to suggest that these challenges taken together will give the project the opportunity, which may not yet be so readiy available in other spheres of information provision - namely to examine in some depth how the changing nature of the public information space which is the World Wide Web will impact technologically and organizationally on our collection management activities.</p>
<p>What will happen next - clearly the project officer will begin to work closely with our Information Technology Group (ITG) colleagues to design an appropriate technical infrastructure to support this work and with the help of LPA colleagues will revisit the preliminary list of titles to validate and enhance it to what is judged as a definitive level. However the most important area of work in this preparatory, planning phase will concentrate on building solid liaisons with the producers of this material and working with our legal advisors to build an appropriate process for acceptable harvesting and archiving of the journals. This area will I believe be the most challenging part of the whole project by nature of the diversity of the journal producers. Although we have collected this kind of material in the print environment for many years it has rarely meant any detailed interface with the producers. To work with and reach agreements with them may well become a very time-consuming matter for often they are no accepted publishing companies, with established procedures for protecting their IPR and legal resources to do it (and wish to belittle it). Here however we may well be dealing with individuals or loose affiliations rather than clearly established organizations and the possibilities for establishing detailed and permanent agreements with such people may be frought with difficulty - in the field of the Performing Arts this may prove the greater obstacle than the technical challenges.</p>
</div2>

<div2 type="subsection" n="02"><head><hi rend="bold">Yale/Elsevier E-Journal Archive Planning Project</hi></head>
<p rend="center"><hi rend="bold">New York, February 6, 2001</hi></p>
<p><hi rend="bold">What is the project?</hi></p>

<list>
<item>- An attempt to add meaningfully to the body of knowledge and practice related to digital archives and preservation</item>
<item>- A partnership with a large publisher (Elsevier Science) of many mission-critical academic materials</item>
</list>

<p><hi rend="bold">Personnel</hi></p>
<p>All key players are internal - we are backfilling/outsourcing more routine duties</p>

<list>
<item>Scott Bennett and Ann Okerson as principal investigators</item>
<item>Paul Conway, project coordinator</item>
<item>David Gewirtz, technical specialist</item>
<item>Also other staff as needed</item>
</list>

<p>Why this publisher?</p>

<list>
<item>- Builds on earlier NERL local load and serving work with Elsevier (knowledge not lost)</item>
<item>- Large for-profit publishers will be more driven by business reasons to abandon not-profitable aspects or "drags" on their business than not-for-profits</item>
<item>- Elsevier has a huge digital collection, 1100+ titles phased in over time (since 1995). Collections from a variety of sources, countries, offices.</item>
<item>- Collection in multiple e-formats mimics what would be available from a larger universe of publishers. A microcosm of the scholarly publishing world</item>
<item>- One publisher controls these titles and is eager to cooperate and research.</item>
</list>

<p>Our challenges:</p>

<list>
<item>- The Elsevier collections already involves a wide variety of e-formats - how to sample these to make a valid long-term plan?
<list>
<item>TIFF, PDF-wrapped TIFF, SGML, XML with variations within these</item>
<item>Titles come on stream at different times; any title could go thru several formats</item>
</list></item>
<item>- Extracting samples is not easy, as we learned previously.</item>
<item>- What will we choose for rendering software? ScienceServer on offer, but we believe we may want to keep our rendering quite separate from the Elsevier look and feel - and company.</item>
<item>- Identify trigger events when archives will become essential - a unique aspect is that in e-world the archive may be needed very soon, i.e., ownership of titles changes every year at the margins and so content rapidly becomes elusive or changed.</item>
<item>- To what extent is content separable from functionality? Is it? Can content be defined unambiguously?</item>
<item>- What layers of agreement will be necessary, with whom, when, etc? Business models that provide for the transfer of responsibility to an archival agent when the trigger conditions have been met?</item>
<item>- Can the traditional notions of an archive, especially the notions of primary and secondary uses of content, be mapped on an archive of e-journal content.</item>
</list>

<p>Plan of work (next 3 months)</p>

<list>
<item>- Preliminary technical platform established and subset of data obtained from Elsevier.</item>
<item>- Preliminary definition of appropriate business models defining preservation "triggering events."</item>
<item>- Deconstruction of the DTDs used by Elsevier Science to structure their e-journal content and of the "standardized" delivery mechanisms developed to transfer content within the Elsevier organization.</item>
<item>- Development of a conceptual framework for defining the separation of content and functionality within the defined structure of the Elsevier content.</item>
<item>- Develop a timeframe for the planning grant that has us writing a first draft report by Halloween.</item>
<item>- A sequence of brief background papers prepared on the working environment of digital preservation, on the status of preservation metadata, and on the nature of an archive in the digital world.</item>
</list>
</div2>
</div1>

<div1 type="section" n="12"><head><hi rend="italics">Archiving Electronic Journals</hi></head>
<p rend="center"><hi rend="bold">A Research Program Funded by the Andrew W. Mellon Foundation <lb/>Original Grant applications</hi></p>
<p>The applications outline goals and objectives of individual projects. </p>
<div2 type="subsection" n="01"><head>Project Harvest</head>
<p rend="center">The Cornell University Library's Proposal to <lb/>The Andrew W. Mellon Foundation <lb/>To Develop a Repository for E-Journals</p>
<p rend="center">Submitted by <lb/>Sarah E. Thomas <lb/>Principal Investigator <lb/>Carl A. Kroch University Librarian <lb/>Cornell University</p>
<p rend="center">15 October 2000</p>

<div3 type="part" n="01"><head>Overall Objectives for the Project</head>
<p>In response to the call from the Mellon Foundation in a letter of 14 August 2000 from Don Waters, Scholarly Communications Project Officer, the Cornell University Library proposes to develop a plan for a repository of electronic journals in the field of agriculture. <hi rend="italics">Project Harvest</hi>, as the project will be known, would build on Cornell's historic excellence in preservation in general and the preservation of agricultural literature in particular. We propose to initiate a dialogue with a number of agriculture publishers with whom we have successfully cooperated on other projects. During these discussions, we will identify the elements of a compelling preservation strategy and negotiate a mutually acceptable approach that Cornell could implement and which the publishers could accept. As a product of the negotiations, we will develop a model agreement that could be used as the basis for negotiations with other publishers in agriculture as well as publishers in other disciplines.</p>
<p>In parallel with the negotiations with the publishers, we will also be at work on the considerable technical design issues associated with an e-journal repository. We will develop a design that addresses the various functions needed in an e-journal repository, including ingest, storage, management, migration, and access.</p>
<p>At the end of the planning year, we will have negotiated with a number of publishers over the inclusion of their materials in a library-based repository. We hope that the negotiations will lead to the development of a model agreement that other publishers could readily accept. In addition, we will have modeled the architecture for a long-term repository based on the best thinking in the digital preservation community tempered by the realities of what our publisher/partners are willing to accept. We will have developed an RFP for the purchase of equipment and services needed for the implementation of the repository that we will distribute to vendors when further funding is secured. Finally we will have planned how to address other issues associated with the successful implementation of a long-term e-journal repository, including how to gain community support for the project, how it might grow, what organizational model we would need to follow to develop the e-journal archive, and what our long-term budget plan might be.</p>
</div3>

<div3 type="part" n="02"><head>Importance to Cornell</head>
<p>There are a number of reasons why Cornell University wishes to undertake the difficult task of organizing, designing, and implementing a digital e-journal repository. First, it is a natural outgrowth of our long-standing interest in preservation of research library materials. In addition, the proposal builds on our interest in issues surrounding electronic publication. Finally, the subject matter of the proposal - the preservation of electronic agricultural literature - has special importance to us. The Mann Library at Cornell has spearheaded several national initiatives to ensure that essential agricultural literature is preserved; <hi rend="italics">Project Harvest</hi> would extend this interest to the realm of electronic publication. Fortunately, our past experience in all three areas (preservation, electronic publishing, and agricultural subject areas) has equipped us well to undertake <hi rend="italics">Project Harvest.</hi></p>
<div4 type="subpart" n="01"><head>Cornell's leadership in digital preservation</head>
<p>For over a decade the Cornell University Library has been a leader in the preservation field in general, and in the application of digital technologies to library preservation in particular. Through a series of research grants and award-winning publications, Anne Kenney and the other staff of the Library's Preservation Department have developed much of the conceptual basis for our understanding of the place of digital technologies in the conversion of analog material. Over the last several years, she and Oya Y. Rieger have collaborated on a number of research projects to advance Cornell's understanding of digital preservation requirements. One of these projects, funded by the Institute for Museum and Library Services, has resulted in the development of a preservation strategy for Cornell's digital image collections, including requirements for the establishment of a central depository. A second research project, conducted in collaboration with Mann Library staff and funded by the Council on Library and Information Resources, assessed risks associated with file format migration (Lawrence, 2000). Currently Kenney, Rieger and other members of the Department of Preservation are collaborating with colleagues in the Computer Science Department on Project PRISM, a Digital Library Initiative, Phase Two project funded by the National Science Foundation and other interested funding agencies. Project PRISM is exploring issues around information integrity in the development and growth of digital libraries, with particular emphasis on preservation and security requirements. Cornell's growing expertise in digital preservation is evidenced by staff appointments to important initiatives. Anne Kenney, for example, has been named to the RLG/OCLC Working Group on Attributes of a Digital Archive. Oya Rieger serves on the Preservation Metadata Working Group of the RLG/DLF Task Force on Policies and Practice for the Long-Term Retention of Digital Materials and is co-chairing the NISO Technical Committee on Metadata for Digital Still Images. Another library staff member, Peter Hirtle, was a member of the seminal CPA/RLG Task Force on Digital Archiving (Task Force, 1996) and is serving on the Institutional Records Working Group of the RLG/DLF Task Force.</p>
<p>In short, Cornell University has had extensive interest in and commitment to the preservation of research library materials. The preservation of "born digital" material is the next logical area for Cornell to address. Our previous experience has uniquely positioned Cornell to explore and implement an archival repository for electronic journals.</p>
</div4>

<div4 type="subpart" n="02"><head>Cornell's interest in electronic publication</head>
<p>Cornell University has also developed a strong interest in electronic publication. During the past two years, and with the support of The Andrew W. Mellon Foundation, the Cornell University Library has planned and undertaken a project in the electronic publication of mathematical journals. Project Euclid is intended to serve the needs of both mathematics publishers and mathematician end-users. We intend to develop Euclid into a primary channel for the publication and exchange of mathematical scholarship.</p>
<p>Project Euclid demonstrates Cornell University's interest in issues surrounding electronic publication. Project Euclid, however, is intended to be an experiment in publication, not archiving. Nevertheless, the policies, practices, and procedures that are developed as part of <hi rend="italics">Project Harvest</hi> may benefit the journals included in Project Euclid. Because a long-term repository is a key component of the scholarly exchange process in the online environment, such a repository, specifically tailored to the requirements of mathematics publications, would be a further service that we would like to offer those publishers who make use of Euclid to publish their journals.</p>
<p>It is in Cornell's interest, therefore, to support the creation of a protocol for the creation and maintenance of an e-journal archive. Such a protocol could be adapted for mathematics and other disciplines. It would attract other mathematics publishers to the project who are not publishing their journals through Euclid, and foster the support of the Euclid project. In this manner, our currently-funded investigation of new models for scholarly communication and the proposed new investigation into methods by which we can provide long-term access to electronic scholarly information can support each other.</p>
</div4>

<div4 type="subpart" n="03"><head>Cornell's leadership in the preservation of agricultural literature</head>
<p>The literature of agriculture is a natural body of materials for a test of the preservation of electronic literature. For over a decade the Cornell University Library, the land grant library for the state of New York, has taken a leadership role in the preservation of the literature of agriculture. Librarians at Cornell's Mann Library, specializing in agricultural and life sciences, have worked with other land grant university libraries and the National Agricultural Library to establish a national preservation plan for agriculture (Gwinn 1993). As part of the preservation plan, the information components of the agricultural sciences were identified and primary responsibilities for the coordination of preservation activities were assigned to different institutions, as indicated in Figure 1. Cornell currently coordinates several parts of this ongoing preservation work. Mary Ochs and Joy Paulson at Cornell University's Mann Library manage on behalf of USAIN (United States Agricultural Information Network) the NEH-funded cooperative microfilming project to preserve state and county agricultural documents. Cornell also continues to develop the Core Historical Literature of Agriculture digital library. In September 2000, Cornell University received an IMLS National Leadership Grant to digitize the core historical literature of the related field of home economics. As part of the project, Mann Library will implement the guidelines established in the IMLS-funded preservation strategy project mentioned above. Part of the project will experiment with the Endeavor Encompass software to increase the interoperability of the home economics digital library with other digital repositories at Cornell, such as Making of America. Finally, the project will define a set of model workflows for capturing metadata for access and preservation of digital materials.</p>
<p><figure entity="ProjectHarvestdistributionimage002"></figure></p>
<p><figure entity="ProjectHarvestdistributionimage003"><head></head><figDesc>Text Box: Figure 1: The National Agricultural Literature Preservation Plan as of 1993"</figDesc></figure></p>
<p>Agricultural literature is well-served by a carefully developed and coordinated program, the National Preservation Program for Agricultural Literature. The USAIN National Preservation Special Project Committee oversees the plan, and Mary Ochs of Mann Library serves as a member of that committee. As indicated in figure 1, preservation of electronic publications in agriculture was not a significant component of the plan when it was developed. To address one part of the changing landscape of publishing, Cornell University co-sponsored with the National Agricultural Library in March 1997 a meeting on government electronic publications in agriculture. A product of that meeting was the publication by Paul Uhlir, Project Consultant for the National Research Council, of the "Framework for the Preservation of and Permanent Public Access to USDA Digital Publications." This framework was later adopted by the National Agricultural Library in conjunction with the USDA Office of the Chief Information Officer. No similar meeting for electronic journals in agriculture has yet been held. The growing importance of e-journals in the field of agriculture makes the secure archiving and long-term access to these "born digital" files of central importance to the evolving preservation plan. As Cornell's representative on the USAIN special projects committee, Mary Ochs will inform the committee about the work on this planning project and seek input from them. Connections with USAIN and the agricultural library community offer links for building trust within the user community.</p>
</div4>

<div4 type="subpart" n="04"><head>The appeal of a subject-based approach</head>
<p>While the absence of e-journals as an area of concern in the National Agricultural Preservation Plan cries out as an area that needs to be addressed, we are proposing to study the e-journals in agriculture also because of the tactical advantages it provides us. An agricultural subject-based archive would include journals from a wide variety of publishers, with a wide variety of file formats and multiple contractual agreements required. Appendix B contains a list of the core journals in agriculture and represents a starting point in the search for journals for possible inclusion in the archive. This list of journals is based on the seven-volume bibliography, <hi rend="italics">The Literature of the Agricultural Sciences,</hi> edited by Wallace Olsen of Cornell University's Mann Library, which identifies the core journals in the seven sub-disciplines of agriculture (Olsen, 1991-1996). Preliminary investigations (which will be expanded during the planning year) suggest that as many as 75% of the journals are now available in electronic form. As Appendix B indicates, many publishers are represented, and a number of the journals already have in place arrangements with nominal archival repositories such as JSTOR, OCLC's ECO (Electronic Collections Online) project, or HighWire Press. It is unclear, however, whether any of these repositories meet the requirements outlined in the "Minimum criteria for an archival repository of digital scholarly journals" developed by CLIR, DLF, and CNI.</p>
<p>In sum, there are a large number of agricultural journals that are available in electronic form; these journals represent a high percentage of the core serial literature in agriculture; they are produced by a number of different publishers and publishing arrangements; and some of the journals have a quasi-archival arrangement in place. Taken together, the agricultural publishing arena offers the real potential in the second phase of the project for the creation of a large, varied, and robust e-journal repository that reflects much of the diversity found in scholarly communication.</p>
</div4>
</div3>

<div3 type="part" n="03"><head>Planning year focus</head>
<p>We heartily endorse the assertion in the "Minimum Criteria for an Archival Repository of Digital Scholarly Journals" that an archival repository that acts to preserve digital scholarly publications must be a trusted party that conforms to certain minimum requirements agreed to by both scholarly publishers and libraries. The most serious challenges and impediments to the creation of an e-journal repository are political: they have to do not with how the technology is designed, but rather with how the essential stakeholders (publishers, libraries, the scientific societies that support both, and the user) relate and work with each other. Indeed, how they relate will to no small extent determine how the technology evolves. What precisely is stored in such a repository, how access to it is guaranteed, who owns it, how and under what circumstances it is accessed, who authorizes such access, how the entire operation is securely and regularly funded--these and similar questions must be answered jointly by the stakeholders before the building of a fail-safe repository can commence. During the planning year, we will work with our target publishers to formulate and develop provisional answers to these basic business and technical questions. Negotiations with publishers over the design, organization, and operation of the digital repository will therefore be the primary activity during the planning year.</p>
<p>While political issues may be the greatest challenge to the successful implementation of an e-journal repository, serious technical challenges also confront us. There are a number of technical issues that must be identified and addressed in conjunction with the negotiation with publishers. Some concern the nature of the e-journal archive itself. Is it to be, for example, a fail-safe repository of last resort whose contents are shaped by a desire to ensure the longest possible lifespan, or should it try to offer the full range of functionality found in the e-journal itself? Can the repository be built so that both options are possible? Once the nature of the archive is defined, what systems are to be used for the ingest, organization, maintenance, migration, and delivery of the e-journal files? What is the place of redundancy in the system? The development of a technical model for the e-journal repository will be the second focus of the planning year.</p>
<p>In addition to our negotiations with publishers and the development of a technical work plan, we will also use the planning year to develop mechanisms for convincing the scholarly community of the validity of the repository, explore organizational and staffing models for any implemented repository, and explore long-term funding options and growth plans for the repository.</p>
</div3>

<div3 type="part" n="04"><head>Detailed work plan and budget</head>
<p>The planning year will be divided into seven separate but related activities.</p>
<div4 type="subpart" n="01"><head>Work with publishers to develop an archiving policy.</head>
<p>It is our belief that effective archiving of electronic journals can only be accomplished through a publisher/librarian partnership. The Mellon planning grant would allow us to work with publishers to establish a set of responsibilities for both Cornell, as the archiving institution, and the publishers, as archival depositors. Along with those responsibilities, we must establish conditions for inclusion, including copyright clearance, that are broadly acceptable to the publishers, but allow Cornell, as the archiving institution, the flexibility to establish technical specifications and access policies that serve users well. To be successful, these negotiations must identify the benefits and drawbacks of the different configurations of an e-journal archive and find an acceptable common ground for all parties. This will then form the basis of the contracts with publishers depositing files in the archive.</p>
<p>The first step in the acquisitions plan would be to develop selection criteria that will allow us to prioritize from the list of journals in Appendix B which of the publishers we wish to ask to be part of Project Harvest. Twelve publishers are obvious candidates with which to work. These publishers issue a large number of the core titles; they are prominent in the field (and hence likely to serve as models for others); and they represent a wide variety of publishing models, including both profit and non-profit. They include:</p>

<list>
<item>Elsevier, with 16 journals on the list</item>
<item>Either the Tri-Societies (American Society of Agronomy, Crop Science Society of America, and Soil Science Society of America) or Springer, which produces the journals</item>
<item>The National Research Council of Canada. At one point, their archiving policy was to maintain material "until they ran out of room on their server"</item>
<item>Annual reviews. This is available via Highwire, and offer a way of working with another university</item>
<item>University of Chicago Press. Titles include <hi rend="italics">Economic Development and Cultural Change</hi>, <hi rend="italics">International Journal of Plant Sciences,</hi> and <hi rend="italics">American Naturalist;</hi></item>
<item>American Agricultural Economics Association</item>
<item>Federation of American Societies for Experimental Biology</item>
<item>Cambridge University Press, with 7 journals on our list</item>
<item>Entomological Society of America. We have already negotiated permission with them to include several titles in the online Core Historical Literature of Agriculture</item>
<item>Kluwer, with 5 titles on list</item>
<item>Oxford University Press, with 3 titles on list</item>
<item>Blackwell Science, with 9 titles on list</item>
</list>

<p>After identifying the potential publisher partners, we will then ask a pilot group to participate in Cornell's Project Harvest. From those publishers expressing interest in participating, we would gather a small development team to consider the issues outlined above. The goal for the development team would be to create, through an iterative process, a standard agreement for archival deposit. Topics that would be identified in the agreement include:</p>

<list>
<item>The general responsibilities of the publishers and Cornell</item>
<item>Characteristics of the data, accompanying metadata, and any additional documentation that are to be deposited</item>
<item>Guidelines on transmission methods and media for deposit</item>
<item>Procedures for the deposit</item>
<item>Procedures and protocols Cornell will use to verify the arrival and completeness of the data</item>
<item>Rights of the depositing organizations to audit the repository</item>
<item>The respective roles, responsibilities, and rights of the Cornell and the data producers with regard to the data</item>
<item>Articulation of Cornell's responsibilities and capabilities with regard to the accessioning, description, management, and even transformation of the deposited data</item>
<item>Access policies for users of the repository, and how they may vary over time</item>
<item>Conditions on the use of the data, and again how they may vary over time</item>
<item>Fees (if any) associated with the deposit</item>
<item>Cornell's ability to share the data with partners to create an agreed-upon level of redundancy</item>
<item>Clarification of issues surrounding copyright retained by authors</item>
</list>

<p>Other key issues defined by the development team</p>
<p>Assuming the implementation phase of the project is funded, we anticipate contacting all the publishers from the list in Appendix B to assess their interest in participating in the project. Through the planning process, we would need to determine the number of titles we can handle in the first years of the project.</p>
<p>Cornell has had experience with this type of negotiations. We worked with 68 publishers, including Elsevier, Kluwer, and others, to secure rights to use material in TEEAL (The Essential Electronic Agricultural Library) and The Core Historical Literature of Agriculture. In the process of negotiations, staff members developed a standard agreement similar in function (if not in content) to the agreement we are proposing to develop for Project Harvest. In Project TEEAL, once one major publisher agreed to the TEEAL basic agreement many other publishers followed. We anticipate a similar development with Project Harvest. Project Euclid, like TEEAL, has been built on a partnership of publishers and librarians. In the case of Project Euclid, many of the publishers are scientific societies, providing us with experience in learning and understanding the concerns of a different group of publishers. We would use the lessons we have learned from developing Euclid in shaping the discussions for Project Harvest.</p>
<p>We would also draw on the lessons others have learned in negotiating with publishers. The CLIR/DLF draft model license found on the LIBLICENSE web site at Yale University &#x003C;http://www.library.yale.edu/~llicense/&#x003E;, for example, is a natural model on which to draw for our similar effort to develop a model archiving agreement. The data depository program of the Arts and Humanities Data Service &#x003C;http://ahds.ac.uk/deposit/depintro.html&#x003E; will also provide information on what is needed for a digital archive and what creators are likely to be willing to deposit</p>
</div4>

<div4 type="subpart" n="02"><head>Investigate how to ensure scholarly acceptance of the repository</head>
<p>The Cornell repository will only be successful if the scholarly community is convinced that the journals deposited at Cornell will remain accessible and readable over time. An important component of the planning year therefore will be assessing how scholars feel about e-journals and identifying methods to build trust in the community.</p>
<p>In the matter of trust, Project Harvest is in a favored position. Mann Library within the Cornell library system has had a long history of preserving and making available to the scholarly community the core literature of agriculture. An ongoing and significant electronic initiative is the USDA Economics and Statistics System with its statistical and textual reports from the Agriculture Department's Economic Research Service, National Agricultural Statistics Service, and World Agricultural Outlook Board. Scholars know that Cornell has a vested interest in the preservation of the literature of agriculture, making this project mission-driven, rather than external to the overall goals of the institution.</p>
<p>Given the confidence that the university already enjoys with publishers, librarians, and scholars, some in the scholarly community may be willing to accept whatever the university proposes to do just because it comes from Cornell. However, it will also be important to develop formal methods of representing the organizational and technical competencies Cornell plans to build during the course of Project Harvest. To meet this need, the project team will develop a plan to outline the organizational and technical components of the repository. We assume that the success of the journal deposit system developed during the course of the project will be heavily dependent on the reliability and credibility of the organizational and technical work plan. We will convince the repository's customers that materials in the repository are in good hands by articulating for them our plans for the building, maintenance, and management of the repository.</p>
<p>One component part of our information campaign will be to develop a mission statement for Project Harvest that can be shared with the appropriate scholarly communities. The mission statement will include the information recommended by the "Minimum criteria for an archival repository of digital scholarly journals," including the scope and nature of the materials to be included in the repository, the strategy and methods we will adopt to attract materials, and the user community we hope to serve.</p>
<p>A second means of building scholarly acceptance of Project Harvest will be to ensure that the archive conforms to generally accepted standards for digital repositories. One of the recommendations of the highly influential report of the Task Force on Archiving of Digital Information was that standards and criteria for the certification of digital information repositories be developed. Several national and international projects are exploring the process and methodology in defining the requirements for a certified repository. Among the key initiatives are:</p>

<list>
<item>During the October 1999 ISO Archiving Workshop Series, certification of archives (specifically within the framework of the "Reference Model for an Open Archival Information System" (OAIS)) was one of the key areas for workshop focus and possible standardization efforts.<note target="CorGrant01">[1]</note></item>
<item>The upcoming Preservation 2000 conference, which is sponsored by the UK's Cedars Project, RLG, and OCLC, will provide a platform to continue the discussion of criteria for certification at an international level.<note target="CorGrant02">>[2]</note></item>
</list>

<p>In March 2000 the Research Libraries Group (RLG) and the Online Computer Library Center (OCLC) announced that they will cooperate to create infrastructures for digital archiving. One of their goals is to establish best practices and document the attributes of digital archives for research repositories.</p>
<p>The Library's Digital Imaging and Preservation Research Unit is an active participant in all of these initiatives. During the planning phase of Project Harvest, the staff will closely monitor this and related work in the certification of repositories and will actively contribute to them by sharing Cornell's empirical experience. As certification standards emerge, Cornell will publicize our adherence to the standards as one more way of ensuring trust in the user community.</p>
</div4>

<div4 type="subpart" n="03"><head>Develop a technical model for the repository</head>
<p>Cornell will invest in a five-pronged effort that will focus on: 1) establishing a baseline of e-journal software and file format needs; 2) specifying the archival repository; 3) specifying monitoring tools that will flag documents within the repository that require migration; 4) specifying a baseline hardware and software infrastructure to house the repository; and 5) exploring the need and implementation models for redundancy in the repository.</p>
<p><hi rend="bold">1) Establish a baseline of formats and related software.</hi></p>
<p>Cornell will inventory file formats and software in use today to store and manage e-journals in agriculture. We will collect conversion routines that permit modifying these formats. We will explore whether there is one "least common denominator" format that has minimum software dependencies, and that can be used to create one parallel copy of each journal in that format. Whether or not there is such a format, we will also look at how we might maintain the formats in use in the current live system. One area we want to explore in particular is whether we can maintain both systems: a system with high functionality based on current software as well as one based on a more limited, but likely more enduring, format.</p>
<p><hi rend="bold">2) Specify the archival repository.</hi></p>
<p>Cornell will investigate potential architectures and design criteria for the archive repository, and will choose an approach that is the essence of simplicity. The repository will be based on the OAIS reference model and compliant with Open Archives Initiative protocols and other initiatives in the subject domain of agriculture. (Cornell is already planning to implement OAI protocols in Project Euclid.) The repository model will provide for redundancy of instances. The repository architecture needs to support establishing relationships among the e-journal components without depending on specialized software that is itself subject to technological obsolescence. An example of a possible architecture would be one that relates internal components based on sequence and naming conventions. The repository files will contain metadata for each journal complying with contemporary standards and files in multiple formats. It will include at least the file format in common use for that journal today and an additional "least common denominator" version, as well as associated conversion software.</p>
<p><hi rend="bold">3) Specify a monitoring system.</hi></p>
<p>Cornell will specify a software application to manage the status of each member of the repository. It will be a tool that includes a record for each member of the repository with information needed to establish its age, migration status, and technological dependencies (standards, software, etc). This system will be used as a prediction tool. Criteria will be fed to the system to identify changes in standards or versions of software. The system will present specific e-journals in the repository related to that criteria. These e-journals will then require review to determine whether they need migration.</p>
<p>In investigating and developing the specification of such a monitoring system, Cornell will build upon its previous and current digital preservation investigations. For example, the Risk Management of Digital Information project, which was sponsored by CLIR, equipped the library with a better understanding of the organizational and technical threats that need to be monitored and controlled to ensure the longevity of digital resources (report available at &#x003C;http://www.clir.org/pubs/abstract/pub93abst.html&#x003E;). The library's current DLI2 project focuses on digital preservation. Particularly relevant to this proposal is a Web profiling tool that is being developed by the library's Digital Imaging and Preservation Unit and the Cornell Computer Science Department. This web profiling software will attempt to gather information on various characteristics of digital resources to support digital preservation monitoring and decision-making. This tool provides a technical background for the development of the proposed assessment tool. Another library project, sponsored by an IMLS grant, helped the library to develop a better understanding of the role of preservation metadata in supporting the long-term management of digital collections. The library is developing guidelines for preservation procedures and metadata for digital image collections that are to be deposited in a central digital repository.</p>
<p><hi rend="bold">4) Establish baseline hardware infrastructure.</hi></p>
<p>Cornell will specify hardware with modular storage components to accommodate massive growth in the amount of material stored and identify an architecture for data and system backup that is automatic and self-reporting. Reliability and redundancy of internal hardware components, combined with growth and migration potential, will be priority attributes in the hardware plan. Cornell will develop an RFI to distribute to hardware vendors for their comment before the end of the planning year.</p>
<p><hi rend="bold">5) Investigate need for and approach to redundancy.</hi></p>
<p>Along with the addition of new journals to the repository, there is the possibility of mirroring and/or distributing some of the repository functions to library collaborators. The land grant community has strong ties and a history of cooperative preservation efforts. Other institutions within the land grant community could provide redundancy for the system Cornell develops, or they might duplicate the procedures followed by Cornell with other publishers and subjects. In either event, the workload would be shared among other committed partners. During the planning year, we would want to explore further the need for redundancy in the repository, and begin to work with potential partners. Cornell is a partner in the LOCKSS program from Stanford University and Highwire Press. LOCKSS - Lots of Copies Keeps Stuff Safe - is intended to be a revolutionary, distributed archiving model. We will want to see if any of the lessons learned from the LOCKSS project can be applied to Project HARVEST.</p>
</div4>

<div4 type="subpart" n="04"><head>Develop acquisition and growth plans</head>
<p>During the planning year, we will develop a two-phased acquisition and growth plan. The first phase will focus on the addition of journals to the pilot agricultural repository. This work will continue during the implementation phase. As new journals are published in the field of agriculture, or as older journals become more important, publishers could request to have a journal included in Project Harvest. Journals could also be nominated, possibly by an advisory board of agricultural scholars who would recommend whether to seek out that journal for Project Harvest. We may also wish to work with the agricultural library community to ensure that at least one print copy of all e-journals that also have a printed manifestation is retained. This process would be explored fully during the planning process.</p>
<p>More importantly, the implementation phase would give us hard data on how the pilot could be expanded to other disciplines and/or publishers in a second phase. Our experience may indicate that future repositories should be developed around a subject discipline, as with Project Harvest. We may also find that while the subject approach proves useful in the pilot phase when the primary task is negotiating a general agreement with publishers (and Cornell's good relationship with agricultural publishers makes this task possible), future repositories would be better organized around publishers and their specific publishing systems than by subject. One of the elements we will want to assess during the planning year (and possibly after) is whether a subject-based approach is appropriate for a repository, or whether we should use the agreements we have developed with our agricultural publishing partners as the basis for a general agreement regarding the deposit of all of our partner's publications, regardless of subject matter.</p>
</div4>

<div4 type="subpart" n="05"><head>Identify an organizational and staffing model</head>
<p>We can already see that the project will require collaboration across normal institutional boundaries. We are structuring the planning phase so that it will be a cooperative project drawing on the expertise found in Mann Library, the Preservation and Digital Libraries and Information Technologies (DLIT) departments, and the Library's Institute for Digital Collections (CIDC). Project Harvest will be overseen in the planning phase by a steering committee consisting of representatives from the Mann Library, DLIT, and the Preservation Department, with the inclusion of a faculty member to represent the interest of users.</p>
<p>The staffing model of the planning phase is based on the functional activities suggested in the OAIS reference model. Staff will be assigned to work in each of these four areas:</p>
<p><hi rend="bold"><hi rend="underline">Submission</hi></hi></p>
<p>identify and contact publishers seeking collaboration</p>
<p>negotiate terms for submission, access, updates, and other conditions</p>
<p>plan future growth and acquisitions</p>
<p>coordinate the role of Cornell in agricultural cooperative preservation efforts</p>
<p>The submission activities of the planning phase will be the primary responsibility of the Collection Development unit in Mann Library. They will be assisted by a working group drawn from the staff from the Preservation Department and license librarians in Mann Library and CUL Central Technical Services. Legal advice from the university's General Counsel's office will be sought as appropriate when working out the details of the contract.</p>
<p><hi rend="bold"><hi rend="underline">Ingestion</hi></hi></p>
<p>prepare data for archiving</p>
<p>profile resources - identify characteristics</p>
<p>chose standards, develop procedures</p>
<p>Planning for ingest will be a collaborative effort between the Mann Library's Information Technology Section and the Digital Library and Information Technology division in the Cornell University Library system. A minimum of one half FTE will work in this area and the subsequent area. The work will be informed by the findings of the Submission group and the preservation requirements identified by Preservation Department staff, particularly in the area of standards.</p>
<p><hi rend="bold"><hi rend="underline">Data Management, Archival Storage, and Access</hi></hi></p>
<p>determine hardware and software needs</p>
<p>conduct requirements analysis to determine system infrastructure</p>
<p>design the archival system (both ingest and access components)</p>
<p>Again, Mann Library's Information Technology Section and the Digital Library and Information Technology division in the Cornell University Library system will collaborate on the design of this aspect of the system.</p>
<p><hi rend="bold"><hi rend="underline">Policy Development</hi></hi></p>
<p>facilitate the interaction of the different groups within the library</p>
<p>contribute to the development of criteria for the certification of archival repositories</p>
<p>develop economic models to ensure the long-term sustainability of the repository</p>
<p>work closely with the technology team and the collection development team to develop strategies for standards, file formats used, preservation metadata, preservation strategies, etc.</p>
<p>Staff of the Preservation Department will take the lead in identifying the policy framework for the project. Their investigations will be tempered by the work of the Submission group and the technical requirements identified by the Ingest and Data Administration groups.</p>
<p>Overall policy will be approved by a Steering Committee for the project. The Steering committee will be composed of senior administrators in the library (the directors of Mann Library and the Digital Library and Information Technology division, the Associate Director of the Preservation Department, and the University Librarian serving as PI) and one faculty member, representing the interests of some of the users.</p>
<p>A key question to explore during the planning year will be whether digital repository functions can be absorbed within our existing organizational model, or whether a new organizational unit that cuts across current administrative, subject, and functional lines is needed.</p>
</div4>

<div4 type="subpart" n="06"><head>Negotiate access policies for the prototype repository</head>
<p>Publishers have been unwilling in the past to maintain large print archives of back issues of their journals. Often libraries hold the only complete back-run of print titles. E-journals, while they do not require large warehouses or library shelves for storage, do require electronic storage space and maintenance that assures the integrity of the digital content. It is unclear whether publishers intend to maintain archives their own archives, but libraries are requiring this assurance when they sign e-journal contracts. Many e-journal publishers are relying on OCLC ECO (Electronic Collections Online) for archiving, but OCLC cannot do it all, nor is the reliance on one sole archive sound practice. Research libraries are, not surprisingly, unwilling to discard print issues without long term guarantees that e-journal files will be available.</p>
<p>This planning grant would allow us to explore two major scenarios for an e-journal archive, the "dark archive" and the "living archive." The "dark archive" model creates an archive where stored files would only be used in an emergency. This model is similar to the model of storing microfilm in the National Underground Storage facility. In order to minimize the cost of maintaining a "dark archive," e-journal content might be converted on ingest to some common, stable, minimal format (albeit with a concomitant loss of functionality). A "living archive" of agricultural scholarship, in contrast, would be modeled after JSTOR or OCLC and would provide access to back files of e-journals that publishers no longer wished to maintain or to which publishers are willing to provide additional access. The publishers would of course still be able to provide access to recent issues if they desired. As part of the planning process, the development team would need to investigate the staffing, contractual, economic and technical implications of both options.</p>
<p>The living archive presents the greater challenge in that publishers may be less willing to allow open access to their material. The development team would have to carefully evaluate the implications of the various access policies on the publishers and the users. Issues such as when files would be made available, mechanisms for allowing access, and comparability with the original files, among other issues, must be addressed.</p>
</div4>

<div4 type="subpart" n="07"><head>Develop a plan for the long-term funding of an e-journal repository</head>
<p>Libraries have traditionally assumed the cost of storing and preserving paper copies of agricultural journals. While libraries may be willing to absorb the cost of preserving electronic copies of the same publications, it is more likely that a business model that can make the preservation of e-journals self-sustaining must be found. During the planning year, we will investigate several approaches for making the repository economically self-sufficient over the long-term. This requires that we account for the capital costs associated with building and expanding the repository infrastructure over time. We must also account for the operating costs associated with maintaining and providing access to the repository. [Guthrie, 2000]</p>
<p>There are several possible sources of funds that could be used to maintain and grow the repository over time. They include:</p> <p>agencies and foundations supportive of the need to preserve the agricultural literature</p>
<p>publishers, who may be willing to pay on a per-journal basis the cost for archiving the journal (perhaps by including an archival surcharge with the electronic access surcharge common among major publishers)</p>
<p>acquiring free or reduced subscriptions from publishers in exchange for archiving their journals</p>
<p>charging fees for access to the archival repository</p>
<p>The last three options require the agreement and cooperation of the publishers. Based on the results of the negotiations with them, we anticipate being able to develop a business model that will indicate how much, if anything, archiving agricultural literature will cost Cornell University.</p>
</div4>
</div3>

<div3 type="part" n="05"><head>Project Staff</head>
<p><hi rend="italics">Project Harvest</hi> will be a Library-wide effort. The following individuals will play key roles in its implementation.</p>
<p><hi rend="bold">Sarah Thomas</hi>, University Librarian, will serve as Principal Investigator of Project Harvest.</p>
<p><hi rend="bold">Peter B. Hirtle</hi>, Co-Director, Cornell Institute for Digital Collections, will serve as Project Coordinator.</p>
<p>Three working groups will work directly with the Coordinator. Each will be chair by a senior library staff member. <hi rend="bold">Mary Ochs</hi>, Head, Collection Development and Preservation at Mann Library, will chair the Publisher Relations Group. <hi rend="bold">Tim Lynch</hi>, Head, Information Technology Section at Mann Library, will chair the Technical Design Group. <hi rend="bold">Oya Y. Rieger</hi>, Acting Assistant Director of Preservation for Digital Imaging and Preservation Research, will chair the Preservation Policy Group.</p>
<p>A Publisher Relations Specialist, Preservation Policy Advisor, and Administrative Assistant will be hired to work with Cornell staff on Project Harvest.</p>
<p>A Steering Committee will be established to provide general oversight. <hi rend="bold">Anne R. Kenney</hi>, Co-Director, CIDC and Associate Director of the Department of Preservation, will chair the Steering Committee. Other members will include: <hi rend="bold">Sarah Thomas</hi>, University Librarian, <hi rend="bold">Janet McCue</hi>, Director of Mann Library, and <hi rend="bold">H. Thomas Hickerson</hi>, Associate University Librarian for Digital Libraries, Information Technology and Special Collections.</p>
</div3>

<div3 type="part" n="06"><head>Citations</head>
<p>Guthrie, Kevin. 2000. "Developing a Digital Preservation Strategy for JSTOR, an interview with Kevin Guthrie." RLG DigiNews 4:4 (15 August 2000) &#x003C;http://www.rlg.org/preserv/diginews/diginews4-4.html#feature1&#x003E;</p>
<p>Gwinn, Nancy E. 1993. A national preservation program for agricultural literature. S.l. : s.n.</p>
<p>Lawrence, Gregory W., William R. Kehoe, Oya Y. Rieger, William H. Walters, and Anne R. Kenney. 2000. Risk Management of Digital Information: A File Format Investigation. Washington, D.C. : Council on Library and Information Resources.</p>
<p>Olsen, Wallace C., editor. 1991-1996. The Literature of the Agricultural Sciences. Ithaca, N.Y. : Cornell University Press.</p>
<p>Task Force on Archiving of Digital Information. 1996. Preserving digital information: Report of the Task Force on Archiving of Digital Information. Washington, D.C. : Commission on Preservation and Access.</p>
<p>Uhlir, Paul. 1997. Framework for the preservation of and permanent public access to USDA digital publications. S.l. : s.n.</p>
</div3>

<div3 type="part" n="07"><head>Appendix A: Chronological Workplan</head>
<p>Note: lead participants are identified in <hi rend="italics">italics</hi> after each task.</p>
<p>(Prior to start of project)</p>
<p>Advertise and interview for project-funded positions: Publisher relations specialist; Administrative support person (<hi rend="italics">Project coordinator, administrative staff</hi>)</p>
<p>Identify space and equipment for new <hi rend="bold">Project Harvest</hi> staff (<hi rend="italics">Project coordinator, Library administration</hi>)</p>
<p>Jan. 2001 - March 2001</p>
<p>Hold <hi rend="bold">Project Harvest</hi> organization meeting. Bring together <hi rend="bold">Project Harvest</hi> Team, Advisory Committee. Create mission statement for the <hi rend="bold">Project Harvest</hi> plan (<hi rend="italics">Project leader, Project Harvest team</hi>)</p>
<p>Develop selection criteria to allow prioritization of possible partners (<hi rend="italics">Publisher relations specialist, collection development staff</hi>)</p>
<p>Contact an initial group of potential partners to identify partners interested in the problem (<hi rend="italics">Publisher relations specialist, collection development staff</hi>)</p>
<p>Establish, based on the OAIS model and the "Minimum criteria" what we feel are the ideal component parts of an e-journal preservation system (<hi rend="italics">Preservation policy advisor</hi>)</p>
<p>Establish a baseline of formats and software used in pilot e-journals (<hi rend="italics">Publisher relations specialist, Technology design group)</hi></p>
<p>Advisory Committee will meet to review progress (<hi rend="italics">Project coordinator)</hi></p>
<p>April 2001 - May 2001</p>
<p>Hold negotiations with the pilot group of publishers on the issues we have identified as core to a successful e-journal archival policy (<hi rend="italics">Publisher relations specialist, Preservation policy advisor)</hi></p>
<p>Investigate potential architectures for e-journal repository that are both open and compatible with the needs identified in the negotiations with the publishers (<hi rend="italics">Technology Design Group)</hi></p>
<p>Identify the organizational and staffing model the Library would follow in implementing <hi rend="bold">Project Harvest</hi> (<hi rend="italics">Project leader, Project Harvest team</hi>)</p>
<p>Advisory Committee will meet to review progress (<hi rend="italics">Project coordinator)</hi></p>
<p>June 2001 - July 2001</p>
<p>Develop a model license agreement based on the results of the negotiations with the pilot group of publishers (<hi rend="italics">Project coordinator, Publisher relations specialist, Preservation policy advisor, Legal counsel)</hi></p>
<p>Contact additional publishers lower on the priority the list in order to field test the license agreement. (<hi rend="italics">Publisher relations specialist)</hi></p>
<p>Specify a software application to manage the status of each member of the repository (<hi rend="italics">Technology Design Group)</hi></p>
<p>Advisory Committee will meet to review progress (<hi rend="italics">Project coordinator)</hi></p>
<p>August - October 2001</p>
<p>Contact remainder of the publishers of the core journals in agriculture to solicit interest in possible participation in the project (<hi rend="italics">Publisher relations specialist)</hi></p>
<p>Establish the baseline hardware needed to implement <hi rend="bold">Project Harvest</hi> (<hi rend="italics">Technology Design Group)</hi></p>
<p>Investigate the place of redundancy in the archiving system (<hi rend="italics">Technology Design Group, Preservation policy advisor, Publisher relationsspecialist)</hi></p>
<p>Given the needed technological and organizational environment, develop a business model that can make <hi rend="bold">Project</hi> <hi rend="bold">Harvest</hi> financially acceptable to the Library (<hi rend="italics">Project Coordinator, Preservation policy advisor, Publisher relations specialist)</hi></p>
<p>Advisory Committee will meet to review progress (<hi rend="italics">Project coordinator)</hi></p>
<p>November - December 2001</p>
<p>Assuming a sustainable business model can be identified, prepare a grant application for the implementation of <hi rend="bold">Project</hi> <hi rend="bold">Harvest</hi> based on the findings of the previous year (<hi rend="italics">Project Coordinator)</hi></p>
<p>Develop an RFP for the hardware and software needed to implement Project Harvest in a manageable, scalable, fashion. The RFP will be ready to distribute as soon as implementation funding is received (<hi rend="italics">Technology Design Group)</hi></p>
<p>Develop methods for representing the organizational and technology competencies developed during the design of Project Harvest to the scholarly and user communities (<hi rend="italics">Preservation policy advisor, Publisher relations specialist)</hi></p>
<p>Develop formal acquisition and growth plans to guide the implementation of Project Harvest. The plan will determine how new journals are to be added to the implementation (<hi rend="italics">Publisher relations specialist, Project Coordinator)</hi></p>
<p>Advisory Committee will meet to review progress (<hi rend="italics">Project coordinator)</hi></p>
<p>Throughout the course of the project:</p>
<p>Share information about the design and implementation of Project Harvest with relevant preservation and agricultural information communities (<hi rend="italics">Entire project team)</hi></p>
</div3>

<div3 type="part" n="08"><head>Appendix B: The
Core Agricultural Journals</head>

<p><table>
<row><cell role="label">Title</cell><cell role="label">Publisher</cell><cell role="label">ECO</cell><cell role="label">JSTOR</cell><cell role="label">Highwire</cell><cell role="label">Other</cell></row>
<row><cell>Acta Agriculturae Scandinavica</cell><cell>Munsgaard Press for the Scand. Assn. Ag. Scients. &amp; Royal Swedish Acad. Ag. &amp; Forestry</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Acta Horticulturae</cell><cell>International Society for Horticultural Science</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Advances in Agronomy</cell><cell>Academic Press (San Diego)</cell><cell></cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Agrarwirtschaft</cell><cell>Alfred Strothe for the Institut f&#x00FC;r Landwirtschaftliche Marktforschung</cell><cell></cell><cell></cell><cell></cell><cell>n/a?</cell></row>
<row><cell>Agribusiness: An International Journal</cell><cell>Wiley</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Agricultural and Forest Meteorology</cell><cell>Elsevier BV (Netherlands)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Agricultural Finance Review</cell><cell>"Dept. of Agricultural Economics, Cornell University "</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>"Agricultural Mechanization in Asia, Africa and Latin America (AMA) "</cell><cell>Farm Machinery Industrial Research Corporation Shin Morinsha Co(Business Center for Academic Societies)</cell><cell></cell><cell></cell><cell></cell><cell>n/a?</cell></row>
<row><cell>Agricultural Situation in India</cell><cell>"Ministry of Agriculture, Directorate of Economics and Statistics"</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Agricultural Systems</cell><cell>Elsevier Science (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Agricultural Water Management</cell><cell>Elsevier BV (Netherlands)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Agri-Finance</cell><cell>Century Communications</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Agri-Marketing</cell><cell>Century Communications</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Agronomie</cell><cell>Editions Scientifiques et Medicales Elsevier for l'Institut National de la Recherche Agronomique</cell><cell></cell><cell></cell><cell></cell><cell>n/a?</cell></row>
<row><cell>Agronomy Journal</cell><cell>American Society of Agronomy</cell><cell></cell><cell></cell><cell></cell><cell>Springer</cell></row>
<row><cell>American Economic Review</cell><cell>American Economic Association</cell><cell></cell><cell>X</cell><cell></cell><cell>n/a</cell></row>
<row><cell>American Journal of Agricultural Economics</cell><cell>American Agricultural Economics Association</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>American Journal of Botany</cell><cell>Botanical Society of America</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>American Journal of Clinical Nutrition</cell><cell>American Society for Clinical Nutrition</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>American Journal of Physiology</cell><cell>American Physiological Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>American Naturalist</cell><cell>University of Chicago Press for American Society of Naturalists</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>American Potato Journal</cell><cell>Potato Association of America</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>American Sociological Review</cell><cell>American Sociological Association</cell><cell></cell><cell>X</cell><cell></cell><cell>n/a (ProQuest)</cell></row>
<row><cell>Analytical Chemistry</cell><cell>American Chemical Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Animal Feed Science and Technology</cell><cell>Elsevier (BV Neth)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Animal Production</cell><cell>Durrant for the British Society of Animal Production</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Annals of Applied Biology</cell><cell>Association of Applied Biologists</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Annals of Botany</cell><cell>Academic Press (London)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Annals of Internal Medicine</cell><cell>American College of Physicians</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Annals of the Entomological Society of America</cell><cell>Entomological Society of America</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Annual Review of Ecology and Systematics</cell><cell>Annual Reviews</cell><cell></cell><cell>X</cell><cell>X</cell><cell>X</cell></row>
<row><cell>Annual Review of Phytopathology</cell><cell>Annual Reviews</cell><cell></cell><cell></cell><cell>X</cell><cell>X</cell></row>
<row><cell>Annual Review of Plant Physiology and Plant Molecular Biology</cell><cell>Annual Reviews</cell><cell></cell><cell></cell><cell>X</cell><cell>X</cell></row>
<row><cell>Applied and Environmental Microbiology</cell><cell>American Society for Microbiology</cell><cell></cell><cell></cell><cell>X</cell><cell>Pub</cell></row>
<row><cell>Applied Engineering in Agriculture</cell><cell>American Society of Agricultural Engineers</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Aquacultural Engineering</cell><cell>Elsevier Science (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Archives of Animal Nutrition = Archiv f&#x00FC;r Tierern&#x00E4;hrung</cell><cell>Harwood Academic Publishers</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Archives of Biochemistry and Biophysics</cell><cell>Academic Press (San Diego)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Australian Journal of Agricultural Economics</cell><cell>Australian Agricultural Economics Society</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Australian Journal of Agricultural Research</cell><cell>Commonwealth Scientific and Industrial Research Organization</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Australian Journal of Botany</cell><cell>Commonwealth Scientific and Industrial Research Organization</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Australian Journal of Plant Physiology</cell><cell>Commonwealth Scientific and Industrial Research Organization</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Australian Journal of Soil Research</cell><cell>Commonwealth Scientific &amp; Indstrial Research Organization</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Avian Diseases</cell><cell>American Association of Avian Pathologists</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Biochemical Journal</cell><cell>Biochemical Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Biological Reviews of the Cambridge Philosophical Society</cell><cell>Cambridge University Press</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Biology of Reproduction</cell><cell>Society for the Study of Reproduction</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Bioresource Technology</cell><cell>Elsevier (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>BioScience</cell><cell>American Institute of Biological Sciences</cell><cell></cell><cell></cell><cell></cell><cell>Catchwood</cell></row>
<row><cell>"Bioscience, Biotechnology, and Biochemistry "</cell><cell>"Japan Society for Bioscience, Biotechnology and Agrochemistry"</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Botanical Review</cell><cell>New York Botanical Garden</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>British Journal of Nutrition</cell><cell>Cambridge University Press for the Nutrition Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>British Poultry Science</cell><cell>Carfax Publishing Co.</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Bulletin of Entomological Research</cell><cell>Commonwealth Agricultural Bureaux International</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Canadian Agricultural Engineering</cell><cell>Canadian Society of Agricultural Engineering</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Canadian Entomologist</cell><cell>Entomological Society of Canada</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Canadian Journal of Agricultural Economics</cell><cell>Canadian Agricultural Economics and Farm Management Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub (NRC)</cell></row>
<row><cell>Canadian Journal of Animal Science</cell><cell>Agricultural Institute of Canada for the Canadian Society of Animal Science</cell><cell></cell><cell></cell><cell></cell><cell>Pub (NRC)</cell></row>
<row><cell>Canadian Journal of Botany</cell><cell>National Research Council of Canada</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Canadian Journal of Forest Research = Journal Canadien de la Recherche</cell><cell>National Research Council of Canada</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Canadian Journal of Microbiology</cell><cell>National Research Council of Canada</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Canadian Journal of Plant Science</cell><cell>Agricultural Institute of Canada with the Canadian Society of Agronomy and the Canadian Society for Horticultural Science</cell><cell></cell><cell></cell><cell></cell><cell>Pub (NRC)</cell></row>
<row><cell>Canadian Journal of Soil Science</cell><cell>Agricultural Institute of Canada with the Canadian Society of Soil Science and the Canadian Society of Agrometeorology</cell><cell></cell><cell></cell><cell></cell><cell>Pub (NRC)</cell></row>
<row><cell>Cereal Chemistry</cell><cell>American Association of Cereal Chemists</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Cereal Foods World</cell><cell>American Association of Cereal Chemists</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Choices</cell><cell>American Agricultural Economics Association</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Commonwealth Forestry Review</cell><cell>Commonwealth Forestry Association</cell><cell></cell><cell></cell><cell></cell><cell>n/a--this one was tricky since title change &amp; publishers</cell></row>
<row><cell>Communications in Soil Science and Plant Analysis</cell><cell>M. Dekker</cell><cell></cell><cell></cell><cell></cell><cell>n/a--Not Yet</cell></row>
<row><cell>Critical Reviews in Food Science and Nutrition</cell><cell>CRC Press</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Crop Science</cell><cell>Crop Science Society of America</cell><cell></cell><cell></cell><cell></cell><cell>Springer</cell></row>
<row><cell>Current Science</cell><cell>Current Science Association</cell><cell></cell><cell></cell><cell></cell><cell>n/a (ProQuest)</cell></row>
<row><cell>Diabetes</cell><cell>American Diabetes Association</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Die Landtechnik</cell><cell>Landwirtschaftsverlag M&#x00FC;nster-Hiltrup</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Ecological Monographs</cell><cell>Ecological Society of America</cell><cell></cell><cell>X</cell><cell></cell><cell></cell></row>
<row><cell>Ecology</cell><cell>Ecological Society of America</cell><cell></cell><cell>X</cell><cell></cell><cell></cell></row>
<row><cell>Economic Botany</cell><cell>New York Botanical Garden for the Society for Economic Botany</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Economic Development and Cultural Change</cell><cell>University of Chicago Press</cell><cell></cell><cell></cell><cell></cell><cell>Not yet (ProQuest)</cell></row>
<row><cell>Endocrinology</cell><cell>Endocrine Society</cell><cell></cell><cell></cell><cell>X</cell><cell>Pub</cell></row>
<row><cell>"Entomologia, Experimentalis et Applicata"</cell><cell>Kluwer Academic for Nederlandse Entomologische Verenigung</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Entomophaga</cell><cell>Lavoisier Abon</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Environmental Entomology</cell><cell>Entomological Society of America</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Environmental Pollution</cell><cell>Elsevier Science (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Euphytica</cell><cell>Kluwer Academic Publishers</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Eurasian Soil Science</cell><cell>Scripta Technica</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>European Journal of Biochemistry</cell><cell>Springer International (Berlin) for Federation of European Biochemical Societies</cell><cell>X</cell><cell></cell><cell>X</cell><cell>Pub</cell></row>
<row><cell>European Journal of Soil Science</cell><cell>Blackwell Science (Oxford)</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>European Molecular (EMBO)</cell><cell>EMBO and Oxford University Press (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>European Review of Agricultural Economics</cell><cell>Walter de Gruyter</cell><cell></cell><cell></cell><cell></cell><cell>n/a--Not Yet</cell></row>
<row><cell>Experimental Agriculture</cell><cell>Cambridge University Press</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>FAO Quarterly Bulletin of Statistics</cell><cell>Food and Agricultural Organization of the United Nations</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>FASEB Journal</cell><cell>Federation of American Societies for Experimental Biology</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>FEBS Letters</cell><cell>Elsevier Scientific for FEBS (Neth)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Food Chemistry</cell><cell>Elsevier Science (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Food Policy</cell><cell>Butterworth-Heinemann</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Food Technology</cell><cell>Institute of Food Technologists</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Foreign Agricultural Trade of the United States (FATUS)</cell><cell>USDA Economic Research Service</cell><cell></cell><cell></cell><cell></cell><cell>n/a--data is available through ERS</cell></row>
<row><cell>Forest Ecology and Management</cell><cell>Elsevier Science</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Forest Science</cell><cell>Society of American Foresters</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Forestry</cell><cell>Oxford University Press</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Forestry Chronicle</cell><cell>Canadian Institute of Forestry</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Gastroenterology</cell><cell>W.B. Saunders for the American Gastroenterology Association</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>General &amp; Comparative Endocrinology</cell><cell>Academic Press (San Diego)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Genetics</cell><cell>Genetics Society of America</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Geoderma</cell><cell>Elsevier Scientific (Netherlands)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Heredity; An International Journal of Genetics</cell><cell>Blackwell Science for The Genetics Society of Great Britain (Oxford)</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>HortScience</cell><cell>American Society for Horticultural Science</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>IDS Bulletin</cell><cell>Institute of Development Studies</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Indian Journal of Agricultural Economics</cell><cell>Indian Society of Agricultural Economics</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>International Journal of Food Science and Technology</cell><cell>Blackwell Science for the Institute of Food Science and Technology (UK)</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>International Journal of Plant Sciences</cell><cell>University of Chicago Press</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Irrigation and Drainage Systems</cell><cell>Kluwer Academic</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Irrigation Science</cell><cell>Springer-Verlag (Berlin)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>JAOCS; Journal of the American Oil Chemists' Society</cell><cell>American Oil Chemists' Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>JASA</cell><cell>American Statistical Association</cell><cell></cell><cell>X</cell><cell></cell><cell>n/a (ProQuest)</cell></row>
<row><cell>Journal of Agricultural and Applied Economics</cell><cell>Southern Agricultural Economics Association</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Agricultural and Food Chemistry</cell><cell>American Chemical Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Agricultural and Resource Economics</cell><cell>Western Agricultural Economics Association</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Agricultural Economics</cell><cell>"Agricultural Economics Society, UK (Editors @ Dept. of Agriculture &amp; Food Economics, University of Reading"</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Agricultural Economics Research</cell><cell>USDA Economics Research Service</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Agricultural Engineering Research</cell><cell>Academic Press for the Silsoe Research Institute (London)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Journal of Agricultural Science</cell><cell>Agricultural University of Norway</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Animal Science</cell><cell>American Society of Animal Science</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Applied Bacteriology</cell><cell>Blackwell Science for the Society for Applied Bacteriology (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Applied Ecology</cell><cell>Blackwell Science (Oxford)</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Bacteriology</cell><cell>American Society for Microbiology</cell><cell></cell><cell></cell><cell>X</cell><cell>Pub</cell></row>
<row><cell>Journal of Biological Chemistry</cell><cell>American Society for Biochemistry &amp; Molecular Biology</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Journal of Clinical Investigation</cell><cell>Rockefeller University Press for American Society for Microbiology</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Journal of Dairy Research</cell><cell>Cambridge University Press</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Journal of Dairy Science</cell><cell>American Dairy Science Association</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Developing Areas</cell><cell>Western Illinois University</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Development Studies</cell><cell>F. Cass</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Ecology</cell><cell>Blackwell Science (Oxford)</cell><cell>X</cell><cell>X</cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Economic Entomology</cell><cell>Entomological Society of America</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Economic Literature</cell><cell>American Economic Association</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Endocrinology</cell><cell>Society for Endocrinology</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Environmental Quality</cell><cell>"American Society of Agronomy, Crop Science Society of America, and Soil Science Society of America"</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Experimental Botany</cell><cell>Clarendon Press for the Society of Experimental Botany</cell><cell>X</cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Journal of Food Processing and Preservation</cell><cell>Food &amp; Nutrition Press</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Food Protection</cell><cell>"International Association of Milk, Food, and Environmental Sanitarians"</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Food Science</cell><cell>Institute of Food Technologists</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of Forestry</cell><cell>Society of American Foresters</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Genetics and Breeding</cell><cell>Instituto Sperimentale per la Cerealicoltura</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Heredity</cell><cell>Oxford University Press for the American Genetics Association</cell><cell>X</cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Journal of Horticultural Science</cell><cell>Headley Brothers</cell><cell></cell><cell></cell><cell></cell><cell>n/a?</cell></row>
<row><cell>Journal of Invertebrate Pathology</cell><cell>Academic Press (San Diego)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Journal of Molecular Biology</cell><cell>Academic Press (London)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Journal of Nematology</cell><cell>Society of Nematologists</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Nutrition</cell><cell>American Institute of Nutrition</cell><cell></cell><cell></cell><cell>X</cell><cell>n/a</cell></row>
<row><cell>Journal of Pediatrics</cell><cell>C.V. Mosby</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>"Journal of Reproduction and Fertility, and its Supplement"</cell><cell>"Journals of Reproduction and Fertility, Ltd."</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of Rural Studies</cell><cell>Pergamon Press</cell><cell></cell><cell></cell><cell></cell><cell>Elsevier</cell></row>
<row><cell>Journal of Soil and Water Conservation</cell><cell>Soil and Water Conservation Society of America</cell><cell></cell><cell></cell><cell></cell><cell>n/a (ProQuest)</cell></row>
<row><cell>Journal of Stored Products Research</cell><cell>Pergamon Press &amp; Elsevier Science (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Elsevier</cell></row>
<row><cell>Journal of Texture Studies</cell><cell>Food &amp; Nutrition Press</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of the American Dietetic Association</cell><cell>American Dietetic Association</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of the American Medical Association (JAMA)</cell><cell>American Medical Association</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of the American Society for Horticultural Science</cell><cell>American Society for Horticultural Science</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Journal of the Association of Official Analytical Chemists International</cell><cell>Association of Official Analytical Chemists</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Journal of the National Cancer Institute (JNCI)</cell><cell>National Cancer Institute/U.S. Government Printing Office</cell><cell>X</cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Journal of the Science of Food and Agriculture</cell><cell>J. Wiley for Society of Chemical Industry</cell><cell></cell><cell></cell><cell></cell><cell>Pub (Wiley)</cell></row>
<row><cell>Journal of Wildlife Management (and monographs)</cell><cell>Wildlife Society</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Lancet</cell><cell>"Lancet Limited and Little, Brown"</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Land Economics</cell><cell>University of Wisconsin Press</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Lebensmittel-Wissenschaft &amp; Technologie = Food Science &amp; Technology</cell><cell>Academic Press for Swiss Society of Food Science &amp; Technology (London)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Lipids</cell><cell>American Oil Chemists' Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Livestock Production Science</cell><cell>Elsevier Scientific (BV Neth)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Meat Science</cell><cell>Elsevier Applied Science (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Metabolism; Clinical and Experimental</cell><cell>W.B. Saunders</cell><cell></cell><cell></cell><cell></cell><cell>n/a--Not Yet</cell></row>
<row><cell>Microbiological Reviews</cell><cell>American Society for Microbiology</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Microbiology</cell><cell>Society for General Microbiology</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Molecular and General Genetics</cell><cell>Springer-Verlag (Berlin)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Mycological Research</cell><cell>Cambridge University Press for the British Mycological Society</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Nature</cell><cell>Macmillan Magazines</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Netherlands Journal of Agricultural Science</cell><cell>Royal Netherlands Society for Agricultural Science</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>New England Journal of Medicine</cell><cell>Massachusetts Medical Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Norsk Landbruksforsking = Norwegian Agricultural Research</cell><cell>Statens Fagtjeneste for Landbruket = Norwegian Agricultural Advisory Centre</cell><cell></cell><cell></cell><cell></cell><cell>Pub? www.dffe.dk/publikationer/</cell></row>
<row><cell>Nucleic Acids Research</cell><cell>Oxford University Press</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>Nutrition Reviews (&amp; Supplement)</cell><cell>International Life Sciences Institute</cell><cell></cell><cell></cell><cell></cell><cell>n/a (ProQuest)</cell></row>
<row><cell>Oecologia</cell><cell>Springer-Verlag (Berlin)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Outlook on Agriculture</cell><cell>Centre for Agricultural and Biosciences International</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Pediatrics</cell><cell>American Academy of Pediatrics</cell><cell></cell><cell></cell><cell>X</cell><cell>X</cell></row>
<row><cell>Pedobiologia</cell><cell>Gustav Fischer</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Pesticide Biochemistry and Physiology</cell><cell>Academic Press (San Diego)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Pesticide Science</cell><cell>John Wiley for the Society of Chemical Industry</cell><cell></cell><cell></cell><cell></cell><cell>Pub (Wiley)</cell></row>
<row><cell>Physiologia Plantarum</cell><cell>Munksgaard</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Physiological and Molecular Plant Pathology</cell><cell>Academic Press (London)</cell><cell>X</cell><cell></cell><cell></cell><cell>IDEAL</cell></row>
<row><cell>Phytochemistry</cell><cell>Pergamon Press</cell><cell></cell><cell></cell><cell></cell><cell>Elsevier</cell></row>
<row><cell>Phytopathology</cell><cell>American Phytopathological Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Plant and Soil</cell><cell>Kluwer</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Plant Breeding = Zeitschrift f&#x00FC;r Pflanzenz&#x00FC;chtung</cell><cell>Blackwell Wissenschafts-Verlag</cell><cell>X</cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Plant Disease</cell><cell>American Phytopathological Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Plant Pathology</cell><cell>Blackwell Science (Oxford)</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Plant Physiology</cell><cell>American Society of Plant Physiologists</cell><cell></cell><cell></cell><cell>X</cell><cell></cell></row>
<row><cell>"Plant, Cell and Environment"</cell><cell>Blackwell Science (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Planta; Archiv f&#x00FC;r Wissenschaftliche Botanik</cell><cell>Springer-Verlag (Berlin)</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Population and Development Review</cell><cell>Population Council</cell><cell></cell><cell>X</cell><cell></cell><cell></cell></row>
<row><cell>Poultry Science</cell><cell>Poultry Science Association</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Proceedings of the National Academy of Sciences (U.S.)</cell><cell>National Academy of Sciences</cell><cell></cell><cell>X</cell><cell>X</cell><cell></cell></row>
<row><cell>Proceedings of the Nutrition Society</cell><cell>Cambridge University Press for the Nutrition Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub (CABWeb)</cell></row>
<row><cell>Proceedings of the Royal Society of London. Series B</cell><cell>The Royal Society</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Proceedings of the Society for Experimental Biology and Medicine</cell><cell>Blackwell Science (Cambridge)</cell><cell>X</cell><cell></cell><cell>X</cell><cell>Pub</cell></row>
<row><cell>Review of Marketing and Agricultural Economics</cell><cell>Australian Agricultural Economics Society</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Rural Sociology</cell><cell>Institute for Environmental Studies--University of Illinois for the Rural Sociological Society</cell><cell></cell><cell></cell><cell></cell><cell>n/a (ProQuest)</cell></row>
<row><cell>Science</cell><cell>American Association for the Advancement of Science</cell><cell></cell><cell>X</cell><cell>X</cell><cell>X</cell></row>
<row><cell>Scientia Horticulturae</cell><cell>Elsevier for the International Society for Horticultural Science (Netherlands)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Silvae Genetica</cell><cell>J.D. Sauerlander's Verlag</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Sociologia Ruralis</cell><cell>Blackwell (Oxford)</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Soil &amp; Tillage Research</cell><cell>Elsevier Scientific BV (Netherlands)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Soil Biology and Biochemistry</cell><cell>Pergamon Press; Elsevier-Oxford</cell><cell></cell><cell></cell><cell></cell><cell>Elsevier</cell></row>
<row><cell>Soil Science</cell><cell>Williams &amp; Wilkins Co.</cell><cell></cell><cell></cell><cell></cell><cell>n/a--Not Yet</cell></row>
<row><cell>Soil Science and Plant Nutrition</cell><cell>Japanese Society of Soil Science and Plant Nutrition</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Soil Science Society of America Journal</cell><cell>Soil Science Society of America</cell><cell></cell><cell></cell><cell></cell><cell>Springer</cell></row>
<row><cell>The New Phytologist</cell><cell>Cambridge University Press</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Theoretical and Applied Genetics</cell><cell>Springer-Verlag (Berlin)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Transactions of the ASAE</cell><cell>American Society of Agricultural Engineers</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Water Resources Research</cell><cell>American Geophysical Union</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>"Water, Air, and Soil Pollution"</cell><cell>Kluwer Academic</cell><cell>X</cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>Weed Science</cell><cell>Weed Science Society of America</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>World Bank Economic Review</cell><cell>World Bank</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>World Development</cell><cell>Elsevier/Pergamon Press (Oxford)</cell><cell></cell><cell></cell><cell></cell><cell>Pub</cell></row>
<row><cell>World's Poultry Science Journal</cell><cell>Butterworth for the World's Poultry Science Association</cell><cell></cell><cell></cell><cell></cell><cell>n/a</cell></row>
<row><cell>Zeitschrift f&#x00FC;r Pflanzenern&#x00E4;hrung und Bodenkunde = Journal of Plant Nutrition and Soil Science</cell><cell>VCH Verlagsgesellschaft</cell><cell></cell><cell></cell><cell></cell><cell>Wiley</cell></row>
<row><cell>KEY:</cell><cell>n/a = not available</cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell></cell><cell>Pub = publisher</cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell></cell><cell>Not yet = publisher does offer some e-journals but this title is not yet available</cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell>Searching Steps:</cell><cell>1. Library catalog</cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell></cell><cell>2. Google</cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell></cell><cell>3. 2nd publisher (like Elsevier) if needed</cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
<row><cell></cell><cell>"4. Verified titles on ECO, JSTOR, Highwire"</cell><cell></cell><cell></cell><cell></cell><cell></cell></row>
</table></p>
</div3>

<div3 type="part" n="09"><head>Endnotes</head>
<note id="CorGrant01">[1] Archival Workshop on Ingest, Identification, and Certification Standards (AWIICS), 13-15 October 1999 &#x003C;http://ssdoo.fsfc.nasa.gov/nost/isoas/awiics/ws.html&#x003E;</note>
<note id="CorGrant02">[2] &#x003C;http://www.ukoln.ac.uk/events/cedars-2000/&#x003E;</note>
</div3>
</div2>

<div2 type="subsection" n="02"><head>PROPOSAL FOR A STUDY OF ELECTRONIC JOURNAL ARCHIVING</head>
<p rend="center">Submitted to the Andrew W. Mellon Foundation <lb/>October 13, 2000</p>
<p>The Harvard University Library is requesting funding from the Andrew W. Mellon Foundation to create a plan for the archiving of electronic journals, in response to a letter of invitation received from the Foundation in August 2000.</p>

<div3 type="part" n="01"><head>BACKGROUND</head>
<p>The Harvard University Library, from its founding in 1638, has sustained a commitment to preserve its vast research collections for current and future use by scholars worldwide. In the twentieth century, traditional book repair and rebinding activities were complemented by a preservation microfilming program that is more vigorous today than ever before and continues to strengthen. Programs for collections conservation, special collections conservation, digitization, studio photography, and sound re-recording are equally vigorous; as are preservation field services, disaster preparedness activities, and efforts to upgrade environmental controls in library buildings throughout the institution.</p>
<p>Two years ago the Harvard libraries received a $12 million grant from the University to build the infrastructure needed to support the creation, storage, and delivery storage of digital library collections. Since then a team of library and computer specialists has been assembled, and the development of many basic architectural components for Harvard's digital library is now well underway. We believe that this infrastructure will provide the basis for a robust digital preservation program. Although we already have enough experience to be keenly aware that establishment of a preservation program for digital library resources will be a complex and expensive undertaking, we anticipate that building such a program on top of the library's general digital collections infrastructure will help to control development and operating costs. The components of our infrastructure that we believe are applicable to a digital archiving project include:</p>

<list>
<item>A repository system to support reliable, sustained storage and management of very large numbers of digital objects;</item>
<item>A "naming" system to support the identification and location of digital objects in a persistent and system-independent way;</item>
<item>A generalized model of access management to protect intellectual property;</item>
<item>Expertise in the design of metadata schemes, the information necessary to manage, display, preserve, and re-purpose digital objects;</item>
<item>Scalable operations support to ensure the professional operation of an ongoing production service for the ingestion and storage of a significant number of digital objects</item>
</list>

<p>The library has funding to carry development of this infrastructure forward for at least 3 more years.</p>
<p>Harvard's level of acquisition of published digital resources is growing rapidly, and the University now lists more than 2,000 journals and databases in its electronic gateway. Shared expenses for electronic resources across Harvard now exceed one million dollars, and combined expenditures for the purchase of digital resources by individual Harvard libraries is at least an equal to this. Strategically, the growth of digital acquisitions at Harvard has been directed toward collection priorities and the cultivation of best practices rather than by market trends. Most journals that we subscribe to electronically are individually selected by subject bibliographers on the basis of merit rather than being acquired through publisher-driven "all-or-nothing" packages. Licensing guidelines have been developed to advise the libraries and prospective vendors in the acquisition and negotiation process, with an emphasis on fair use protections, archival rights, and vendor accountability.</p>
<p>Currently, most of the electronic journals we offer are also acquired in paper format. In large part this is because both librarians and the faculty they serve are concerned about preserving archival access for the long term, for which currently only the paper copy will suffice. This duplication involves duplicate costs and efforts, and is not sustainable over time. Addressing the archiving of electronic journals is thus strategically important to Harvard.</p>
</div3>

<div3 type="part" n="02"><head>PLANNING TOPICS</head>
<p>Digital preservation is a new and very immature field. An E-journal archiving program will involve the exploration of many complex and ill-defined issues. During the planning process we will analyze a number of key areas, with the intent of developing sufficient understanding to allow us to prepare a concrete plan for a 4-year archiving project. Among the key areas we will address in the planning process are:</p>
<div4 type="subpart" n="01"><head>Target content</head>
<p>We face at least 2 key questions regarding content. The first is, "What specific journals will we archive?" We envision a three-part selection strategy.</p>

<list>
<item>We will seek at least one arrangement with a publisher providing a significant volume of articles (the "anchor tenant") to test the scaling of our archive.</item>
<item>We will seek agreement with at least one scholarly society with an active publishing program. Working with these two sources, which we believe will present quite different perspectives on the project, we will develop a model for the archive-publisher relationship.</item>
<item>We will analyze the list of E-journals for which we acquire <hi rend="bold"><hi rend="italics">only</hi></hi> digital copies, and select a number of titles for archiving. These titles will likely involve quite different challenges from those with the "anchor tenant," reflecting different business models, technical expertise, and institutional roles. We are also very likely to try to extend our archiving efforts to include non-journal electronic serials, where we are acquiring an increasing number of titles with equally pressing preservation issues.</item>
</list>

<p>The second content-related question has to do with which of the various components of the selected journals we will encompass in the archive. Journal articles are reasonably straightforward as objects. They have obvious granularity, well-developed conventions and systems for bibliographic description, and established identification schemes (SICI, DOI). The other parts of journals are less obvious. Does one include such textual elements as letters to the editor or book reviews? Advertisements? Does one need to replicate the "issue" as originally published, including such elements as cover and table of contents page? Are links in articles included, and what responsibility for these does the archive assume? E-journals are beginning to include sophisticated related materials (models, data sets, simulations, programs, etc.). Are these to be included? And preserved? A key task in our planning year will be to analyze such additional content, create an inventory of types, draft a policy addressing how such materials should be handled, and discuss with our peers this proposed policy (see "Discussion of NERL role" below).</p>
</div4>

<div4 type="subpart" n="02"><head>Discussions with publishers</head>
<p>A critical element in any attempt to archive commercial intellectual property in electronic form will be negotiating the respective rights and responsibilities of publishers and archiving institutions. To what degree will publishers bear the cost of preparing archival formats of published materials? Or of creating the metadata required for archiving? Who will be able to access archived materials, and under what circumstances? Will publishers support part of the cost of archiving?</p>
<p>We will use the planning year to begin discussions with selected publishers about these issues. Given the uncertainty of funding for archival operations, we cannot begin negotiating archiving licenses, but we hope to raise both our own level of sophistication and that of possible project publishing partners, and to begin to build a consensus regarding what "normal" practice will be in this area.</p>
</div4>

<div4 type="subpart" n="03"><head>Technical requirements</head>
<p>While it is popular to contend there are more policy than technical issues involved in archiving, Harvard believes that there are indeed a great number of technical issues and developments involved in a sophisticated archiving program. Among the areas for investigation are:</p>

<list>
<item><hi rend="italics">Accession automation</hi>. In order to control costs and make a large-scale operation possible, as much as possible of the process of adding materials to the archive will need to be handled by computers rather than people. Areas such as ingestion, quality control, format transformations, and metadata ingestion and creation lend themselves to automation.</item>
<item><hi rend="italics">Format investigation</hi>. The cost and complexity of archiving will depend to a significant degree on the technical formats of the objects archived. Investigation of the formats available from publishers, as well as the formats preferable for archiving, will be a key planning issue. It may be necessary to develop a policy regarding what formats will be accepted into the archive.</item>
<item><hi rend="italics">On-going validation or auditing</hi>. Archival collections will require periodic evaluation to ensure against the loss of content or viability. Some form of systems support for such auditing will be required. Auditing may also require third-party access facilities (discussed below).</item>
<item><hi rend="italics">Bibliographic control</hi>. It is not clear what level of bibliographic control over the archival collection will be needed. It is likely that some new bibliographic facility will be required for at least some objects (such as journal issues, as opposed to articles).</item>
<item><hi rend="italics">Naming</hi>. Analysis is needed to determine what archival objects will require formal naming, where such names should be recorded (particularly outside of the archiving institution), and what the relationship is between archived objects and existing formal naming systems such as the Digital Object Identifier.</item>
<item><hi rend="italics">Access management</hi>. While Harvard has established a generalized access management facility for digital content, it is primarily oriented towards internal users. Depending on the nature of archiving licenses, extensions will probably be needed to provide for appropriate external access. (Such access will presumably be offered at the institutional rather than individual level, based on the Mellon guideline specifying that the primary responsibility of an archive should be to institutional subscribers).</item>
<item><hi rend="italics">Storage strategy</hi>. As envisioned, Harvard's archiving project is likely to involve a considerable amount of content. During the planning year we will create estimates of the number of objects involved and their size, and devise an appropriate strategy to minimize the combined cost of storage and operations.</item>
<item><hi rend="italics">Output facilities</hi>. A key issue will be who has access to archived materials, and what the service expectations of such users will be. Will we provide Harvard users with day-to-day access to materials, perhaps as part of ongoing validation? If so, a reasonably sophisticated user interface to objects will be required. Will selected outside users have access in order to validate the functioning of the archive? If so, what delivery format will be required? The Mellon guidelines require that archives deliver objects to other institutional subscribers when the "fail safe" is exercised. Will there be standard formats in which such objects will be delivered?</item>
</list>

<p>These issues will be investigated during the planning phase of the proposed project to determine the nature and scale of developments required, and to create a plan and timeline. Prototype and exploratory developments will be pursued in the planning year as appropriate.</p>
</div4>

<div4 type="subpart" n="04"><head>Internal institutional roles</head>
<p>Traditional preservation activities are a shared responsibility between curatorial departments and preservation technologists. At Harvard, curatorial responsibility is heavily decentralized along topical subject and language lines. It seems unlikely that the scope of an archiving program will be defined in terms of curatorial responsibility, particularly since such a program will likely involve inter-institutional arrangements. Yet archiving necessarily involves fundamental curatorial issues, such as deciding when to migrate materials and to what format, and periodically assessing the state of the archival collection. The planning process will address how to allocate responsibility across current (or new) institutional structures.</p>
</div4>

<div4 type="subpart" n="05"><head>External relationships</head>
<p>No institution will archive solely for its own use, nor rely solely on its own archiving program. Therefore no institution can decide on the nature of its archiving operation in isolation. Harvard proposes to work with its peers in the NorthEast Research Libraries consortium (NERL) on several key aspects of its program:</p>

<list>
<item>requirements for archiving licenses, and the negotiation of such licenses,</item>
<item>decisions about what specific components of journals should be included in an archive,</item>
<item>the standards and "good practices" an archive must follow to be relied upon by other institutions subscribing to the archived content,</item>
<item>the appropriate level of inter-institutional auditing, and</item>
<item>the output formats that must be immediately available from an archive in order to respond to the access needs of other institutions.</item>
</list>
</div4>

<div4 type="subpart" n="06"><head>Costs and economic issues</head>
<p>Harvard believes that the most important single economic issue in archiving electronic journals will be managing costs. The level of archiving eventually undertaken, and the distribution of responsibilities and costs among the players will be very sensitive to the total cost of the enterprise. It is critical that the archiving process be designed to minimize marginal costs. We suspect that three factors will have the greatest impact on costs:</p>

<list>
<item>effective automation of the archiving process to reduce labor and complexity;</item>
<item>sophisticated selection of archiving hardware and software; and</item>
<item>the efficiencies inherent in large-scale archiving operations.</item>
</list>

<p>All three factors will be a constant focus of our efforts in both the planning and implementation phases.</p>
<p>A proposed model for archive cost distribution will be addressed during the planning phase. For paper-based publications, archiving costs were borne in a largely unplanned pattern, with the great majority of libraries and scholars relying on the preservation activities of a relatively small number of institutions. In the archiving institutions, the costs of preservation (the binding of journals, for example) were also largely bundled into collections budgets, as much of the required activity was also related to daily services to users. With digital publications, archiving and day-to-day access can be (and are likely to frequently be) separately calculated and budgeted. This will require that the community more explicitly address the issue of cost distribution.</p>
<p>There are 3 immediately obvious sources of support for archiving: publishers, the digital archiving institutions, and other subscribing institutions (particularly those that would previously have archived paper copies of a title). In addition, there may be new sources of support, including governments (some of which have been active in the support of microform-based preservation), foundations, scholarly societies, and cooperatives of various sorts (library, scholarly, higher education). It seems likely that the pattern for support will not be the same for all types of publications. The funding structure for archiving the publications of a scholarly society, for example, may be different from that for publications issued by a for-profit publisher or of an academic department.</p>
<p>During the planning phase, we will undertake several initiatives related to long-term funding:</p>

<list>
<item>analysis of different types of publications for which different sources of funding might be appropriate;</item>
<item>exploration with publishers of the distribution of costs, particularly those related to the preparation of objects and metadata for archiving; and</item>
<item>discussions within NERL about the distribution of costs, perhaps making this an explicit part of the negotiations at the point of acquisition. (NERL's primary role today is the joint licensing of commercial electronic resources.)</item>
</list>

<p>A key product of the planning phase will be a proposed budget for the archiving project, addressing staffing (development, operations, and management), hardware and software acquisitions and maintenance, third-party service vendor costs, and overhead.</p>
</div4>
</div3>

<div3 type="part" n="03"><head>PROJECT STAFFING</head>
<p>The planning project will be carried out primarily by a Project Manager with both library and technology experience, working with various teams within Harvard and without. The Project Manager will be Y. Kathy Kwan, a librarian with significant systems experience who recently joined Harvard after serving as an Associate Fellow at the National Library of Medicine. Kwan will be dedicated full time to the planning project. Within the Harvard libraries we will form two primary teams:</p>
<p><hi rend="italics">Project Steering Committee</hi>. This group will be composed of senior curators, preservation experts, and library systems staff, and will address functional and organizational issues. Proposed members of the Committee are:</p>

<list>
<item>Marianne Burke (Assistant Director for Resource Management, Countway library of Medicine)</item>
<item>Dale Flecker (Associate Director for Planning and Systems, Harvard University Library)</item>
<item>Diane Garner (Librarian for the Social Science, Harvard College Library)</item>
<item>Jeffrey Horrell (Associate Librarian of Harvard College for Collections)</item>
<item>Y. Kathy Kwan (Project Manager)</item>
<item>Jan Merrill-Oldham (Malloy-Rabinowitz Preservation Librarian)</item>
<item>Constance Rinaldo (Librarian, Ernst Mayr Library of the Museum of Comparative Zoology)</item>
<item>Lynne Schmelz (Librarian for the Sciences, Harvard College Library)</item>
<item>MacKenzie Smith (Digital Library Projects Manager)</item>
</list>

<p><hi rend="italics">Technical Team</hi>. An internal team composed of staff with significant experience in digital library development will investigate technical issues and systems requirements. Proposed members of the Team include:</p>

<list>
<item>Stephen Chapman (Preservation Librarian for Digital Projects)</item>
<item>Dale Flecker (Associate Director for Planning and Systems, Harvard University Library)</item>
<item>Y. Kathy Kwan (Project Manager)</item>
<item>MacKenzie Smith (Digital Library Projects Manager)</item>
<item>Robin Wendler (Metadata Analyst)</item>
</list>

<p>In addition, developers from the current Library Digital Initiative technical staff with appropriate expertise (e.g., repositories, access management) will participate on the Technical Team as appropriate.</p>
<p>A fundamental feature of the LDI development process is the regular open review of all technical analyses and designs by a group technical experts drawn from across the university. Representatives from academic computing groups, libraries, and museums, and the senior staff of the chief information officer participate in these reviews. The same methodology will be used in reviewing all technical work in the archiving project.</p>
</div3>

<div3 type="part" n="04"><head>PLAN OF WORK</head>
<p>Policy and functional issues will be addressed by the Steering Committee, and technical issues will be handled by the Technical Team. Project activities will be coordinated and documented by the Project Manager. The programmer will be involved in preparing technical specifications and in exploratory development.</p>

<div4 type="subpart" n="01"><head>1. Review literature and current practices (Quarter one)</head>

<list>
<item>Review current efforts in digital electronic archiving, specifically E-journal archiving.</item>
</list>
</div4>

<div4 type="subpart" n="02"><head>2. Secure core publishers (Quarters one and two)</head>
<list>
<item>Approach a potential "anchor tenant" and one scholarly society publisher to explore interest in project participation.</item>
<item>Discuss in detail with the committed publishers, the business and technical issues associated with archiving of E-journals, including title selection, right of access, archival format, metadata creation, and cost distribution.</item>
</list>
</div4>

<div4 type="subpart" n="03"><head>3. Analyze targeted journals (Quarters one and two)</head>
<list>
<item>Examine content of the targeted journals and inventory their types and format.</item>
<item>Decide which components will be archived.</item>
</list>
</div4>

<div4 type="subpart" n="04"><head>4. Foster partnership with NERL (Quarters one and three)</head>
<list>
<item>Meet with NERL members to establish common goals and requirements for an E-journal archive, including content analysis of targeted journals, archival format, good/established practices in handling different data types, trusted access, licensing issues, cost distribution, and ongoing audit.</item>
<item>Formulate policy for the archive based on the outcome of above discussion.</item>
</list>
</div4>

<div4 type="subpart" n="05"><head>5. Define functional requirements (Quarters one, two and three)</head>
<list>
<item>Develop requirements for the archive in the areas of accession, archival format, validation/audit, bibliographic control, metadata, naming, access management, storage, and output facilities.</item>
</list>
</div4>

<div4 type="subpart" n="06"><head>6. Design high-level system architecture (Quarters two, three, and four)</head>
<list>
<item>Design high-level system architecture based on functional requirements.</item>
<item>Propose specifications for software and hardware.</item>
</list>
</div4>

<div4 type="subpart" n="07"><head>7. Select additional titles (Quarters two, three, and four)</head>
<list>
<item>Add to the project a selection of titles that Harvard has acquired in electronic form only.</item>
<item>Discuss project participation with respective publishers.</item>
</list>
</div4>

<div4 type="subpart" n="08"><head>8. Explore internal institutional roles (Quarters two, three, and four)</head>
<list>
<item>Conduct exploratory discussions with relevant parties within Harvard to determine how responsibility, such as selection of content, format migration, system maintenance, and assessment of the state of the archival collection, will be distributed.</item>
</list>
</div4>

<div4 type="subpart" n="09"><head>9. Exploratory development (Quarters three and four)</head>
<list>
<item>Test the validity and explore possible inadequacy of functional requirements as drafted.</item>
<item>Select, with agreement from a relevant publisher, a very small sample for the test.</item>
<item>Develop a system prototype for exploration.</item>
<item>Analyze the result to refine the proposed functional requirements and system design.</item>
</list>
</div4>

<div4 type="subpart" n="10"><head>10. Define the archive policy (Quarter four)</head>
<list>
<item>Consolidate the outcome from discussions with publishers, NERL, Harvard institutions, and the project team, to formulate appropriate policy for the E-journal archive.</item>
<item>Identify all players for implementation and clarify their roles.</item>
</list>
</div4>

<div4 type="subpart" n="11"><head>11. Estimate the cost of an archiving project (Quarter four)</head>
<list>
<item>Chart all parts of the E-journal archive implementation with proposed timeline.</item>
<item>Estimate software and hardware needs, including acquisition and maintenance costs and scale.</item>
<item>Estimate staffing needs.</item>
<item>Estimate the overall budget for program implementation.</item>
</list>
</div4>

<div4 type="subpart" n="12"><head>12. Prepare the program implementation plan (Quarter four)</head>
<list>
<item>Report the findings of the planning year.</item>
<item>Propose the implementation plan for an E-journal archive at Harvard, detailing its mission, guiding policies, scope, participating parties, technical infrastructure, budget, and estimated outcome.</item>
</list>
</div4>
</div3>
</div2>

<div2 type="subsection" n="03"><head>Planning for an Archive of Dynamic E-Journals at MIT</head>

<p><hi rend="bold">Planning for an Archive of Dynamic E-Journals at MIT </hi></p>
<p><hi rend="italics">A proposal for the Andrew W. Mellon Foundation</hi></p>
<p>13 October 2000</p>

<p>The MIT Libraries applaud the interest of the Trustees of the Andrew W. Mellon Foundation in the challenge of maintaining our scholarly literature for future generations. At MIT, we are interested in tackling the archiving of a specific subset of the new scholarly literature, a medium we think will constitute the next generation of e-journal publishing, a medium we will call "dynamic e-journals." Dynamic e-journals are scholarly web sites which aim to share discoveries and insights, but do not feel bound by the conventions of "issues" and "articles" that have become standard in print. We believe that the dynamic e-journals currently published represent the leading edge of a broad range of dynamic content which we must learn to capture for future scholars.</p>
<p>It must be said that developing a model, let alone a mechanism, for archiving dynamic e-journals is an ambitious undertaking, particularly when publishers and libraries are still caught in the transition between paper and electronic publication, trying to decide whether to maintain solid footing in both worlds, or leap, possibly irretrievably, into the electronic sphere. Dynamic e-journals - whose number will inevitably grow - force us even closer to making the leap into the digital arena, since they have no print counterpart. We want to anticipate the growth of this new truly digital mode of scholarship, to be ready with a model and a method to capture these uniquely valuable entities: the first dynamic e-journals. Libraries were not ready with an archiving solution for the first generation of e-journals, but if we move now we can be ready for the second .</p>
<p>This move will not be easy, for the issues involved in archiving dynamic e-journals are complex; indeed, while the technical, procedural, and philosophical issues spawned by the need to preserve electronic journals in their traditional form are significant and daunting, they are dwarfed by the complexities of preserving dynamic e-journals. Because dynamic e-journals leave behind the conventions of print, they explode the archiving challenges. That it took some time for e-journals to reach this point is not surprising. e-journals have followed the pattern common in cases of technological change, in that the first technological innovations mimicked the previous, print-based technology: the first e-journals bundled articles into issues and often were presented as digital images of print pages. e-journals then evolved into a hybrid model which shared features of both the old and the new technologies: they were characterized by online structures resembling print in organization, but with html-based interlinkages. We now find ourselves grappling for the first time with a form that fully leverages the functionality of the new technology.</p>
<p>Dynamic e-journals, with all their complexity, are our future; we want to meet the archiving challenges they represent so that we can be sure we are ready to make the newest form of e-journal dependably available to future scholars. Ignoring the archiving challenges and focusing exclusively on simpler problems first will mean that the very earliest examples of a unique form of scholarly communication may not be available to future scholars. This would be a great loss not only to scholars in the disciplines covered by the dynamic e-journals, but also to future historians and sociologists, and scholars in related disciplines.</p>

<div3 type="part" n="01"><head><hi rend="bold">Dynamic e-journals</hi></head>
<p>On the crest of this second wave of e-journals, MIT Press officially launched CogNet at the end of September, 2000 (<xref doc="cognetmit">http://cognet.mit.edu</xref>). MIT Press believes CogNet is "the future of journals publishing." CogNet strives to create a community for researchers in cognitive and brain sciences. It offers a gateway for scholars' research, teaching, and community needs by acting as a central repository for important traditional resources in cognitive and brain sciences (including books, journals, conference proceedings, and reference works); forming dynamic partnerships with all of the participants in the information chain for cognitive and brain sciences, including scholars, professional societies, academic departments, and other publishers; and providing customized services, all in a dynamic, constantly updated environment. Professor Terrence J. Sejnowski of the Salk Institute and the University of California, San Diego, has said that Cognet "is an important new venture that brings together many different resources for the cognitive and brain sciences. By bringing information directly to researchers and students and allowing rapid dissemination of important new research directions, CogNet is bypassing the slow and expensive efforts in the commercial publishing world. A new model for how scientific publishing will look in the next century is already being tested today in CogNet."</p>
<p>And the MIT Press is not alone. Other publishers have also begun to invent this second wave of e-journals, including Columbia University Press with EarthScape and CIAO (Columbia International Affairs Online). Columbia EarthScape is billed as "an online resource on the global environment." It offers continuously updated information on research and education, including a mix of traditional resources such as conferences, journals, books, and resources "born digital," such as databases, datasets, and a new quarterly publication "Earth Affairs Magazine," as well as sample syllabi, and classroom models. It provides, like CogNet, a central point for access to relevant links and to a multiplicity of resources. Columbia EarthScape has set the goal of "transforming the way researchers, teachers, students, and decision makers get critical information in the Earth sciences and environmental policy." According to their website, the service "creates, selects, and links the widest range of Earth-systems resources available online."</p>
<p>Columbia University Press has also launched CIAO, which, according to the web site (<xref doc="ciaonet">http://www.ciaonet.org/</xref>) "is designed to be the most comprehensive source for theory and research in international affairs. It publishes a wide range of scholarship from 1991 on that includes working papers from university research institutes, occasional papers series from [non-governmental organizations], foundation-funded research projects, and proceedings from conferences." Like its dynamic e-journal counterparts , it aims to offer a dynamically updated, wide-ranging, centralized access point to a variety of resources in a clearly-defined subject area.</p>
<p>In a similar effort, the American Association for the Advancement of Science (AAAS) has collaborated with the Stanford University Libraries and The Center for Resource Economics/Island Press to develop a "Knowledge Environment" to support research in signal transduction. The Signal Transduction Knowledge Environment (STKE) (<xref doc="stke">http://www.stke.org</xref>) is intended to "systematize the consensus knowledge within a scientific domain and to facilitate users' access to that knowledge." The AAAS' idea is that in a Knowledge Environment like the STKE, "access occurs through searching, browsing, and current awareness features combined with user-friendly graphical interfaces. KEs combine primary and review literature with more dispersed sources of "how-to", "what-is", and "where-to" knowledge. Specific electronic tools that facilitate entry of information into the underlying databases are also being developed as part of the concept." Like Cognet, the STKE is intended to harness the full potential of the internet to improve access to current information and the speed and breadth of scholarly exchange. Like Cognet, it is a hybrid, offering access to some traditional forms, but in a new dynamic context that is experimental and evolving.</p>
<p>Vanderbilt University is considering a new publishing venture that could evolve into a dynamic e-journal. Vanderbilt's initiative would involve partnering with scholarly societies and universities to host a site supporting the field of archaeology. According to Paul Gherman, University Librarian, the site would include a preprint server, current journals in the field, monographs, core texts, reports of excavations, maps, and images of artifacts.</p>
<p>These examples make it clear that publishers are beginning to embrace the idea that the web and new media open up new mechanisms for attracting authors and building relationships with their customers far beyond what was available to them in print. Dynamic e-journals are among the first of these new mechanisms, encouraging exchange between readers and authors, and fostering the development of a community of interest around the core of the journal. They depend less on the bundle of articles called an issue, and more on discipline-based contexts which evolve out of the discussions of articles and other submissions.</p>
<p>Dynamic e-journals build community through this creation of context and the potential for dynamic engagement. They fully harness the potential power of the digital environment for scholarly communication, capturing discussions that occur at professional meetings and field trips, weekly seminars, and lab visits for a geographically scattered audience. In so doing, the dynamic e-journal seems, ironically, to bring us full circle from the earliest days of research and scholarship, when small groups of interested researchers sent their papers to each other, forming communities to exchange ideas. This method worked when the number of scholars was limited. Dynamic e-journals graft this same sense of intense, focused community into today's vastly more complex and larger scholarly arena, offering widespread groups of scholars a forum for an immediate exchange, a central source for information, and allowing for contributions ranging from informal to formal. Dynamic e-journals have the power to offer, potentially, both the potency of real-time exchange and a forum for in-depth inquiry.</p>
<p>We have chosen to retain the term "journal" in our description of this new online publication form, because we believe that the essence of the scholarly journal lies not in the container-specific definition of journal as something published in discrete units over time, but rather in terms of the purpose -- the essence -- of what we have known as the scholarly journal. This purpose has been to record, distribute, and provide quality control for scholarly research. The particular package, or container, which was based on the constraints of print publication, was the familiar numbered journal. Shedding the demands of the print container, the soul of the journal is now freed to take on new shape. Dynamic e-journals are the new shape. We expect them to serve as the heart of the system of scholarly communication in the twenty-first century, as the traditional journal did (and still does, for now) in its time.</p>
<p>The existing dynamic e-journals make it clear that journals have already begun evolving into substantially different entities that do more than just distribute standard research articles that have been peer reviewed. New types of content, tools, and services have started to emerge, such as: open posting of articles that have not been peer-reviewed for open review; publication of articles as completed, prior to publication in issues (being done currently by American Chemical Society); working papers; articles of longer length than standard research articles; negative results; datasets; computational models; and aggregations of content from a number of different journals into new collections. Additional services -- such as letters to the editors, links to abstracting and indexing services, and material from other journals, bibliographies, indexes, related links, etc. -- will be bundled with the content in order to keep the journal, albeit in a more dynamic form, as the central tool for publication of new research.</p>
<p>It could be argued that at this stage in the development of dynamic e-journals, the new "container" is primarily an amalgam of traditional publication forms, with some added functionality. We believe that even if dynamic e-journals currently contain pieces borrowed from the print world and from traditional forms, such as key reference works, they will evolve beyond these forms. It seems inevitable that once freed from the constraints of print, dynamic e-journals will begin to tap the potential of the digital world and will become less and less like the print entities they may currently include. Even as aggregations, dynamic e-journals constitute a new "species" of publication: with the added "born digital" elements as well as added functionality and opportunity to comment and interact with the material, with the connectivity and context offered by dynamic e-journals, the whole is bigger than the sum of its parts. And, above all, it is important to begin resolving the archiving issues that are inherent in such multifaceted and dynamic tools while they are still evolving.</p>
</div3>

<div3 type="part" n="02"><head><hi rend="bold">Archiving Dynamic e-journals</hi></head>
<p>Though dynamic e-journals bring benefits to authors and readers that cannot be achieved in print, their shape-shifting nature presents unique demands for anyone trying to capture their content. As noted above, the challenge is especially complex for dynamic e-journals. This is true for several reasons:</p>

<list>
<item> It is more difficult to identify those points in time when new content arrives in these publications and updating is less programmatic than in the traditional journals, where all new content takes a specific form: an article or an issue.</item>
<item> It is more difficult to identify appropriate retention strategies, as various aspects of these publications will be of varying degrees of historical scholarly value.</item>
<item> Various components of these publications (conference papers, datasets, interactive discussions) may demand different archival strategies and methods, both because of their varying significance and their varying technical underpinnings.</item>
<item> The "look and feel" of dynamic e-journals is more complex and multi-faceted, so determining how to replicate the entire e-journal through archiving is also more complex.</item>
</list>

<p>Given these challenges, working through the "Minimum criteria" included in the call for proposals, and determining how to meet these with regard to dynamic e-journals, would be a major part of the planning we would engage in over the next year. We would need to work on a series of questions, including: How could we define our archival mission? What would be the appropriate deposits? How much context will be necessary for presenting the content of a dynamic e-journal to future scholars? What elements merit archiving, according to what means? What auditing techniques and agents would test our fulfillment of mission? With whom could we network to ensure broader preservation of this information? Are there significantly different copyright implications due to the dynamic nature of these e-journals?</p>
</div3>

<div3 type="part" n="03"><head><hi rend="bold">MIT Strength and Timing</hi></head>
<p>Archiving this content demands a close working relationship with the publisher and possibly even new techniques that a publisher could use to push archival content out to an archive site as it is generated within the dynamic site. As we come to understand the strategies that work for gathering this content, we imagine we could define them in ways that would allow publishers to work with more remote partners. But to develop the strategies will certainly take an established base of trust.</p>
<p>The MIT Libraries and the MIT Press have a relationship we believe could sustain such an effort. (This relationship is strengthened by the fact that both the Libraries and the Press report to the same individual, Ann Wolpert, Director of Libraries.) We expect that what we establish as fair groundrules for archiving of dynamic e-journals could be used as a template for building similar relationships with other publishers, particularly university presses. We would test this by reaching out to a few other publishers, such as Columbia University Press, to explore the realities of expanding the model developed at MIT.</p>
<p>A year of working out the appropriate relationships and technical details will also put the MIT Libraries in a good position to leverage the digital repository infrastructure we are building as part of our DSpace project to house the archived e-journal content. Since we will be depending on this infrastructure as the long-term home of our own digital output, we would welcome the opportunity to submit the process to the auditing required to satisfy both ourselves and our partners that it serves as a safe repository for dynamic e-journals.</p>
<p>The MIT Libraries also participate in the Northeast Research Libraries consortium (NERL). Other NERL institutions are engaged in similar e-journal archiving projects. We plan to share information about strategies and tools with them in a supportive environment that emphasizes mutual learning. In addition, we will use the body of NERL institutions as a forum on the issue of acceptable assurance of reliability over time.</p>
</div3>

<div3 type="part" n="04"><head><hi rend="bold">Planning Process</hi></head>
<p>We feel that this project would be best managed by a full-time project planner who could coordinate efforts across the libraries and with our publisher partners. This planner would be responsible for three broad activities:</p>
<p>(1) surveying the existing e-journal environment and negotiating partnerships with appropriate publishers of dynamic e-journals;</p>
<p>(2) exploring the strategies and technologies we might apply to archiving dynamic e-journals, understanding the legal issues, and convening meetings of experts to illuminate the challenges; and</p>
<p>(3) developing a specific plan for building a sustainable dynamic e-journal archive at MIT and nurturing investment in the plan by key stakeholders. While the project planner and other staff of the libraries involved in this effort would certainly be welcome to experiment with prototypes of the archiving process, our real focus for the planning year would be on the partnerships, strategies, and plans which have to be put in place for a serious development project to get under way in future years. From a raw technology perspective, we hope to be able to take advantage of the Dspace repository infrastructure (<xref doc="webbmitdspace">http://web.mit.edu/dspace</xref>) so that it becomes a home for e-journal archives as well. We also bring to the project our limited experience collecting a mirror of the three existing e-journal-only publications of the MIT Press.</p>
<p>Our working relationship with MIT Press is quite strong, but this project will require a broader scale of participation than the Press. Our survey effort will seek to identify other publishers developing second-wave dynamic e-journals. Ideally, we would identify two other publishers with whom to forge relationships. We will also want to make sure that our strategy is planned with reference to the direction other NERL institutions pursue on this topic. We hope that over time archives can interoperate sufficiently to serve as fail-safe repositories for one another and auditors of each other's practice. </p>
</div3>

<div3 type="part" n="05"><head><hi rend="bold">Work Plan</hi></head>
<p>Quarter 1: Our activity will focus on recruiting a Project Planner, negotiating for publishing partners, detailed analysis of the technical and legal challenges, and a thorough review of prior applicable work. Along with partnering with the MIT Press we anticipate approaching both Columbia and Stanford as partners for the full archiving project, and identifying experts in related, applicable areas, e.g., archiving dynamic information such as web sites and listservs.</p>
<p>Quarter 2: We will bring together partners and experts for the first of two workshops exploring the complexities of the issues undertaken, and identifying the key technical and legal hurdles which need to be addressed. The Project Planner will develop and lead teams of staff from MIT and its partners in developing the technical specifications required for success, based on the <hi rend="italics">Minimum Criteria for an Archival Repository of Digital Scholarly Journals.</hi></p>
<p>Quarter 3: We will provide the necessary time to explore, test, and refine the technical specifications developed previously. It will also allow us to determine whether the DSpace project provides a suitable infrastructure for supporting the dynamic e-journal archive, and if other applicable work, e.g., LOCKSS, can be used.</p>
<p>Quarter 4: We will first reconvene our partners and necessary experts to explore the work done, and provide ample time for discussion, review, and exploration of outstanding issues. Based on the outcome of this final two day workshop necessary revisions in the proposal will be made.</p>
</div3>

<div3 type="part" n="06"><head><hi rend="bold">Budget</hi></head>
<p>I. Qualified staff will be essential to the success of this proposal. A full-time Project Planner is a requirement. The Project Director will be Carol Fleishauer, Associate Director for Collections Services. She will be the key liaison from the Libraries, providing guidance to the Project Planner and coordinating the participation of other MIT Libraries staff with expertise in licensing, e-journals, preservation, technical, and user issues.</p>
<p>II. Equipment and software will be necessary for the Project Planner.</p>
<p>III. Travel by the Project Planner to partnering organizations will be required to build understanding of the dynamic e-journal environments produced by each of the publishers. In addition we anticipate that solicited partners will need to visit the MIT team on occasion.</p>
<p>IV. Workshops will be important activities to facilitate useful discussion and analysis of the technical, legal, and social challenges associated with this project. We propose two workshops, each lasting two days. The first will help define the specific issues that make dynamic e-journals different than normal e-journals. The second will be helpful in reviewing the progress made in the planning year, and insure that the final proposal is relevant and possible. The workshops are intended to bring together key players from the "dynamic journal" publishing world with key technical people who have experience in (or are experts in) archiving dynamic information of various types (web sites, listservs, publications). Outcomes of the workshops would be to: define some of the problems inherent in archiving dynamic journals; develop possible strategies for approaching these problems; create connections between MIT Libraries and key players that will result in longer-term dialogues; develop archiving "awareness" within the publishing community; brainstorm possible solutions.</p>
<p>V. Funds will cover normal workshop expenses, e.g., travel, food, stipends, and consulting fees for legal and other experts.</p>
<p>VI. Communication charges will cover expenses incurred by the Project Planner.</p>
<p>VII. Other charges are nominal costs for related administrative expenses.</p>
</div3>

<div3 type="part" n="07"><head><hi rend="bold">Outcomes</hi></head>
<p>The primary product of this grant will be an MIT proposal for a full Electronic Journal Archiving Project. By the time we submit such a proposal, we also expect to have an explicit list of publishers who have signed an appropriate document indicating their readiness to pursue the project with us. Finally, we will have clarified the technical strategy we plan to use to capture such dynamic e-journals.</p>
</div3>

<div3 type="part" n="08"><head><hi rend="bold">Contacts</hi></head>
<p>We have a small team of staff working on this project at MIT. The main contacts for this proposal are:</p>
<p>Eric Celeste, efc@mit.edu, 617-253-8184</p>
<p>Carol Fleishauer, fleish@mit.edu, 617-253-5962</p>
<p>Teresa Ehling, ehling@mitpress.mit.edu, 617-253-1672</p>
</div3>
</div2>

<div2 type="subsection" n="04"><head>New York Public Library, Archiving performing arts journals: A planning project</head>
<p><xref doc="diglibpreservenyplprop101300">http://www.diglib.org/preserve/nyplprop10-13-00</xref></p>
</div2>

<div2 type="subsection" n="05"><head>Stanford University, LOCKSS: A distributed digital archiving system</head>
<p>(see the Lockss website at <xref doc="lockssstanford">http://lockss.stanford.edu</xref>)</p>
</div2>

<div2 type="subsection" n="06"><head>UNIVERSITY OF PENNSYLVANIA</head>
<div3 type="part" n="01"><head>PROPOSAL FOR A PLANNING GRANT FOR ARCHIVING AND PRESERVATION OF ELECTRONIC JOURNALS</head>
<div4 type="subpart" n="01"><head>The problem</head>
<p>Like many research libraries, the University of Pennsylvania Library subscribes to an increasing number of journals in electronic form.  The digital form of journals offers some significant benefits compared to the print form, including enhanced accessibility, search facilities, linking services, and the ability to include and extract new kinds of content (such as data sets) in scholarly publications.  However, subscribing to publications in electronic form also carries substantial risks.  When we obtain print journals, we can be reasonably sure that we will continue to have full access to them in the years to come, at little cost to us, because the technology of print preservation is well understood and because access and preservation of our print journals is not constrained by legal restrictions or the continuing fortunes or policy of a publisher.  On the other hand, technology for the preservation of digital information is unproven for long-term preservation.  Furthermore, the legal and economic environment of electronic journal subscriptions is also in flux, making our ability to maintain control over our copies of electronic journals uncertain.  These risks have made libraries hesitant to take full advantage of the benefits electronic journals can provide.  They also threaten the long-term viability of the record of scholarship.</p>
<p>Reliable, persistent electronic journal archives solve many of these problems.  Such archives benefit the libraries that subscribe to electronic journals, by ensuring that they will continue to have access to journal content, and be able to use it effectively for scholarly activity, over the long term.  Such archives also benefit the publishers of  electronic journals: They make it more attractive for libraries to buy subscriptions, since they know they will have long-term access to current and past issues of the journals.  Archives also benefit the authors of journal content, by ensuring that their scholarship remains in public view.</p>
<p>Since the Penn Library started acquiring and creating digital content, we have recognized the need to preserve it for decades, or even centuries. All of our digital collections need to have preservation support: not just our electronic journals, but also our digitized images, our on-line books, our catalogs and finding aids, our databases, and our multimedia content.  Journal literature, as the primary record of progress in scholarly research, is especially important to preserve over the long term. Moreover, we expect to use techniques and tools for archiving and preserving electronic journals to archive and preserve other types of digital information as well.</p>
</div4>

<div4 type="subpart" n="02"><head>The proposal</head>
<p>Therefore, the Penn Library proposes to establish a long-term digital archive for electronic journals, as part of the Mellon Electronic Journal Archiving Program.   We intend to make arrangements with selected publishers of electronic journals to archive their publications. We intend to set up a system that can ensure their long-term accessibility.  We intend to study how such systems can be set up to effectively archive electronic journals at low cost.  We intend to share our findings, and (where permitted by applicable licenses) our archival systems and content, with the broader library community. </p>
<p>Paul Mosher, the Director of Penn Libraries and Vice-Provost of the University of Pennsylvania, is very interested in moving this project forward.  He will be visiting with publishers later this month to start partnerships with them in creating such an archive.</p>
<p>We propose to start with a one-year phase to design and plan the archive, to start archiving selected journals on an experimental basis, and to study the costs and benefits, and optimal strategies, for maintaining such an archive.  We expect that this phase would produce several important contributions:</p>

<list>
<item>Agreements with publishers to provide electronic journal content for perpetual use and archiving, and models for agreements on the rights and responsibilities of electronic journal archives. </item>
<item>A design, and the beginnings of a first implementation, for sustainable, distributed archives for electronic journal content. </item>
<item>A framework (both technical and procedural) for working with peer institutions to share information and responsibilities concerning archived electronic journals, including a consensus on minimum criteria for trustworthy electronic archives. </item>
<item>An experience report and evaluation on best practices for starting and maintaining journal archives. </item>
</list>
</div4>

<div4 type="subpart" n="03"><head>Advantages of Penn as a pilot site </head>
<p>Penn's digital library program has several features that make it especially well-equipped to act as a pilot site for this program: </p>

<list>
<item>We have in place, or are working on developing, many of the pieces of the digital architecture that would be needed to support an electronic journal archive.  In particular:
<list>
<item>We have acquired a terabyte-scale networked disk storage unit for on-line access to our digital holdings, which should provide reliable access and backup.  While this unit is largely already allocated to other projects, we can expand the existing structure for archiving electronic journal issues. </item>
<item>We have implemented, and now maintain, a database containing information about the electronic journals to which we subscribe.  We are now developing tools for librarians to input new information into this database, and for patrons to browse and search the database to gain access to full-text journal content.  The database, and accompanying tools, could be extended to manage metadata about journals we archive, and provide access to them. </item>
<item>We have installed a Handle server, and are implementing tools for maintaining Handle databases, that should provide persistent identification and location of digital content, including electronic journal content, that is not dependent on the location of the content or the technology used to manage or serve it. </item>
</list></item>
<item>We are participating in collaborative programs organized by RLG and the DLF to provide metadata about our digital collections to peer institutions using standard formats and protocols.  We hope to use similar mechanisms to give libraries information about our electronic journal holdings, and share content where licenses permit it. </item>
<item>We have been working with Oxford University Press, a major publisher of scholarly books and journals, for over a year to make their current book releases in history available to our local community.  We have gained experience in working with publishers to receive their digital content, convert it to a form suitable for on-line use, maintain it, and make it available under terms mutually beneficial to the publisher and our scholarly community.   Our OUP book project has included tools to browse and search the content of books.  It aims to study how electronic books can be used most effectively in a university environment.  We hope to reuse infrastructure, findings, and experience from this project in our journal-archiving efforts.</item>
<item>We have a large body of professionals who are experienced and knowledgeable in applying digital library technology to meet the needs of library users.  All major branches of the library, from public services to cataloging to special collections, have integrated digital technology into their operations for several years.  In addition, we have specialized staff, with library, computer science, and information technology experience, whose primary job is to research and develop digital library technology.  They work with the rest of the library staff to deploy it in effective ways. </item>
</list>

<p>In the past year, our digital library group has gained substantial experience in migrating digital data and metadata into new forms suitable for long-term use.  Projects we have worked on have included converting digital image data and metadata from low-resolution and proprietary formats to high-resolution, standard formats; conversion of static web pages and scripts into database forms that can be presented and browsed in a variety of forms; and conversion of a Yiddish database built on 1980s-era dBase programs and private character encodings into a database searchable and browsable on the Web that uses standard Unicode representations for non-Roman characters.</p>

<list>
<item>We can use, and make available to other institutions, a distributed software architecture for managing data formats, and for supporting operations that extract information from these formats and migrate data from old to new data formats while controlling information loss.  This architecture, known as the Typed Object Model (TOM), has been developed by a computer scientist now on our library staff, has been used for several years as the basis for a web-based conversion service, and has open-source software implementations available through the Penn library.  TOM should be an important tool in keeping electronic journals usable even if the data formats in which they were originally published become obsolete.</item>
</list>
</div4>

<div4 type="subpart" n="04"><head>Planned Activities</head>
<p>Here is what we plan to do during the planning phase of the project:</p>
<div5 type="division" n="01"><head>1. Select a set of electronic journals to start archiving, and make arrangements with their publishers to archive them.</head>
<p>We intend to concentrate on academic publishers, and to archive as many of each publisher's journals as feasible.  For the initial phase of the project, we hope to set up archiving for at least 80 journals from at least two publishers.  Although we do not yet have confirmed journal archiving partners, we plan to initially approach Oxford University Press (with whom we already have an arrangement to store and provide on-line books), and Cambridge University Press, with whom we also have working ties.  Our library director, Paul Mosher, will be visiting both publishers in late October.  We already subscribe to about 120 electronic journals provided by Oxford and Cambridge, which would be a sufficient base for the initial phase of this project.  If our needs and scale warrant, we would also approach other publishers.</p>
<p>For the planning phase, we would start by archiving issues that are already in electronic format, and issues that appear in the future. However, we would design the archive so that newly digitized past issues could also be included.  (Retrospective conversion may play more of a role in the second phase of the program, but some initial experimentation, to assess how the archive could accommodate different production workflows and formats, may also be conducted during the planning phase.)</p>
<p><hi rend="bold">Milestones:</hi> </p>

<list>
<item>By 3 months from the start of the grant period, we expect to have made initial arrangements with at least two publishers to work with us in setting up an archive for their journals. </item>
<item>By 6 months, we plan to start collecting journal content from these publishers, either harvested from the Web, or sent to us by special arrangement with the publishers. </item>
</list>
</div5>

<div5 type="division" n="02"><head>2. Negotiate agreements (licenses) of archival rights and responsibilities with our publisher partners.</head>
<p>When we started to make Oxford University Press books available to our users, a simple "gentleman's agreement" was sufficient for the first phase of our collaboration.  In the longer term, however, archives must negotiate more explicit licensing agreements that clearly spell out the rights and responsibilities of the publishers and archivers of electronic journals, and guarantee them into the future.  Otherwise, an archive may find itself unable to keep the promises that it has made to preserve archived issues and provide them to the scholarly community.</p>
<p>We will need to negotiate licenses with the publishers sufficient to enable us to maintain the utility of the archived issues and provide them to the scholarly community.  In some respects, the terms of these licenses can simply guarantee the same legal rights and abilities that libraries already have for archiving their print journals.  In particular, we would seek</p>

<list>
<item>the right to store the electronic copies, and provide access to our campus users, in perpetuity. </item>
<item>the right to provide access to other institutions and mirror sites (based on their subscriptions, parallel or consortial arrangements with publishers, and/or the passage of time since the original publication of the journal). </item>
<item>the right to create derivative works based on the originally licensed material, for the purpose of maintaining useful, high-quality access to the journal content as technology changes.</item>
<item>the right to create and supply metadata on the journal content to the public at large. </item>
<item>the right to transfer the electronic content, rights, and responsibilities, to another archiving institution. </item>
</list>

<p>At the same time, we would prepare and publish statements of the archival responsibilities assumed for each journal or set of journals.  Because the exact form of an electronic journal may need to change as technology changes, these statements would need to make clear exactly what functions of the journal would be preserved.  For example, the commitments made for one journal might include preserving the text, charts, and other illustrations of the editorial matter of the journal, and its table of contents, but not include preserving the exact pagination and layout, or advertising matter.  (A journal of more historical interest than direct scholarly interest, though, might have its page images preserved, in contrast.)  Other commitments may relate to the metadata preserved for journals, the policy for corrections and errata, supplementary data sets, or value-added services like full-text indexing or reference linking.  Because no institution is guaranteed to go on forever, we would also need to account for the possibility of transferring responsibility for these commitments to other parties, both in our licensing agreements and in our statements of responsibility.</p>
<p>We intend to seek guidance from our university counsel, and possibly from our law school and library, in crafting such agreements.  Even more importantly, we intend to collaborate with other partner libraries in the journal archiving project to produce a set of model licenses and statements of responsibility. We believe the most effective journal archiving system will involve many different publishers, with archival responsibilities shared by multiple institutions.  Standard licenses and statements of responsibilities, developed through the collaboration of several active archives and publishers, can greatly smooth the operation of a distributed archival system.</p>
<p><hi rend="bold">Milestones:</hi></p>

<list>
<item>By 3 months from the start of the grant period, we will have locally prepared an initial draft of rights and responsibilities we expect our archive to have. </item>
<item>By 6 months, we expect to have made initial legal agreements with the publishers we  started working with, of at least limited duration.  At this point, we would provide the details of these agreements to partners in the archiving project, for discussion and consultation. </item>
<item>By 12 months, we expect to have "permanent" agreements with these publishers (that is, with archival rights for materials collected to date granted in perpetuity). </item>
</list>
</div5>

<div5 type="division" n="03"><head>3. Determine the necessary metadata and workflow needed to receive, validate, archive, and provide access to electronic journals.  Make necessary arrangements with publishers, and within the library, to support this workflow and maintain this metadata.   Decide on standard initial formats and protocols to use to communicate our electronic journal data and metadata.</head>
<p>Our agreements with journal publishers would include specifications of the content formats and metadata we expect them to provide. We would also create our own metadata for descriptive and administrative purposes, and for supporting value-added services.  We would plan to share non- administrative metadata with the public at large, so that others can see what we hold, what we're committed to providing, and how we keep track of our holdings.</p>
<p><hi rend="bold">Milestones:</hi></p>

<list>
<item>By 4 months into the grant period, we intend to have detailed descriptions of the metadata we intend to use in the project, and the initial workflow we plan to follow. </item>
<item>By 7 months, we plan to have provided the details of the metadata and workflow actually used to partner institutions. </item>
<item>By 12 months, we plan to have at least some of this metadata publicly viewable. </item>
</list>
</div5>

<div5 type="division" n="04"><head>4. Design, and begin installing, an information base (consisting of databases and filesystems) for storing and accessing archived journal content and related metadata.</head>
<p>This would include installing tools for checking the integrity of this data, and for backing it up (both within the organization, and with mirror sites).  We would also install (and implement, where needed) required client and server software for communicating e-journal data and metadata, under appropriate access control.</p>
<p>Unlike the archival commitments specified earlier, the exact choices of formats, protocols, and software used in the information base can change over time as needed.  However, it is still important to make initial choices that will support our archival commitments, that will be compatible with the practices of our content suppliers, archiving partners, and readers, and that can be transferred or translated for new technology when needed. </p>
<p><hi rend="bold"> Milestones:</hi></p>

<list>
<item>By 6 months into the grant period, we expect to have an initial information base set up to store journal content and metadata.</item>
<item>By 12 months, we intend to have made initial agreements with institutional partners to mirror material.</item>
</list>
</div5>

<div5 type="division" n="05"><head>5. Plan, and begin to install, documentation and support for the data formats and protocols used by the archive.</head>
<p>Support should include, where feasible, translation of data to alternative formats, and/or services to provide access to information managed using formats and protocols not directly supported by clients.   (That is to say, we should set up migration and emulation services for our data.)</p>
<p>Even if there is no immediate need for migration and emulation services, due to the exclusive use of widely-used formats and protocols, such services will eventually be necessary as technology changes.   By setting up support for migration and emulation from the start, we hope to reduce costs incurred later on, by building on the support and knowledge base already built for our old systems.  Furthermore, the startup costs for this form of data format support give us some empirical basis for estimating, and amortizing, the costs of keeping up with technology change over the long term.</p>
<p><hi rend="bold">Milestones:</hi></p>

<list>
<item>By 9 months, we will have available documentation (written by ourselves or by third parties) of the standard formats and protocols used in our information base. </item>
<item>By 11 months, the standard data formats used in our archive will be registered with our type brokers (see <xref doc="tomlibraryupenn">http://tom.library.upenn.edu/</xref>) with converters or data extraction services available.</item>
</list>
</div5>

<div5 type="division" n="06"><head>6. Start acquiring and archiving journals, indexing them, providing metadata, and providing content to authorized parties, on an experimental basis.</head>
<p>From the start, measure computing resources and labor required to enter and maintain the journals.  Measure their usage as well.  Using this data, evaluate the costs and benefits of running the archive, and consider possibilities for ongoing funding sources (such as internal funding, shared costs in a consortium, and/or revenue from subscriptions).  Our experience and analysis would also permit us to make well-informed plans for ongoing staffing, acquisitions, and access policies for the archive.</p>
<p><hi rend="bold"> Milestones:</hi></p>

<list>
<item>By 6 months, we will have decided on measurement and assessment practices for our initial phase.  Measurement will begin on incoming content.  Also at this point, initial proposals for sustaining the archive will be made, and publicized to partners.</item>
<item>By 9 months, local users will be able to examine content in our information base under appropriate access control and usage logging.</item>
</list>
</div5>

<div5 type="division" n="07"><head>7. Produce a report, at the end of the year, describing our experience and findings from the planning year.  Assuming our findings are reasonably positive, produce a plan for continuing, and growing, the archive on a permanent basis.</head>
<p>We would work with fellow archiving and journal-using sites to reach agreement on suitable protocols, practices, and architecture for long- term, distributed journal archives.  We would also distribute any software and metadata that we develop for managing the electronic journal archives.    (For example, this could include TOM servers and associated access and translation scripts for data formats used in the archive.)</p>
<p><hi rend="bold">Milestones:</hi></p>

<list>
<item>By 12 months, an experience report will be published, and a plan for continuing the archive will be submitted to Mellon.  Software developed by us, and not subject to licensing constraints, would also be made available when in a reasonably stable state.
</item>
</list>
</div5>
</div4>

<div4 type="subpart" n="05"><head>Schedule</head>
<p>Here is a summary of the milestones described above, arranged chronologically.  (Note that these are dates of expected completions.  Work on these items will start considerably earlier.  In particular, work towards the milestones of the first 6 months would start as soon as possible.)</p>

<p><table>
<row><cell><hi rend="bold">3 months:</hi></cell><cell>Initial archiving arrangements made with publishers. Draft licenses/statements of rights and responsibilities written.</cell></row>
<row><cell><hi rend="bold">4 months:</hi></cell><cell>Detailed descriptions of metadata and workflow created.</cell></row>
<row><cell><hi rend="bold">6 months:</hi></cell><cell>Initial journal archive information base created. Initial licenses/statements of rights and responsibilities agreed to and distributed for comment. Collection of journal content and metadata begins. Initial plans for sustainability proposed.</cell></row>
<row><cell><hi rend="bold">7 months:</hi></cell><cell>Details of metadata and workflow provided to partner institutions.</cell></row>
<row><cell><hi rend="bold">9 months:</hi></cell><cell>Journal archive content available to local users Standard formats and protocols publicly documented.</cell></row>
<row><cell><hi rend="bold">11 months:</hi></cell><cell>Broker services available for standard archive data formats.</cell></row>
<row><cell><hi rend="bold">12 months:</hi></cell><cell>Initial mirroring arrangements made. "Permanent" licenses/statements of rights and responsibilities agreed to. Journal metadata publicly viewable. Experience report and plan for continuation. Software depot set up for locally developed tools.</cell></row>
</table></p>
</div4>

<div4 type="subpart" n="06"><head>Staffing</head>
<p>The following staff members will be working on this project:</p>
<p><hi rend="bold">John Mark Ockerbloom (project lead)</hi> is digital library architect and planner at the University of Pennsylvania library.  He joined the Penn Library in 1999, coming from Carnegie Mellon University, where he earned a Ph.D. in computer science in 1998.  He has been involved in digital library- related projects since 1993.   His thesis work, for instance, included the design and implementation of a distributed architecture for managing diverse data formats, which has applications in digital library interoperability and preservation.  He was a consultant for the Universal Library project at Carnegie Mellon, and has presented his work to the Coalition for Networked Information, the ACM Digital Libraries Conference, and the Mid-Atlantic Regional Archives Conference.  At Penn, his achievements in migrating old technology to new uses have included the successful adaptation of a multilingual Yiddish song database from 1980s dBase technology and private character sets to a Web-accessible searchable form using Unicode and standard HTML. He also edits The On-Line Books Page, the Internet's longest-running site indexing and supporting freely available on-line books.</p>
<p><hi rend="bold">Delphine Khanna</hi> is a digital projects librarian at Penn.  She joined the Penn Library in 1999.  She came to Penn from Rutgers, where she worked on several digital-library projects of the Center for Electronic Text in the Humanities.  At Penn, she has led several digital library projects, including an ongoing, project to archive and provide access to hundreds of thousands of digital images from our Fine Arts library.  She has experience and expertise implementing projects with many formats and programs used in digital libraries, including SGML and XML, EAD, TEI, Cold Fusion, Verity, and DLXS.  She holds a Masters of Library Science from Syracuse University, and a Masters of Linguistics and Computer Science from the University of Paris, France. Michael Winkler is the Web manager at the Penn Library.  He joined the Penn library in 1999, after working in a similar role at North Carolina State University.  At Penn, he has defined both data structures and workflows for changing our electronic journals, databases, and new materials information from ad-hoc, hand-maintained web pages to structured, low-overhead databases which are being integrated with our Franklin library catalog, and delivered to the public through new, powerful search tools.  (Some of these tools can now be found at http://www.library.upenn.edu/prototypes/public.html) Roy Heinz is the director of Library Computing at Penn Library, which supports all aspects of digital library use and development at Penn.  He is also the project lead for our Oxford University Press on-line books project, funded by the Mellon Foundation. Grover McKenzie is senior systems programmer and Unix system administrator at the Penn Library.  He has worked for Library Computing for the past nine years, and has installed, maintained, and upgraded our Unix- based servers (including those for our Oracle database, and our new terabyte- scale networked storage unit), and our networking and backup infrastructure.</p>
<p>We plan to expand our staff, using funds from various sources (including this grant), to include at least one more person providing programming and database support for our digital library projects.  This person, once hired, may (among other duties) build the tools and database we would use for this project. Before then, John Ockerbloom, Delphine Khanna, and Michael Winkler would be developing or installing any necessary tools for this phase of the project. John Ockerbloom would be in charge of planning, designing, and reporting on the project, and maintain liasons with our external partners. Grover McKenzie would provide support for the basic network and storage infrastructure.  Roy Heinz, along with other high-level library management staff, would oversee the progress of the project, and facilitate relations with our external partners. the project, and helping to build a robust infrastructure and community for electronic journal archiving.</p>
</div4>
</div3>
</div2>

<div2 type="subsection" n="07"><head>PROPOSAL FOR A DIGITAL PRESERVATION COLLABORATION</head>
<p rend="center">between The Yale University Library and Elsevier Science</p>
<p rend="center">10 October 2000</p>
<p>1. ENDURING ACCESS TO ELECTRONIC JOURNALS. Authors, publishers, and librarians all feel it is imperative that assured long-term access to electronic journals be provided. The inherent mutability of information technology, a rapidly changing marketplace for electronic publishing, and the absence of any well-established preservation practice for electronic information make the prospect for long-term access most doubtful. Until we have successfully addressed this issue, scholarly communication will remain bound to print and paper because with these formats we can assure long-term access to traditionally published scholarly information. This is a costly and dysfunctional bondage, where electronic publication otherwise serves scholarly communication decidedly better.</p>
<p>The Yale Library and Elsevier Science regard the long-term access to electronic journals as mission critical. We feel that both organizations have vitally important, complementary capabilities to bring to a digital archives project. Our experience in negotiating licenses leaves us feeling confident that we respect one another's institutional imperatives and value the human talent in both organizations that must be engaged in an archival project. We believe we will be able to manage genuine differences in our organizational missions and cultures in a way that will allow us to work in close collaboration on our shared concern for digital archiving.</p>
<p>Assured access to electronic journals embraces a variety of activities that might usefully be grouped in three categories, each distinctively driven by:</p>

<list>
<item><hi rend="underline">The circumstances of ordinary commerce</hi>. Included here are access arrangements (such as mirror sites) designed to deal with ordinary telecommunications, time zone, and redundancy needs. This category also includes arrangements for responding to extraordinary emergencies (such as massive equipment failure, damage done by hackers, etc.).</item>
<item><hi rend="underline">Likely changes in publishing</hi>. The Yale Library and Elsevier Science recognize that some arrangement must be made to ensure enduring access to electronic content in the face of changing commercial circumstances. What should be done when some substantial part of a publisher's content is no longer commercially viable (the digital equivalent of going "out of print")? when a publisher sells a particular journal, ceases publication of one or more titles, bundles material in significantly different ways, or disengages from a certain line of business? when a publisher is sold or goes out of business? Such changes in a company's commercial circumstances pose grave threats to enduring access to its publications. In an enterprise as volatile as publishing now is, we should expect many such changes in any 10-20 year period.</item>
<item><hi rend="underline">Traditional archival needs</hi>. In the very long term (100 years+), most readers will address questions to an archive of Elsevier Science publishers unlike the questions of today's practicing scientist. These questions will normally be of a historical character, and they will be addressed to an archive structured in ways that are especially responsive to historical inquiries. These questions will reflect the intellectual paradigms of the future, which can hardly be predicted today.</item>
</list>

<p>The term "archiving" has been applied somewhat indiscriminately to all of the situations where assured long-term access to electronic journals is needed. Elsevier Science provides for timely, uninterrupted access to its electronic publications as a part of its ordinary business. The publisher has its own telecommunications capabilities and back-up arrangements in place and is exploring additional arrangements with national libraries and local-load customers to guard against more damaging emergencies. Recognizing these arrangements, the Yale Library and Elsevier Science propose to take action on the two other access needs identified above.</p>
<p>We seek funds from the Andrew W. Mellon Foundation for a year-long effort to plan our archive in detail and to create the test-bed computing capabilities needed for that planning.</p>
<p>2. DEFINING THE SCOPE OF A COLLABORATIVE PROJECT. The Yale Library and Elsevier Science intend to work collaboratively in the following ways:</p>

<list>
<item>The library and Elsevier Science both wish to understand the ordinary commercial life cycle of scientific journal articles so that we might create an archive that protects readers from the failures of access that are likely to occur in that cycle. We believe that the competitive, commercial marketplace can be a highly efficient way of providing access both to individual articles and aggregations of them (say in journals or in still larger databases). We also believe there is a time when the marketplace will no longer support access to some part of a publisher's output. This point in time will vary immensely from article to article, from journal title to journal title, from discipline to discipline, etc., and neither publishers nor librarians yet know enough about the online environment to predict confidently when this time will come. But everything in our experience suggests that continuing always to burden commercially viable content with content that is not, or that is only marginally viable, robs us of the economic efficiencies of the marketplace. So burdened, a publisher is likely to change its business plan or, in the extreme case, go out of business. These are points of great risk for scholarly communication, as the ordinary uses of the threatened journals may become unsupported. We must develop an archival practice that guards against this danger.</item>
<item>The library is interested in working with Elsevier Science to support ordinary archival uses of that company's journals published electronically. Responding to well-established patterns in the use of archival collections, our archive will be designed to support two principal kinds of inquiry, both of them significantly unlike the needs of the practicing scientists that Elsevier Science journals are created to support. These are (1) inquiries into the scholarly, business, technical, and policy environments within which Elsevier conducted its publishing business; and (2) inquiries that treat archival information in transformative ways. Inquiries of the former sort usually draw on a wide variety of resources and are sometimes possible only after confidential or commercially sensitive information in an archive can be opened for study. Inquiries of the latter sort usually address subject or disciplinary interests unlike those that originally prompted the publication of the material in the archive. Such inquiries typically require some reconfiguration, re-assembly, or re-purposing of the archival information (often in conjunction with other archival holdings). There is no way confidently to predict what these archival inquiries will be, who will make them, and when they will be made. The most likely prediction about these archival uses, judged by other archives, is that they will be relatively infrequent initially but will increase over time as the scholarly value and integrity of the archive increases.</item>
</list>

<p>3. DISTINGUISHING CONCEPUTALLY BETWEEN CONTENT AND FUNCTIONALITY. In the print world, intellectual content and the physical presentation of that content (including, for instance, indexes and elements of graphic design) are immutably linked in discrete, time-bound publications. Whole intellectual disciplines, such as descriptive bibliography, have developed around this fixed relationship between content and its physical embodiment (the elements of which are sometimes referred to as paratext features). In the digital world, no such immutable links exist. Indeed, readers positively expect the presentation of content to change, in the form of new system functionalities that enhance use. But at the same time, readers are most uneasy with the thought that the intellectual content of electronic publications might change in ways unknown to them. Readers insist on the authority and authenticity of digital content but welcome changes in functionality.</p>
<p>The Yale Library and Elsevier Science, observing this striking difference in reader behaviors in the print and digital worlds, wish to test the viability of archival services based on a fundamental distinction between the "content" of the scientific articles Elsevier publishes and the "functionality" provided to readers by Elsevier at any given point in time. We believe this distinction may be critically important in setting and meeting reader expectations about digital archives, in devising technical strategies for meeting those expectations, and in controlling the long-term costs of archival services. We have therefore made the distinction a central feature of the exploratory planning we are proposing to the Mellon Foundation.</p>
<p>We define content as the data and discourse about the data that authors submit to the publisher, along with other discourse-related values added by the publisher's editorial process (e.g., revisions prompted by peer review, copy-editing). We define functionality as a set of further value-adding activities that do not have a major impact on the reader's ability to understand content. So understood, functionality embraces a very wide spectrum of things, from graphic design to search engines, and from branding or aggregating practices to the provision of links among related materials. Functionality has most to do with reader productivity (e.g., the ease and efficiency, or even the pleasure of use). Functionality is not linked to individual content but is pervasive to large bodies of content. In posing this distinction, we recognize that the boundary between content and functionality may not be crystal clear in every circumstance. It is likely to vary at any given time as one moves from one disciplinary literature to another, from one publisher to another, and from one journal to another. It is also likely to change over time, as technology evolves. While we recognize this significant variability, we also believe that the distinction is inherent to digital technology and is likely to figure centrally in any viable archival strategy.</p>
<p>More specifically, we believe an archive of electronic journals must unquestionably preserve and provide access to the journals' content, as here defined, over very long periods of time (i.e., 100+ years). Users of the archive must feel confident they are seeing the data and discourse the author and publisher agreed to publish, and not some other version of the work (e.g., a pre-print) or versions of the work corrupted by non-authorial intrusions. By contrast, we hypothesize there is no comparably important idea of archival functionality. Authors, readers, and publishers alike expect functionality to improve over time and independently of any specific content. There is rarely a compelling interest in maintaining earlier functionality (except where there is a failure to improve, as for instance when changes in functionality threatened access to content). And while it is certainly possible to imagine archival inquiries that turn on the functionality provided by the publisher at a given point in time, one might well wish to archive functionality separately and in a manner different from content.</p>
<p>Similarly, because archival inquiries are unlike those that shape the business practices of the publisher, the functionality offered by the publisher may not be what would best support archival use. Indeed, if one accepts that much archival use is unpredictable and requires the repurposing of archival materials, any idea of a single "authentic" functionality may be a barrier to effective archival inquiry.</p>
<p>4, TECHNICAL MEANS FOR DISTINGUISHING BETWEEN CONTENT AND FUNCTIONALITY. Technically, how might an archive of Elsevier Science journals separate content from functionality and ensure the authority and authenticity of the former for the long term?</p>
<p>In addressing this question, we distinguished among four fundamental representations of content carried in digital bits and bytes.</p>

<list>
<item><hi rend="italics">Alphabetic, symbolic, and BLOB codes</hi>. Digital bits and bytes encode alphabets and symbols, using ASCII and Unicode conventions, and a variety of digital objects, using BLOBs (i.e., binary large objects). BLOBs are used to encode tables, images, multi-media objects, etc. ASCII code is one of the most stable features of the digital environment because it is so basic and flexible, because it is used so pervasively, and because it represents massive sunk-costs. It makes economic sense to focus archival effort at this level of coding.</item>
<item><hi rend="italics">Document codes</hi>. While more recently developed, SGML and related document codes (representing many paratext elements) are a second fundamental level of coding that is essential to create meaning from digital bits and bytes. We expect document codes to be relatively stable and for that reason to be an appropriate target for archival effort.</item>
<item><hi rend="italics">Metadata</hi>. Metadata relating to a given document is a particularly important category of encoded information. Standards for such metadata are now being developed, with the intention that such information will remain relatively stable in the otherwise fast-changing digital environment. Metadata will be particularly important to and an appropriate target for our archival effort.</item>
<item><hi rend="italics">Rendering software</hi>. The library as an archival agency must provide its readers with the ability to render alphabetic, symbolic, BLOB, and document codes into a form that can be read and used. Today, a number of choices present themselves, including OpenText, Science Server, and IBM's Digital Library. Other choices will no doubt present themselves in the future. It is possible that some rendering software will be more effective in supporting a particular line of archival inquiry than others. Especially given the unpredictability of archival inquiries, it will probably be important that the alphabetic, symbolic, BLOB, and document codes be renderable by a number of different software packages.</item>
</list>

<p>5. CREATING A BASIC ARCHIVE. Elsevier Science is able and willing to provide the Yale Library with SGML versions of nearly all of its current journals (c. 1,100 titles). The availability of back files in SGML form varies, with significantly less SGML material being available for pre-1998 publications. Other digital formats-including TIFF and PDF-wrapped TIFF files-are available for pre-1998 material. Elsevier Science does not wish to provide and the Yale Library does not wish to use for either of the two services described here the full online functionality offered to Elsevier customers. Elsevier Science will, however, provide to the archive all of the metadata it creates. In its simplest conceptual terms, therefore, our agreement is that Elsevier Science will provide the content for the archive (i.e., the bits and bytes coded for rendering alphabetic and other symbols, BLOBS, documents, and the metadata associated with this content), while the library will provide rendering software and the computing environment for its use.</p>
<p>In creating that environment, we will draw on the inherent advantages for archiving of a multi-tired client/server architecture supported by a mass storage archival system. Tier three of the system will provide database management functionality where the content will be stored in a RDBMS, ODBMS, or a file system. Tier two, our middleware, will provide process management software. We are drawn to the archival management software being developed at the San Diego Super Computer Center and at the Harvard and MIT libraries (our partners in the Northeast Library Consortium, or NERL) to manage the intake, object naming schemes, validation, access management, and other tasks that must be performed at this tier. The design of the these tiers will be informed by the InterPARES Project, a leading effort to develop the knowledge required for the permanent preservation of digital records, and by the standards for digital archives being advanced by the Council on Library and Information Resources and the Digital Library Federation. Tier one of our archival system will provide a user interface, in the form of a web server-browser, to request, render, and display data from tiers two and three.</p>
<p>The content and computing architecture just described will constitute a digital archive capable of meeting the two most essential archival responsibilities. These are (1) preserving the documentary content published by Elsevier Science and the evidence of provenance relating to that content, and (2) supporting a wide range of largely unpredictable inquiries against that content and its provenance.</p>
<p>At the same time, we intend to design our archive to be technically capable of meeting the ordinary, non-archival information needs of readers should (or when) commercial circumstances prompt Elsevier Science to change its business practices in ways that imperil access to its content. The Yale Library and Elsevier Science will identify a set of specific circumstances in which the library's archive will become the means of ordinary access to Elsevier Science journals. These will include the business changes identified above, such as when parts of the publisher's content becomes commercially non-viable, when publication of a title ceases, when the publisher substantially changes its line of business, etc. The Yale Library and Elsevier Science will establish agreements governing the intellectual property affected by changed circumstances such as these. We will also describe the computing environment that the Yale Library will provide to support ongoing access and the latitude the library will have for non-profit business arrangements that might improve the provision of access. Both collaborators will publicize their agreement on these matters, to inform authors and the wider library community about the steps we are taking to ensure that enduring, long-term access to our archival content is certain.</p>
<p>The Yale Library already has substantial experience in working as trial local-load customer of Elsevier Science. This experience prompts our interest in a preservation project, and we are particularly glad to have the strong support of the Elsevier Board of Directors for this project. Though we will provide an archival home for only one publisher initially, considerable variety in the size and content of Elsevier's publications ensures that our technical design will be generalizable and scalable. Moreover, we believe the example of a successful project with one of the world's most important publishers of science journals will be influential when we approach other publishers, later, and when other libraries and publishers consider collaborative action on archiving. Finally, the archival profession urgently needs some highly visible success stories regarding digital content. The ready engagement in and commitment of Elsevier Science to this project will be important factors in our success in planning and implementing archiving services.</p>
<p>6. A DEVELOPMENTAL ARCHIVE. Although we feel confident about our ability to design a digital archive able to meet basic archival responsibilities and provide against an important set of commercial contingencies, many questions will remain about the good design and management of a digital archive. In our initial discussions, the Yale Library and Elsevier Science have identified the following questions as important to both of us. We expect to refine, refocus, and prioritize these questions and to identify others during the planning phase of our project.</p>

<list>
<head><hi rend="italics">Questions bearing on the technical design of the archive</hi></head>
<item>How persistent will the coding conventions be for alphabets, symbols, BLOBs, documents, and metadata? Are there real economic advantages in making these canonical codes the focus and basic building blocks of our archival work?</item>
<item>A significant part of what Elsevier Science has published digitally exists now only as TIFF and PDF-wrapped TIFF files, and not in SGML. Should this material be included in the archive, even though the more basic coding is not available? This question points to a yet more fundamental one. What do we regard as the most reliable document for archival purposes? Is it a particular rendering of the document (a TIFF file, for instance) or is it the underlying content coding that can be rendered in a number of different ways?</item>
<item>What are the limits of our ability to separate content from functionality? These two are so closely linked in much software design that we will surely encounter areas in which the separation cannot be made without some jeopardy to the integrity and utility of the archival record.</item>
<item>What should the archival record of functionality be and where and how should it be maintained? In what measure is the provenance of functionality more closely bound to the publisher's corporate archive than to the content itself?</item>
<item>What options for data rendering and other middleware software do we have? Do any of these options meet archival purposes better? Do any promise to be more robust for those cases where the archive must substitute for the normal, commercial means of access?</item>
<item>What resonance does our proposed separation of content and functionality have with thinking within the digital preservation community about migration and emulation strategies? Does either strategy become decidedly more or less attractive given this separation?</item>
<item>How does one test the reliability over time of the archive as a means of reader access to its digital content?</item>
<item>Significant differences in media stability and storage capacity suggest there may be a significant choice to be made between tape or compact disk technology for our storage medium. How do these trade-offs bear on our ability to contain the cost of media migrations over long periods of time?</item>
<item>Our focus on the fundamental alphabetic, symbolic, BLOB, and document codes assumes relative stability in those codes, some of which are just now being developed. It may be that over very long periods (100+ years), even these basic codes will change so much that emulating them or migrating through their changes will be formidably expensive, especially in light of presumably infrequent use of archival material. Given this possibility, should we explore a technically bi-modal archiving strategy that preserves the content (not the functionality) as digital output to microfilm, which could be reconverted to digital format on demand where that re-conversion was appropriate for a particular archival inquiry? If there is merit in such a bi-modal approach, how would certain information (e.g., color images, video and audio material) be handled?</item>
</list>

<list>
<head><hi rend="italics">Questions relating to changes in commercial circumstances</hi></head>
<item>Can we anticipate some kinds of commercial change and manage them proactively? For instance, can we identify a set of ordinary uses of Elsevier Science content that can or should be segmented because they pose distinctive commercial challenges? Should we actively plan for different commercial strategies to maintain access to current materials (including, say, material published in the last 5 years), recent materials (e.g., material published 6 to 15 years ago), and older materials (e.g., published more than 15 years ago)? At some point, access to infrequently used material will not be profitable and will burden the commercially viable parts of the publisher's business. How can we measure and understand such information life cycles in a way that serves both the commercial needs of Elsevier Science and the access needs of readers, where those needs diverge? Are there technical or other operational synergies among a publisher's profitable services, its emergency back-up services, and the not-for-profit operations of an archive that can be invoked to manage through this information life cycle?</item>
<item>What resources-human, technical, and financial-will be required to sustain the archive indefinitely over time? What contribution will Elsevier Science make, as the creator of the archival material, toward meeting these resource needs? What contribution will the Yale Library make as an archival agency? What contribution would other libraries, which depend on the existence of the archive, make? Are there points in the life cycle of Elsevier Science publications where marginal revenues might be realized but might not justify the commercial effort required to earn them? If so, might these revenues be used to help support the cost of archival operations? (A rough analog is the way some university presses are now using mid-list books that are no longer sufficiently profitable to attract trade publishers to build income to support traditional scholarly publishing.)</item>
</list>

<list>
<head><hi rend="italics">Questions about the utility of the archive</hi></head>
<item>What view will authors take of the proposition that the digital coding of their documents, rather than a particular rendering of those codes, constitutes the archival record of their work? More generally, what view will authors take of the systematic differentiation between content and functionality that we propose? These same questions need to be posed to users of the archive as well.</item>
<item>When commercial changes shift readers away from the commercial services of Elsevier Science to the archive, in accord with our agreements, will a technical structure appropriate for infrequent archival inquiries adequately support possibly more frequent ordinary use? In such circumstances, the archives middleware and telecommunications capabilities may not be appropriately scaled and they may not offer some functionality important to readers. How will these issues be addressed, and what not-for-profit business arrangements might be instituted to solve problems of scale that arise in such circumstances?</item>
<item>What kinds of inquiries will be made of the archival record we create? Are we right in predicting they will be sufficiently infrequent, <hi rend="italics">sui generis</hi>, and involve such transformative uses of the record that they pose no attractive commercial opportunities for Elsevier Science? Can the library maintain a fully open (or "bright") archive that responds usefully to archival inquiries but does not seriously threaten the commercial interests of Elsevier Science? More broadly, what demand for related archival resources will an archive of journal content create? What impact will our content archive have on broader records management and archival practices within Elsevier Science?</item>
<item>How do the costs of maintaining a digital archive of Elsevier Science publications compare with those of maintaining a print version of the journals to ensure long-term preservation and access? In considering this cost differential, how should we appraise the capabilities of digital publishing that cannot be replicated in print?</item>
</list>

<list>
<head><hi rend="italics">Questions that may affect the strategic direction of Elsevier Science</hi></head>
<item>Given the likely difficulty in some cases of disengaging content from functionality, are there things that Elsevier Science might do in the design of its current and ongoing business process to facilitate that separation? That is, in what ways can its commitment to good archival practice become a source of strategic direction for Elsevier Science?</item>
<item>The metadata provided by Elsevier Science will be the primary testimony to the provenance of the documents in our archive. How adequately do these metadata represent the processes by which Elsevier Science conducts its business and creates a public (i.e., a published) record of scientific communication? Are additional metadata required? Here again, in what ways might its commitment to good archival practice become a source of strategic direction for Elsevier Science?</item>
<item>Is there provenance information about the documents in our archive that might best be maintained in a separate corporate archive? For instance, is information about editorial board membership for a given journal best kept in our archive of individual published documents or in a corporate archive of Elsevier Science? Where should the archival record of the functionality Elsevier Science created and delivered to its customers be kept, in both the near and long term?</item>
</list>

<list>
<head><hi rend="italics">Doomsday question</hi></head>
<item>Acting alone, the best that any publisher can do to ensure enduring long-term access to its content is to make credible arrangements to transfer that content to a library, should commercial circumstances make that necessary. This is true of Elsevier Science as a commercial publisher, just as it is true of JSTOR, the nearest we have today to a trusted third-party agent for preservation and access. There are, however, no agencies to which libraries can hand off their preservation and access commitments, should they need to. Is there anything that can or should be done about this fact? Is there anything about this fact that has changed with the emergence of digital technology? Is there anything that can or should be done now to protect the preservation mission of libraries against the pressures created by other parts of their mission?</item>
</list>

<p>7. INITIAL PLANNING ACTIVITIES. Few of the questions posed above can be usefully explored-either by the Yale Library and Elsevier Science or by other investigators-unless we actually create a digital archive. There follows an outline of the planning steps we will take over a year's time to create a digital archive for the journals published electronically by Elsevier Science. An italicized statement at the end of each bullet indicates the sequence and duration of our planning activities.</p>

<list>
<item>Decide (for at least initial implementation) on the content of the archive. Will it include TIFF and PDF-wrapped TIFF files as well as SGML files? Will it include a variety of editorial matter (names of editors, instructions to authors, copyright policies, etc.) as well as content created by authors? Will the archive include advertisements appearing in the print versions of the journal? Does the archive require any metadata beyond what Elsevier Science now routinely creates? Will the archive include ancillary indexing and abstracting services or free information resources now created by Elsevier Science? The decisions we make on these issues need not be regarded as definitive or final. Indeed, we may wish to make different decisions on some of these matters for various parts of our archival file, so as to test the utility of our initial answer to these questions. <hi rend="italics">First quarter.</hi></item>
<item>Establish initial agreements regarding intellectual property and other business practices that will govern the archive as the means of supporting ordinary use of Elsevier Science content when changes in commercial circumstances make that necessary. <hi rend="italics">First quarter</hi>.</item>
<item>Acquire and deploy the test bed computing hardware and software needed for the archive of Elsevier Science publications described above. Explore the willingness of software developers to provide their products to us for short-term testing and development activities at no cost or at below-market rates. During the planning year, only a test-bed level of capability will actually be deployed. Production level capabilities would be created in the follow-on demonstration project. Nonetheless, planning would attend carefully to questions of operational efficiency and to questions of scale as regards the initial size of the archive, its growth over time, and the requirement that the archive be capable of supporting some approximation of normal use should commercial changes require the archive to support such uses. Decide whether the archive will support more than one capability for rendering the encoded material of the archive. <hi rend="italics">First and second quarters</hi>.</item>
<item>Devise and implement prototype procedures to ensure both the  reliability of the archive's content (i.e., it faithfully represents the editorial and publishing activities of Elsevier Science) and its authenticity (i.e., material in the archives persists without change, except such changes initiated and documented by the archive as part of carrying the material forward through time). These activities and those in the next bullet will require substantial travel and consultation, to ensure that our project takes full advantage of the archival work being done at other NERL partner libraries and by R&amp;D laboratories elsewhere. <hi rend="italics">First and second quarters.</hi></item>
<item>Devise and implement prototype methods by which the operational stability and reliability of the archive can be tested periodically. The object here is to create a solid record of access, for both archival and normal inquiries, that leaves the community served by the archive confident of its technical reliability. <hi rend="italics">Second quarter.</hi></item>
<item>Devise and implement prototype methods to register and assist readers pursuing archival inquiries, comparable (where appropriate) to those used in print archives. Devise and implement service quality improvement procedures that use our experience with readers to improve the archive. <hi rend="italics">Third and fourth quarters.</hi></item>
<item>Develop a fully-detailed technical, service, and business plan for the creation of an enduring archive of Elsevier Science publications. Design this plan so that it might accommodate the journals of other publishers. <hi rend="italics">Third and fourth quarters.</hi></item>
<item>Continually revisit, refine, and refocus the questions posed in the previous section. Restate them as appropriate and begin to devise the methodologies that may be used for addressing them, giving special attention to those that bear on the long-term sustainability of preservation and archival functions. <hi rend="italics">All four quarters.</hi></item>
<item>Prepare project announcements and reports, as appropriate, for the Mellon Foundation; for the publishing, library, and digital preservation communities; and for authors writing for Elsevier Science publications.</item>
</list>

<p>8. PROJECT STAFFING AND BUDGET.</p>
<p><hi rend="italics">Staffing</hi>. Scott Bennett (Yale University Librarian) and Ann Okerson (Associate University Librarian) will co-direct the project, drawing on their substantial experience in scholarly publishing, preservation, copyright, and licensing. They each expect to devote not less than 5% of their annual effort to the project. They will in fact devote whatever time is required to ensure the success of the project.</p>
<p>Karen Hunter (Senior Vice President, Elsevier Science) will direct the Elsevier Science part of the project planning effort, drawing on her distinguished record in scholarly publishing and on her career-long liaison work with academic libraries.</p>
<p>Paul Conway (Head of the Yale Library Preservation Department) will be the project manager. He will devote an estimated 40% of his annual effort to the project, drawing on his internationally recognized expertise in preservation and digital technology and on his demonstrated project management skills. Working under the direction of Scott Bennett and Ann Okerson, Paul Conway will keep the project team focused on the completion of its tasks in a timely fashion. He will provide the project with daily coordination, leadership energy, and staff support; he will draft most of the project documents.</p>
<p>The project will hire a systems officer to lead in specifying the technical environment needed for our archival work, to explore alternatives for creating that environment, and to build prototype elements of our system. We expect to employ a systems officer already working at Yale, to ensure familiarity with the institution and a prompt start for our project. Practically speaking, it will probably not be possible to release the full-time effort of a senior systems officer for this project. Preliminary conversations suggest we can secure the majority of such a person's time, along with the efforts of others, to give us a strong team with a wide range of expertise and the equivalent of at least a full-time appointment.</p>
<p>Project personnel have substantial experience in defining and negotiating licenses for intellectual property. Yale's Office of the General Counsel has been both thoughtful and generous in supporting this work when that has been needed. We believe this tested team approach will meet the project's need for legal counsel during the planning year.</p>
<p>While it is likely the project will need the services of a business planning consultant, the nature, scope, and cost of those services cannot realistically be predicted now. It seems best to rely on the University Librarian's Discretionary Funds for this purpose.</p>
</div2>
</div1>

</back>

</text>
</TEI.2>